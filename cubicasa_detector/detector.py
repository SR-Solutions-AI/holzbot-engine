# file: engine/cubicasa_detector/detector.py
from __future__ import annotations

import sys
import os
import cv2
import numpy as np
import torch
import torch.nn.functional as F
import json
import math
import re
import requests
import base64
from pathlib import Path
from PIL import Image
from io import BytesIO
from skimage.morphology import skeletonize

# ImportÄƒm funcÈ›iile OCR È™i room filling din modulul dedicat
from .ocr_room_filling import (
    fill_stairs_room,
    fill_room_by_ocr,
    preprocess_image_for_ocr,
    run_ocr_on_zones,
    _reconstruct_word_from_chars,
)

# ImportÄƒm funcÈ›iile din modulele refactorizate
from .raster_api import (
    call_raster_api,
    generate_raster_images,
    generate_api_walls_mask,
    validate_api_walls_mask,
    brute_force_alignment,
    apply_alignment_and_generate_overlay,
    generate_crop_from_raster,
)
from .wall_repair import (
    repair_house_walls_with_floodfill,
    bridge_wall_gaps,
    smart_wall_closing,
    get_strict_1px_outline,
)
from .raster_processing import (
    generate_raster_walls_overlay,
    detect_interior_exterior_from_raster,
    calculate_scale_per_room,
    generate_walls_interior_exterior,
    generate_interior_structure_walls,
)
from .interior_exterior import detect_interior_exterior_zones
from .scale_detection import detect_scale_from_room_labels, call_gemini
from .measurements import calculate_measurements

# OCR pentru detectarea textului
try:
    import pytesseract
    TESSERACT_AVAILABLE = True
except ImportError:
    TESSERACT_AVAILABLE = False
    print("âš ï¸ pytesseract nu este disponibil. Detectarea textului 'terasa' va fi dezactivatÄƒ.")

# ============================================
# CONFIGURARE PATHS
# ============================================

def _get_cubicasa_path():
    """GÄƒseÈ™te automat CubiCasa5k relativ la acest fiÈ™ier."""
    current_dir = Path(__file__).parent
    candidates = [
        current_dir / "CubiCasa5k",
        current_dir.parent / "CubiCasa5k",
        current_dir.parent.parent / "CubiCasa5k",
    ]
    
    for path in candidates:
        if path.exists():
            return str(path)
    
    # Am comentat partea de raise pentru a nu bloca rularea
    # raise FileNotFoundError(
    #     "Nu gÄƒsesc folderul CubiCasa5k. "
    #     "PlaseazÄƒ-l Ã®n runner/cubicasa_detector/ sau runner/"
    # )
    return str(current_dir / "CubiCasa5k")

CUBICASA_PATH = _get_cubicasa_path()
sys.path.insert(0, CUBICASA_PATH)

try:
    from floortrans.models.hg_furukawa_original import hg_furukawa_original
except ImportError as e:
    # Am modificat excepÈ›ia pentru a nu bloca rularea
    print(f"AtenÈ›ie: Nu pot importa modelul CubiCasa. VerificÄƒ path-ul: {e}")
    class hg_furukawa_original:
        def __init__(self, n_classes): pass
        def to(self, device): pass
        def eval(self): pass


# ============================================
# HELPERS GENERALE
# ============================================

def ensure_dir(path):
    Path(path).mkdir(parents=True, exist_ok=True)

def save_step(name, img, steps_dir):
    path = Path(steps_dir) / f"{name}.png"
    cv2.imwrite(str(path), img)

def filter_thin_lines(walls_raw: np.ndarray, image_dims: tuple, steps_dir: str = None) -> np.ndarray:
    """
    Filtrarea liniilor subÈ›iri (nemodificatÄƒ).
    """
    h, w = image_dims
    min_dim = min(h, w)
    min_wall_thickness = max(3, int(min_dim * 0.004))
    
    print(f"      ğŸ§¹ Filtrez linii subÈ›iri: prag {min_wall_thickness}px...")
    
    filter_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (min_wall_thickness, min_wall_thickness))
    walls_eroded = cv2.erode(walls_raw, filter_kernel, iterations=1)
    
    if steps_dir:
        save_step("filter_01_eroded", walls_eroded, str(steps_dir))
    
    walls_filtered = cv2.dilate(walls_eroded, filter_kernel, iterations=1)
    
    if steps_dir:
        save_step("filter_02_restored", walls_filtered, str(steps_dir))
    
    pixels_before = np.count_nonzero(walls_raw)
    pixels_after = np.count_nonzero(walls_filtered)
    removed_pct = 100 * (pixels_before - pixels_after) / pixels_before if pixels_before > 0 else 0
    
    print(f"         Eliminat {removed_pct:.1f}% pixeli (linii subÈ›iri)")
    
    return walls_filtered

def aggressive_wall_repair(walls_raw: np.ndarray, image_dims: tuple, steps_dir: str = None) -> np.ndarray:
    """Reparare puternicÄƒ a pereÈ›ilor pentru imagini mari (nemodificatÄƒ)."""
    h, w = image_dims
    min_dim = min(h, w)
    
    kernel_size = max(7, int(min_dim * 0.009))
    if kernel_size % 2 == 0: kernel_size += 1
    
    print(f"      ğŸ”§ Strong repair: kernel {kernel_size}x{kernel_size}")
    
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size, kernel_size))
    kernel_small = cv2.getStructuringElement(cv2.MORPH_RECT, (max(5, kernel_size-2), max(5, kernel_size-2)))
    
    walls_closed = cv2.morphologyEx(walls_raw, cv2.MORPH_CLOSE, kernel, iterations=2)
    if steps_dir:
        save_step("repair_01_close", walls_closed, steps_dir)
    
    walls_dilated = cv2.dilate(walls_closed, kernel_small, iterations=1)
    if steps_dir:
        save_step("repair_02_dilate", walls_dilated, steps_dir)
    
    walls_final = cv2.morphologyEx(walls_dilated, cv2.MORPH_CLOSE, kernel, iterations=1)
    if steps_dir:
        save_step("repair_03_final_close", walls_final, steps_dir)
    
    return walls_final

def border_constrained_fill(walls_mask: np.ndarray, steps_dir: str = None) -> np.ndarray:
    """
    Ãnchide golurile Ã®n peretele exterior folosind Border-Constrained Fill.
    
    DetecteazÄƒ cel mai mare contur (perimetrul casei), genereazÄƒ convex hull,
    È™i foloseÈ™te hull-ul ca ghidaj pentru a vedea unde ar trebui sÄƒ existe un perete
    Ã®ntre douÄƒ puncte extreme.
    
    Args:
        walls_mask: Masca pereÈ›ilor (255 = perete, 0 = spaÈ›iu liber)
        steps_dir: Director pentru salvarea step-urilor de debug (opÈ›ional)
    
    Returns:
        Masca pereÈ›ilor cu golurile din peretele exterior Ã®nchise
    """
    h, w = walls_mask.shape[:2]
    
    print(f"      ğŸ›ï¸ Border-Constrained Fill: Ã®nchid goluri Ã®n peretele exterior...")
    
    result = walls_mask.copy()
    
    # Pas 1: DetectÄƒm contururile exterioare
    contours, _ = cv2.findContours(walls_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if len(contours) == 0:
        print(f"         âš ï¸ Nu s-au detectat contururi")
        return result
    
    # Pas 2: GÄƒsim cel mai mare contur (perimetrul casei)
    largest_contour = max(contours, key=cv2.contourArea)
    
    if cv2.contourArea(largest_contour) < min(h, w) * 10:  # Contur prea mic
        print(f"         âš ï¸ Conturul cel mai mare este prea mic")
        return result
    
    # Pas 3: GenerÄƒm convex hull pentru conturul cel mai mare
    hull = cv2.convexHull(largest_contour)
    
    if steps_dir:
        # SalvÄƒm vizualizarea hull-ului
        debug_image = cv2.cvtColor(walls_mask, cv2.COLOR_GRAY2BGR)
        cv2.drawContours(debug_image, [largest_contour], -1, (0, 255, 0), 2)  # Verde pentru conturul original
        cv2.drawContours(debug_image, [hull], -1, (0, 0, 255), 2)  # RoÈ™u pentru hull
        cv2.imwrite(str(Path(steps_dir) / "02c_border_hull_debug.png"), debug_image)
    
    # Pas 4: ComparÄƒm hull-ul cu conturul original pentru a gÄƒsi golurile
    # CreÄƒm o mascÄƒ pentru hull
    hull_mask = np.zeros((h, w), dtype=np.uint8)
    cv2.fillPoly(hull_mask, [hull], 255)
    
    # CreÄƒm o mascÄƒ pentru conturul original
    contour_mask = np.zeros((h, w), dtype=np.uint8)
    cv2.fillPoly(contour_mask, [largest_contour], 255)
    
    # DiferenÈ›a dintre hull È™i contur indicÄƒ zonele unde ar trebui sÄƒ existe pereÈ›i
    # Dar nu vrem sÄƒ umplem interiorul, doar sÄƒ conectÄƒm punctele extreme
    hull_points = hull.reshape(-1, 2)
    contour_points = largest_contour.reshape(-1, 2)
    
    # Pas 5: GÄƒsim segmentele din hull care reprezintÄƒ goluri reale Ã®n peretele exterior
    # Strategie: VerificÄƒm doar segmentele care conecteazÄƒ puncte apropiate de conturul original
    connections_made = 0
    max_gap_distance = max(150, int(min(h, w) * 0.12))  # 12% din dimensiunea minimÄƒ
    
    # GÄƒsim punctele din conturul original care sunt aproape de hull
    contour_points = largest_contour.reshape(-1, 2)
    
    for i in range(len(hull_points)):
        p1 = tuple(hull_points[i])
        p2 = tuple(hull_points[(i + 1) % len(hull_points)])
        
        # CalculÄƒm distanÈ›a dintre puncte
        segment_length = np.sqrt((p2[0] - p1[0])**2 + (p2[1] - p1[1])**2)
        
        # IgnorÄƒm segmentele prea scurte sau prea lungi
        if segment_length < 20 or segment_length > max_gap_distance:
            continue
        
        # GÄƒsim cele mai apropiate puncte din conturul original pentru p1 È™i p2
        min_dist_p1 = float('inf')
        min_dist_p2 = float('inf')
        closest_contour_p1 = None
        closest_contour_p2 = None
        
        for cp in contour_points:
            dist_p1 = np.sqrt((cp[0] - p1[0])**2 + (cp[1] - p1[1])**2)
            dist_p2 = np.sqrt((cp[0] - p2[0])**2 + (cp[1] - p2[1])**2)
            
            if dist_p1 < min_dist_p1:
                min_dist_p1 = dist_p1
                closest_contour_p1 = tuple(cp)
            
            if dist_p2 < min_dist_p2:
                min_dist_p2 = dist_p2
                closest_contour_p2 = tuple(cp)
        
        # VerificÄƒm cÄƒ ambele capete sunt aproape de conturul original (max 50 pixeli)
        max_endpoint_distance = 50
        if min_dist_p1 > max_endpoint_distance or min_dist_p2 > max_endpoint_distance:
            continue
        
        # VerificÄƒm dacÄƒ existÄƒ deja un perete Ã®ntre cele douÄƒ puncte din conturul original
        # (nu Ã®ntre punctele din hull, ci Ã®ntre cele mai apropiate puncte din contur)
        if closest_contour_p1 is None or closest_contour_p2 is None:
            continue
        
        # VerificÄƒm dacÄƒ cele douÄƒ puncte din contur sunt consecutive sau apropiate
        # GÄƒsim poziÈ›iile lor Ã®n contur
        idx1 = None
        idx2 = None
        for idx, cp in enumerate(contour_points):
            if np.allclose(cp, closest_contour_p1, atol=2):
                idx1 = idx
            if np.allclose(cp, closest_contour_p2, atol=2):
                idx2 = idx
        
        if idx1 is None or idx2 is None:
            continue
        
        # VerificÄƒm dacÄƒ punctele sunt apropiate Ã®n contur (nu la capete opuse)
        contour_distance = min(abs(idx2 - idx1), len(contour_points) - abs(idx2 - idx1))
        if contour_distance > len(contour_points) * 0.3:  # Prea departe Ã®n contur
            continue
        
        # VerificÄƒm dacÄƒ existÄƒ un gol Ã®ntre cele douÄƒ puncte din contur
        # EÈ™antionÄƒm puncte de-a lungul liniei dintre punctele din contur
        num_samples = max(30, int(segment_length / 5))
        wall_pixels = 0
        space_pixels = 0
        
        for t in np.linspace(0, 1, num_samples):
            px = int(closest_contour_p1[0] + t * (closest_contour_p2[0] - closest_contour_p1[0]))
            py = int(closest_contour_p1[1] + t * (closest_contour_p2[1] - closest_contour_p1[1]))
            
            if 0 <= px < w and 0 <= py < h:
                if walls_mask[py, px] == 255:
                    wall_pixels += 1
                else:
                    space_pixels += 1
        
        # DacÄƒ mai puÈ›in de 40% din linie este perete, existÄƒ un gol
        if wall_pixels / num_samples < 0.4:
            # VerificÄƒm cÄƒ linia nu trece prin interiorul casei
            # EÈ™antionÄƒm cÃ¢teva puncte È™i verificÄƒm cÄƒ nu sunt Ã®n interior
            valid_connection = True
            interior_count = 0
            
            for t in np.linspace(0.2, 0.8, 5):  # VerificÄƒm doar punctele din mijloc
                px = int(closest_contour_p1[0] + t * (closest_contour_p2[0] - closest_contour_p1[0]))
                py = int(closest_contour_p1[1] + t * (closest_contour_p2[1] - closest_contour_p1[1]))
                
                if 0 <= px < w and 0 <= py < h:
                    # VerificÄƒm dacÄƒ punctul este Ã®n interiorul conturului
                    point_inside = cv2.pointPolygonTest(largest_contour, (px, py), False)
                    if point_inside > 0:  # Ãn interior
                        interior_count += 1
                    
                    # VerificÄƒm cÄƒ existÄƒ pereÈ›i Ã®n jur (nu doar spaÈ›iu liber)
                    y_min = max(0, py - 15)
                    y_max = min(h, py + 16)
                    x_min = max(0, px - 15)
                    x_max = min(w, px + 16)
                    neighborhood = walls_mask[y_min:y_max, x_min:x_max]
                    if np.count_nonzero(neighborhood) < 10:  # Prea puÈ›ini pereÈ›i Ã®n jur
                        valid_connection = False
                        break
            
            # DacÄƒ mai mult de 2 puncte sunt Ã®n interior, nu desenÄƒm (ar tÄƒia colÈ›urile)
            if interior_count > 2:
                valid_connection = False
            
            if valid_connection:
                # DesenÄƒm linia Ã®ntre punctele din conturul original (nu din hull)
                cv2.line(result, closest_contour_p1, closest_contour_p2, 255, 2)
                connections_made += 1
    
    print(f"         âœ… FÄƒcute {connections_made} conexiuni pentru peretele exterior")
    
    # SalvÄƒm rezultatul
    if steps_dir:
        output_path = Path(steps_dir) / "02c_border_constrained_fill.png"
        cv2.imwrite(str(output_path), result)
        print(f"         ğŸ’¾ Salvat: {output_path.name}")
    
    return result

def interval_merging_axis_projections(walls_mask: np.ndarray, steps_dir: str = None, corridor_width: int = 5, max_vacuum_gap: int = 20) -> np.ndarray:
    """
    UneÈ™te segmentele de pereÈ›i folosind Binary Conflict Profiling.
    Algoritm robust care verificÄƒ doar segmentele adiacente È™i foloseÈ™te testele de intruziune È™i Ghost.
    
    Algoritm:
    1. Vectorizare: DetectÄƒm segmentele folosind LSD (Line Segment Detector)
    2. Grupare pe Axe: GrupÄƒm segmentele pe "È™ine" (aceeaÈ™i coordonatÄƒ Y pentru orizontale, X pentru verticale)
    3. Sortare È™i Perechi Adiacente: SortÄƒm segmentele È™i verificÄƒm doar perechile adiacente
    4. Test de Intruziune: VerificÄƒm dacÄƒ existÄƒ pereÈ›i perpendiculari Ã®ntre capete
    5. Test Ghost: VerificÄƒm dacÄƒ zona e prea albÄƒ Ã®n original (camerÄƒ)
    
    Args:
        walls_mask: Masca pereÈ›ilor (255 = perete, 0 = spaÈ›iu liber) - 02_ai_walls_closed.png
        steps_dir: Director pentru salvarea step-urilor de debug (opÈ›ional)
        corridor_width: LÄƒÈ›imea coridorului de scanare (nefolosit Ã®n acest algoritm, pÄƒstrat pentru compatibilitate)
        max_vacuum_gap: NumÄƒrul maxim de pixeli albi consecutivi permisi (default: 20)
    
    Returns:
        Masca pereÈ›ilor cu segmentele unite chirurgical
    """
    h, w = walls_mask.shape[:2]
    
    print(f"      ğŸ“ Binary Conflict Profiling: unesc segmente adiacente cu validare robustÄƒ...")
    
    result = walls_mask.copy()
    
    # ÃncÄƒrcÄƒm imaginea originalÄƒ (Ghost Layer) pentru validare
    ghost_img = None
    if steps_dir:
        original_path = Path(steps_dir) / "00_original.png"
        if original_path.exists():
            print(f"         ğŸ” ÃncÄƒrc imaginea originalÄƒ pentru validare...")
            original_img = cv2.imread(str(original_path))
            if original_img is not None:
                # Convertim la grayscale
                ghost_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2GRAY)
                # RedimensionÄƒm dacÄƒ e necesar
                if ghost_img.shape[:2] != (h, w):
                    ghost_img = cv2.resize(ghost_img, (w, h))
                print(f"         âœ… Imagine originalÄƒ Ã®ncÄƒrcatÄƒ pentru validare")
    
    # Pas 1: Vectorizare prin LSD (Line Segment Detector)
    print(f"         ğŸ” Pas 1: Detectez segmente cu LSD...")
    lsd = cv2.createLineSegmentDetector(0)
    lines = lsd.detect(walls_mask)[0]
    
    if lines is None or len(lines) == 0:
        print(f"         âš ï¸ Nu s-au detectat segmente")
        return result
    
    print(f"         âœ… Detectat {len(lines)} segmente")
    
    # CreÄƒm imagini pentru vizualizare
    if steps_dir:
        vis_segments = cv2.cvtColor(walls_mask, cv2.COLOR_GRAY2BGR)
        vis_grouped = cv2.cvtColor(walls_mask, cv2.COLOR_GRAY2BGR)
        vis_connections = cv2.cvtColor(walls_mask, cv2.COLOR_GRAY2BGR)
        vis_result = cv2.cvtColor(walls_mask, cv2.COLOR_GRAY2BGR)
    
    # PaletÄƒ de culori
    colors = [
        (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0),
        (255, 0, 255), (0, 255, 255), (128, 0, 128), (255, 165, 0)
    ]
    
    # DesenÄƒm segmentele detectate
    if steps_dir:
        for i, line in enumerate(lines):
            x1, y1, x2, y2 = line[0].astype(int)
            color = colors[i % len(colors)]
            cv2.line(vis_segments, (x1, y1), (x2, y2), color, 2)
        cv2.imwrite(str(Path(steps_dir) / "02f_01_lsd_segments.png"), vis_segments)
        print(f"         ğŸ’¾ Salvat: 02f_01_lsd_segments.png")
    
    # Pas 2: Grupare pe Axe (È™ine)
    print(f"         ğŸ” Pas 2: Grupez segmente pe axe...")
    horizontal_rails = {}  # cheie: y_coord (rotunjit), valoare: lista de (x1, x2, line_idx)
    vertical_rails = {}    # cheie: x_coord (rotunjit), valoare: lista de (y1, y2, line_idx)
    
    tolerance = 3  # ToleranÈ›Äƒ pentru gruparea pe axe
    
    for line_idx, line in enumerate(lines):
        x1, y1, x2, y2 = line[0]
        
        dx = x2 - x1
        dy = y2 - y1
        length = np.sqrt(dx*dx + dy*dy)
        
        if length < 10:
            continue
        
        # VerificÄƒm dacÄƒ e orizontalÄƒ
        if abs(dy) < tolerance:
            y_coord = int((y1 + y2) / 2)
            y_key = round(y_coord / tolerance) * tolerance
            if y_key not in horizontal_rails:
                horizontal_rails[y_key] = []
            horizontal_rails[y_key].append((min(x1, x2), max(x1, x2), line_idx))
        
        # VerificÄƒm dacÄƒ e verticalÄƒ
        elif abs(dx) < tolerance:
            x_coord = int((x1 + x2) / 2)
            x_key = round(x_coord / tolerance) * tolerance
            if x_key not in vertical_rails:
                vertical_rails[x_key] = []
            vertical_rails[x_key].append((min(y1, y2), max(y1, y2), line_idx))
    
    print(f"         âœ… Grupate: {len(horizontal_rails)} È™ine orizontale, {len(vertical_rails)} È™ine verticale")
    
    if steps_dir:
        for y_key, segments in horizontal_rails.items():
            for x1, x2, line_idx in segments:
                color = colors[line_idx % len(colors)]
                cv2.line(vis_grouped, (int(x1), int(y_key)), (int(x2), int(y_key)), color, 2)
        for x_key, segments in vertical_rails.items():
            for y1, y2, line_idx in segments:
                color = colors[line_idx % len(colors)]
                cv2.line(vis_grouped, (int(x_key), int(y1)), (int(x_key), int(y2)), color, 2)
        cv2.imwrite(str(Path(steps_dir) / "02f_02_grouped_rails.png"), vis_grouped)
        print(f"         ğŸ’¾ Salvat: 02f_02_grouped_rails.png")
    
    # FuncÈ›ii helper pentru validare
    def test_intrusion(start_pt, end_pt, walls_mask_image):
        """
        Test de Intruziune: VerificÄƒ dacÄƒ Ã®ntre capete existÄƒ pereÈ›i perpendiculari.
        """
        # EÈ™antionÄƒm puncte de-a lungul liniei
        dx = end_pt[0] - start_pt[0]
        dy = end_pt[1] - start_pt[1]
        dist = np.sqrt(dx*dx + dy*dy)
        num_samples = max(10, int(dist / 5))
        perpendicular_walls = 0
        
        for t in np.linspace(0.1, 0.9, num_samples):  # EvitÄƒm capetele
            px = int(start_pt[0] + t * dx)
            py = int(start_pt[1] + t * dy)
            
            if 0 <= px < w and 0 <= py < h:
                # VerificÄƒm pe o bandÄƒ perpendicularÄƒ pe linie
                check_radius = 5
                if abs(dx) > abs(dy):  # Linie orizontalÄƒ
                    for offset in range(-check_radius, check_radius + 1):
                        check_y = py + offset
                        if 0 <= check_y < h and abs(offset) > 2:
                            if walls_mask_image[check_y, px] == 255:
                                perpendicular_walls += 1
                                break
                else:  # Linie verticalÄƒ
                    for offset in range(-check_radius, check_radius + 1):
                        check_x = px + offset
                        if 0 <= check_x < w and abs(offset) > 2:
                            if walls_mask_image[py, check_x] == 255:
                                perpendicular_walls += 1
                                break
        
        # DacÄƒ mai mult de 20% din eÈ™antioane au pereÈ›i perpendiculari, respingem
        return perpendicular_walls <= num_samples * 0.2
    
    def test_ghost_profile(start_pt, end_pt, ghost_image):
        """
        Test Ghost: VerificÄƒ profilul de intensitate Ã®n imaginea originalÄƒ.
        DacÄƒ zona e prea albÄƒ (camerÄƒ), respinge conexiunea.
        """
        if ghost_image is None:
            return True
        
        # CreÄƒm o mascÄƒ temporarÄƒ cu linia propusÄƒ
        temp_mask = np.zeros(ghost_image.shape[:2], dtype=np.uint8)
        cv2.line(temp_mask, start_pt, end_pt, 255, 3)
        
        # Extragem pixelii de sub linie
        path_pixels = ghost_image[temp_mask > 0]
        
        if len(path_pixels) == 0:
            return False
        
        # VerificÄƒm raportul de alb (vid)
        white_ratio = np.sum(path_pixels > 245) / len(path_pixels)
        
        # DacÄƒ mai mult de 85% e alb, e camerÄƒ
        return white_ratio < 0.85
    
    # Pas 3: Sortare È™i verificare perechi adiacente
    print(f"         ğŸ” Pas 3: Sortez segmente È™i verific perechi adiacente...")
    connections_made = 0
    
    # ProcesÄƒm È™inele orizontale
    for y_coord, segments in horizontal_rails.items():
        if len(segments) < 2:
            continue
        
        # SortÄƒm segmentele de la stÃ¢nga la dreapta
        segments_sorted = sorted(segments, key=lambda x: x[0])
        
        # VerificÄƒm doar perechile adiacente
        for i in range(len(segments_sorted) - 1):
            x1_end, x1_start, line_idx1 = segments_sorted[i]
            x2_start, x2_end, line_idx2 = segments_sorted[i + 1]
            
            # Capetele segmentelor
            end_pt = (int(x1_end), int(y_coord))
            start_pt = (int(x2_start), int(y_coord))
            
            # VerificÄƒm dacÄƒ existÄƒ un gap
            if x2_start > x1_end:
                gap_size = x2_start - x1_end
                
                # IgnorÄƒm gap-uri prea mari (probabil nu sunt pe aceeaÈ™i axÄƒ)
                if gap_size > w * 0.3:
                    continue
                
                # TEST DE INTRUZIUNE: VerificÄƒm dacÄƒ existÄƒ pereÈ›i perpendiculari
                if not test_intrusion(end_pt, start_pt, walls_mask):
                    if steps_dir:
                        cv2.line(vis_connections, end_pt, start_pt, (0, 0, 255), 2)  # RoÈ™u
                    continue
                
                # TEST GHOST: VerificÄƒm profilul de intensitate
                if not test_ghost_profile(end_pt, start_pt, ghost_img):
                    if steps_dir:
                        cv2.line(vis_connections, end_pt, start_pt, (0, 165, 255), 2)  # Portocaliu
                    continue
                
                # Ambele teste au trecut - unim!
                cv2.line(result, end_pt, start_pt, 255, 3)
                
                if steps_dir:
                    cv2.line(vis_connections, end_pt, start_pt, (0, 255, 0), 2)  # Verde
                    cv2.line(vis_result, end_pt, start_pt, (0, 255, 0), 2)
                
                connections_made += 1
    
    # ProcesÄƒm È™inele verticale (aceeaÈ™i logicÄƒ)
    for x_coord, segments in vertical_rails.items():
        if len(segments) < 2:
            continue
        
        # SortÄƒm segmentele de sus Ã®n jos
        segments_sorted = sorted(segments, key=lambda x: x[0])
        
        # VerificÄƒm doar perechile adiacente
        for i in range(len(segments_sorted) - 1):
            y1_end, y1_start, line_idx1 = segments_sorted[i]
            y2_start, y2_end, line_idx2 = segments_sorted[i + 1]
            
            # Capetele segmentelor
            end_pt = (int(x_coord), int(y1_end))
            start_pt = (int(x_coord), int(y2_start))
            
            # VerificÄƒm dacÄƒ existÄƒ un gap
            if y2_start > y1_end:
                gap_size = y2_start - y1_end
                
                # IgnorÄƒm gap-uri prea mari
                if gap_size > h * 0.3:
                    continue
                
                # TEST DE INTRUZIUNE
                if not test_intrusion(end_pt, start_pt, walls_mask):
                    if steps_dir:
                        cv2.line(vis_connections, end_pt, start_pt, (0, 0, 255), 2)  # RoÈ™u
                    continue
                
                # TEST GHOST
                if not test_ghost_profile(end_pt, start_pt, ghost_img):
                    if steps_dir:
                        cv2.line(vis_connections, end_pt, start_pt, (0, 165, 255), 2)  # Portocaliu
                    continue
                
                # Ambele teste au trecut - unim!
                cv2.line(result, end_pt, start_pt, 255, 3)
                
                if steps_dir:
                    cv2.line(vis_connections, end_pt, start_pt, (0, 255, 0), 2)  # Verde
                    cv2.line(vis_result, end_pt, start_pt, (0, 255, 0), 2)
                
                connections_made += 1
    
    print(f"         âœ… Unite {connections_made} perechi de segmente adiacente")
    
    # SalvÄƒm rezultatele
    if steps_dir:
        cv2.imwrite(str(Path(steps_dir) / "02f_03_connections.png"), vis_connections)
        print(f"         ğŸ’¾ Salvat: 02f_03_connections.png (verde=valide, roÈ™u=intruziune, portocaliu=ghost)")
        
        cv2.imwrite(str(Path(steps_dir) / "02f_04_interval_merging_result.png"), vis_result)
        print(f"         ğŸ’¾ Salvat: 02f_04_interval_merging_result.png")
        
        cv2.imwrite(str(Path(steps_dir) / "02f_05_final_result.png"), result)
        print(f"         ğŸ’¾ Salvat: 02f_05_final_result.png (rezultat final binar)")
    
    return result

# FuncÈ›iile OCR (preprocess_image_for_ocr, _reconstruct_word_from_chars, run_ocr_on_zones) 
# au fost mutate Ã®n ocr_room_filling.py È™i sunt importate de acolo.
# FuncÈ›iile OCR duplicate au fost È™terse - sunt importate din ocr_room_filling.py

# FuncÈ›iile mutate Ã®n modulele refactorizate:
# - repair_house_walls_with_floodfill, bridge_wall_gaps, smart_wall_closing, get_strict_1px_outline -> wall_repair.py
# - detect_interior_exterior_zones -> interior_exterior.py
# - detect_scale_from_room_labels, call_gemini -> scale_detection.py
# - calculate_measurements -> measurements.py
# - call_raster_api, generate_raster_images, brute_force_alignment, etc. -> raster_api.py
    """
    ÃncearcÄƒ sÄƒ repare toÈ›i pereÈ›ii de jur-Ã®mprejurul casei folosind aceeaÈ™i
    idee ca la terasÄƒ: flood fill Ã®n interiorul casei, apoi completarea
    golurilor de pe conturul regiunii umplute.
    
    Args:
        walls_mask: Masca pereÈ›ilor (trebuie sÄƒ includÄƒ deja pereÈ›ii adÄƒugaÈ›i pentru garaj/scÄƒri)
        steps_dir: Director pentru salvarea imaginilor de debug (opÈ›ional)
    
    Returns:
        Masca pereÈ›ilor cu pereÈ›ii exteriori reparaÈ›i (dacÄƒ a fost posibil)
    """
    if walls_mask is None:
        print(f"      âš ï¸ walls_mask este None. Skip repararea pereÈ›ilor casei.")
        return None
    
    try:
        h, w = walls_mask.shape[:2]
    except AttributeError:
        print(f"      âš ï¸ walls_mask nu are atributul shape. Skip repararea pereÈ›ilor casei.")
        return None
    
    # Folosim o metodÄƒ alternativÄƒ dacÄƒ OCR nu este disponibil
    use_ocr = TESSERACT_AVAILABLE
    if not use_ocr:
        print(f"      âš ï¸ pytesseract nu este disponibil. Skip detectarea {room_name}.")
        return walls_mask.copy()
    
    result = walls_mask.copy()
    
    print(f"      ğŸ¡ Detectez È™i umplu camere ({room_name})...")
    
    # Pas 1: ÃncÄƒrcÄƒm overlay-ul sau original-ul pentru OCR
    overlay_path = None
    original_path = None
    if steps_dir:
        overlay_path = Path(steps_dir) / "02d_walls_closed_overlay.png"
        original_path = Path(steps_dir) / "00_original.png"
    
    # PreferÄƒm imaginea originalÄƒ pentru detectarea textului (textul este mai clar acolo)
    ocr_image = None
    if original_path and original_path.exists():
        ocr_image = cv2.imread(str(original_path), cv2.IMREAD_COLOR)
        if ocr_image is None:
            ocr_image = cv2.imread(str(original_path), cv2.IMREAD_GRAYSCALE)
            if ocr_image is not None:
                ocr_image = cv2.cvtColor(ocr_image, cv2.COLOR_GRAY2BGR)
        print(f"         ğŸ“¸ Folosesc original pentru OCR: {original_path.name}")
    elif overlay_path and overlay_path.exists():
        ocr_image = cv2.imread(str(overlay_path), cv2.IMREAD_COLOR)
        print(f"         ğŸ“¸ Folosesc overlay pentru OCR (fallback): {overlay_path.name}")
    
    if ocr_image is None:
        print(f"         âš ï¸ Nu s-a gÄƒsit overlay sau original. Skip detectarea {room_name}.")
        return result
    
    # RedimensionÄƒm dacÄƒ este necesar
    if ocr_image.shape[:2] != (h, w):
        ocr_image = cv2.resize(ocr_image, (w, h))
    
    # Pas 2: DetectÄƒm textul folosind OCR cu preprocesare È™i analizÄƒ pe zone
    print(f"         ğŸ” Pas 1: Detectez text ({room_name})...")
    
    text_found = False
    text_boxes = []
    all_detections = []  # IniÈ›ializÄƒm all_detections pentru a evita NameError
    
    try:
        if use_ocr:
            # Metoda Ã®mbunÄƒtÄƒÈ›itÄƒ: OCR cu preprocesare È™i analizÄƒ pe zone
            print(f"         ğŸ“ Folosesc OCR cu preprocesare È™i analizÄƒ pe zone...")
            
            # Salvez imaginea preprocesatÄƒ pentru debug
            if steps_dir:
                processed_img = preprocess_image_for_ocr(ocr_image)
                cv2.imwrite(str(Path(steps_dir) / f"{debug_prefix}_00_preprocessed.png"), processed_img)
                print(f"         ğŸ’¾ Salvat: {debug_prefix}_00_preprocessed.png (imagine preprocesatÄƒ)")
            
            # RuleazÄƒ OCR pe zone cu zoom
            text_boxes, all_detections = run_ocr_on_zones(ocr_image, search_terms, steps_dir, 
                                         grid_rows=3, grid_cols=3, zoom_factor=2.0)
            
            if text_boxes:
                            text_found = True
        else:
            print(f"         âš ï¸ FÄƒrÄƒ OCR nu pot identifica specific cuvÃ¢ntul '{room_name}'.")
            text_found = False
            text_boxes = []
            all_detections = []
        
        # SelectÄƒm rezultatul cu confidence maxim (dacÄƒ existÄƒ)
        accepted_boxes = []  # DetecÈ›iile acceptate È™i folosite (confidence > 60%)
        best_box_all = None  # Cea mai bunÄƒ detecÈ›ie (chiar dacÄƒ are confidence < 60%)
        
        if text_boxes:
            # SortÄƒm dupÄƒ confidence (descrescÄƒtor)
            text_boxes.sort(key=lambda box: box[5], reverse=True)  # box[5] = confidence
            best_box_all = text_boxes[0]  # Cea mai bunÄƒ detecÈ›ie (chiar dacÄƒ e < 60%)
            
            # Filtram doar detecÈ›iile cu confidence > 60% pentru procesare
            accepted_boxes = [box for box in text_boxes if box[5] > 60]
            
            if accepted_boxes:
                best_box = accepted_boxes[0]
                print(f"         ğŸ¯ Selectat rezultatul cu confidence maxim: '{best_box[4]}' cu {best_box[5]:.1f}%")
                text_boxes = accepted_boxes.copy()  # ActualizÄƒm text_boxes pentru procesare
            else:
                print(f"         âš ï¸ Cea mai bunÄƒ detecÈ›ie: '{best_box_all[4]}' cu {best_box_all[5]:.1f}% (< 60%, nu acceptatÄƒ)")
                text_boxes = []  # Nu avem detecÈ›ii acceptate pentru procesare
        elif use_ocr and all_detections:
            # DacÄƒ nu am gÄƒsit detecÈ›ii care se potrivesc cu termenii, folosim cea mai bunÄƒ detecÈ›ie din toate
            all_detections.sort(key=lambda box: box[5], reverse=True)  # box[5] = confidence
            best_box_all = all_detections[0]
            print(f"         âš ï¸ Nu s-au gÄƒsit detecÈ›ii care se potrivesc cu termenii, dar am gÄƒsit '{best_box_all[4]}' cu {best_box_all[5]:.1f}%")
        
        # SalvÄƒm poza cu cea mai bunÄƒ detecÈ›ie (chiar dacÄƒ nu e acceptatÄƒ)
        if steps_dir and best_box_all:
            vis_best_detection = ocr_image.copy() if ocr_image is not None else cv2.cvtColor(walls_mask, cv2.COLOR_GRAY2BGR)
            best_x, best_y, best_width, best_height, best_text, best_conf = best_box_all
            best_center_x = best_x + best_width // 2
            best_center_y = best_y + best_height // 2
            
            # Culoare: verde dacÄƒ e acceptatÄƒ, portocaliu dacÄƒ nu
            if best_conf > 60:
                detection_color = (0, 255, 0)  # Verde
                status_label = f"âœ… ACCEPTED ({best_conf:.1f}%)"
            else:
                detection_color = (0, 165, 255)  # Portocaliu
                status_label = f"âŒ REJECTED ({best_conf:.1f}% < 60%)"
            
            cv2.rectangle(vis_best_detection, (best_x, best_y), (best_x + best_width, best_y + best_height), detection_color, 3)
            cv2.circle(vis_best_detection, (best_center_x, best_center_y), 8, (0, 0, 255), -1)
            
            label_text = f"{best_text} - {status_label} | No Flood Fill"
            font_scale = max(0.7, best_height / 30.0)
            font_thickness = max(2, int(font_scale * 2))
            (text_width, text_height), baseline = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)
            
            text_y = max(text_height + 5, best_y - 5)
            text_x = best_x
            cv2.rectangle(vis_best_detection, 
                         (text_x, text_y - text_height - baseline), 
                         (text_x + text_width + 10, text_y + baseline), 
                         (255, 255, 255), -1)
            
            cv2.putText(vis_best_detection, label_text, (text_x + 5, text_y), 
                       cv2.FONT_HERSHEY_SIMPLEX, font_scale, detection_color, font_thickness)
            
            output_path = Path(steps_dir) / f"{debug_prefix}_01c_best_detection_with_fill.png"
            cv2.imwrite(str(output_path), vis_best_detection)
            print(f"         ğŸ’¾ Salvat: {output_path.name} (best detection: {best_conf:.1f}%, no flood fill)")
        
        if not text_found or not accepted_boxes:
            if not text_found:
                print(f"         âš ï¸ Nu s-a detectat text ({room_name}) Ã®n plan.")
            else:
                print(f"         âš ï¸ Nu s-a detectat text ({room_name}) cu confidence > 60%.")
            if steps_dir:
                vis_ocr = ocr_image.copy() if ocr_image is not None else cv2.cvtColor(walls_mask, cv2.COLOR_GRAY2BGR)
                cv2.imwrite(str(Path(steps_dir) / f"{debug_prefix}_01_ocr_result.png"), vis_ocr)
                print(f"         ğŸ’¾ Salvat: {debug_prefix}_01_ocr_result.png")
            return result
        
        # Pas 3: VizualizÄƒm textul detectat (toate detecÈ›iile)
        if steps_dir:
            vis_ocr = ocr_image.copy()
            for x, y, width, height, text, conf in text_boxes:
                cv2.rectangle(vis_ocr, (x, y), (x + width, y + height), (0, 255, 0), 2)
                cv2.putText(vis_ocr, f"{text} ({conf:.0f}%)", (x, y - 5), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            cv2.imwrite(str(Path(steps_dir) / f"{debug_prefix}_01_ocr_result.png"), vis_ocr)
            print(f"         ğŸ’¾ Salvat: {debug_prefix}_01_ocr_result.png (text detectat)")
        
        # Pas 3b: VizualizÄƒm DOAR detecÈ›iile acceptate (cele care sunt luate Ã®n calcul)
        if steps_dir and accepted_boxes:
            vis_accepted = ocr_image.copy()
            for x, y, width, height, text, conf in accepted_boxes:
                # DesenÄƒm dreptunghiul cu culoare verde mai intensÄƒ
                cv2.rectangle(vis_accepted, (x, y), (x + width, y + height), (0, 255, 0), 3)
                
                # DesenÄƒm centrul textului (punctul de start pentru flood fill)
                center_x = x + width // 2
                center_y = y + height // 2
                cv2.circle(vis_accepted, (center_x, center_y), 8, (0, 0, 255), -1)  # RoÈ™u pentru centru
                
                # DesenÄƒm textul cu fundal pentru lizibilitate
                label = f"{text} ({conf:.0f}%)"
                font_scale = max(0.6, height / 25.0)
                font_thickness = max(2, int(font_scale * 2))
                (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)
                
                # PoziÈ›ionÄƒm textul deasupra dreptunghiului
                text_y = max(text_height + 5, y - 5)
                text_x = x
                
                # DesenÄƒm fundal pentru text
                cv2.rectangle(vis_accepted, 
                             (text_x, text_y - text_height - baseline), 
                             (text_x + text_width, text_y + baseline), 
                             (0, 255, 0), -1)
                
                # DesenÄƒm textul
                cv2.putText(vis_accepted, label, (text_x, text_y), 
                           cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 0), font_thickness)
            
            cv2.imwrite(str(Path(steps_dir) / f"{debug_prefix}_01b_accepted_detections.png"), vis_accepted)
            print(f"         ğŸ’¾ Salvat: {debug_prefix}_01b_accepted_detections.png ({len(accepted_boxes)} detecÈ›ie/ii acceptatÄƒ/e)")
        
        # Pas 4: Pentru fiecare text detectat, gÄƒsim zona camerei È™i facem flood fill
        print(f"         ğŸ” Pas 2: GÄƒsesc zona camerei È™i fac flood fill...")
        
        # ÃncÄƒrcÄƒm overlay-ul combinat (pereti + original cu 50% transparency)
        overlay_combined = None
        if steps_dir:
            overlay_path = Path(steps_dir) / "02d_walls_closed_overlay.png"
            if overlay_path.exists():
                overlay_combined = cv2.imread(str(overlay_path), cv2.IMREAD_COLOR)
                if overlay_combined is not None:
                    # RedimensionÄƒm dacÄƒ este necesar
                    if overlay_combined.shape[:2] != (h, w):
                        overlay_combined = cv2.resize(overlay_combined, (w, h))
                    print(f"         ğŸ“¸ Folosesc overlay combinat (pereti + original 50%) pentru flood fill")
                else:
                    print(f"         âš ï¸ Nu pot Ã®ncÄƒrca overlay-ul. Folosesc walls_mask simplu.")
        
        # DacÄƒ nu avem overlay, folosim walls_mask simplu
        if overlay_combined is None:
            # CreÄƒm o mascÄƒ pentru spaÈ›iile libere (inversul pereÈ›ilor)
            spaces_mask = cv2.bitwise_not(walls_mask)
        else:
            # Convertim overlay-ul la grayscale
            overlay_gray = cv2.cvtColor(overlay_combined, cv2.COLOR_BGR2GRAY)
            
            # BinarizÄƒm overlay-ul pentru a identifica pereÈ›ii
            # PereÈ›ii Ã®n overlay sunt mai Ã®nchiÈ™i (din combinaÈ›ia de 50% original + 50% walls)
            # Folosim un threshold adaptiv pentru a separa pereÈ›ii de spaÈ›iile libere
            _, overlay_binary = cv2.threshold(overlay_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # InversÄƒm pentru a obÈ›ine spaÈ›iile libere (0 = perete, 255 = spaÈ›iu liber)
            spaces_mask = cv2.bitwise_not(overlay_binary)
            print(f"         ğŸ“Š Overlay binarizat: pereÈ›i identificaÈ›i din combinaÈ›ie")
        
        # ProcesÄƒm DOAR rezultatul cu confidence maxim (dacÄƒ existÄƒ)
        rooms_filled = 0
        if text_boxes:
            # ProcesÄƒm doar primul (È™i singurul) rezultat - cel cu confidence maxim
            box_idx = 0
            x, y, width, height, text, conf = text_boxes[0]
            # Centrul textului
            center_x = x + width // 2
            center_y = y + height // 2
            
            # DeterminÄƒm dacÄƒ este garaj/carport (care are doar 3 pereÈ›i)
            is_garage = room_name.lower() in ['garage', 'garaj', 'carport']
            
            if not use_ocr:
                print(f"         âš ï¸ FÄƒrÄƒ OCR nu pot identifica specific cuvÃ¢ntul. Skip.")
                if steps_dir:
                    vis_fill_attempt = cv2.cvtColor(walls_mask, cv2.COLOR_GRAY2BGR)
                    cv2.circle(vis_fill_attempt, (center_x, center_y), 8, (0, 0, 255), -1)
                    cv2.rectangle(vis_fill_attempt, (x, y), (x + width, y + height), (0, 255, 0), 2)
                    status_text = "âŒ REJECTED: No OCR available"
                    font_scale = 0.8
                    font_thickness = 2
                    (text_width, text_height), baseline = cv2.getTextSize(status_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)
                    cv2.rectangle(vis_fill_attempt, 
                                 (x, y + height + 5), 
                                 (x + text_width + 10, y + height + text_height + baseline + 10), 
                                 (255, 255, 255), -1)
                    cv2.putText(vis_fill_attempt, status_text, (x + 5, y + height + text_height + 5), 
                               cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 255), font_thickness)
                    output_path = Path(steps_dir) / f"{debug_prefix}_02c_flood_fill_attempt_{box_idx + 1}.png"
                    cv2.imwrite(str(output_path), vis_fill_attempt)
                    print(f"         ğŸ’¾ Salvat: {output_path.name} (REJECTED: no OCR)")
            else:
                print(f"         ğŸ¯ GÄƒsit cuvÃ¢ntul '{text}' (confidence {conf:.1f}%) - fac flood fill Ã®n jurul textului...")
                # Facem flood fill DIN JURUL textului, nu din interiorul lui
                
                # CalculÄƒm o zonÄƒ buffer Ã®n jurul textului pentru a gÄƒsi puncte de start
                buffer_size = max(20, int(max(width, height) * 1.5))  # Buffer de ~1.5x dimensiunea textului
                
                # IdentificÄƒm puncte de start Ã®n jurul textului (sus, jos, stÃ¢nga, dreapta, colÈ›uri)
                seed_points = []
                
                # Puncte pe laturile dreptunghiului textului (la distanÈ›Äƒ buffer_size)
                seed_y_top = max(0, y - buffer_size)
                seed_points.append((center_x, seed_y_top))
                seed_y_bottom = min(h - 1, y + height + buffer_size)
                seed_points.append((center_x, seed_y_bottom))
                seed_x_left = max(0, x - buffer_size)
                seed_points.append((seed_x_left, center_y))
                seed_x_right = min(w - 1, x + width + buffer_size)
                seed_points.append((seed_x_right, center_y))
                
                # ColÈ›uri (diagonal)
                seed_points.append((seed_x_left, seed_y_top))
                seed_points.append((seed_x_right, seed_y_top))
                seed_points.append((seed_x_left, seed_y_bottom))
                seed_points.append((seed_x_right, seed_y_bottom))
                
                # VerificÄƒm dacÄƒ existÄƒ cel puÈ›in un seed point valid Ã®n jurul textului (nu verificÄƒm centrul!)
                valid_seed_found = False
                for seed_x, seed_y in seed_points:
                    if 0 <= seed_y < h and 0 <= seed_x < w:
                        if spaces_mask[seed_y, seed_x] == 255:  # SpaÈ›iu liber
                            valid_seed_found = True
                            break
                
                if not valid_seed_found:
                    print(f"         âš ï¸ Nu s-au gÄƒsit seed points valide Ã®n jurul textului '{text}'. Skip.")
                    if steps_dir:
                        vis_fill_attempt = cv2.cvtColor(walls_mask, cv2.COLOR_GRAY2BGR)
                        cv2.circle(vis_fill_attempt, (center_x, center_y), 8, (0, 0, 255), -1)
                        cv2.rectangle(vis_fill_attempt, (x, y), (x + width, y + height), (0, 255, 0), 2)
                        # DesenÄƒm seed points-urile
                        for seed_x, seed_y in seed_points:
                            if 0 <= seed_y < h and 0 <= seed_x < w:
                                if spaces_mask[seed_y, seed_x] == 255:
                                    cv2.circle(vis_fill_attempt, (seed_x, seed_y), 5, (0, 255, 0), -1)
                                else:
                                    cv2.circle(vis_fill_attempt, (seed_x, seed_y), 5, (128, 128, 128), -1)
                        status_text = "âŒ REJECTED: No valid seed points around text"
                        font_scale = 0.8
                        font_thickness = 2
                        (text_width, text_height), baseline = cv2.getTextSize(status_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)
                        cv2.rectangle(vis_fill_attempt, 
                                     (x, y + height + 5), 
                                     (x + text_width + 10, y + height + text_height + baseline + 10), 
                                     (255, 255, 255), -1)
                        cv2.putText(vis_fill_attempt, status_text, (x + 5, y + height + text_height + 5), 
                                   cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 255), font_thickness)
                        output_path = Path(steps_dir) / f"{debug_prefix}_02c_flood_fill_attempt_{box_idx + 1}.png"
                        cv2.imwrite(str(output_path), vis_fill_attempt)
                        print(f"         ğŸ’¾ Salvat: {output_path.name} (REJECTED: no valid seed points)")
                else:
                    # Creez o mascÄƒ care exclude textul (pentru a nu umple interiorul textului)
                    text_mask = np.zeros((h, w), dtype=np.uint8)
                    cv2.rectangle(text_mask, (x, y), (x + width, y + height), 255, -1)
                    
                    # MascÄƒ combinatÄƒ: pereÈ›i + text (nu vrem sÄƒ umplem nici pereÈ›ii, nici textul)
                    exclusion_mask = cv2.bitwise_or(walls_mask, text_mask)
                    
                    flood_mask = np.zeros((h + 2, w + 2), np.uint8)
                    flood_fill_flags = 4  # 4-conectivitate
                    flood_fill_flags |= cv2.FLOODFILL_MASK_ONLY
                    flood_fill_flags |= (255 << 8)  # Fill value
                    
                    # Folosim overlay-ul combinat pentru flood fill
                    if overlay_combined is not None:
                        overlay_for_fill = cv2.cvtColor(overlay_combined, cv2.COLOR_BGR2GRAY)
                        lo_diff = 30
                        up_diff = 30
                        fill_image = overlay_for_fill.copy()
                        print(f"         ğŸ¨ Folosesc overlay combinat pentru flood fill")
                    else:
                        fill_image = spaces_mask.copy()
                        lo_diff = 0
                        up_diff = 0
                        print(f"         âš ï¸ Folosesc spaces_mask simplu (overlay indisponibil)")
                    
                    # Facem flood fill din toate punctele din jurul textului
                    combined_filled_region = np.zeros((h, w), dtype=np.uint8)
                    valid_seeds = 0
                    
                    print(f"         ğŸ” Ãncerc flood fill din {len(seed_points)} puncte Ã®n jurul textului...")
                    
                    for seed_idx, seed_point in enumerate(seed_points):
                        seed_x, seed_y = seed_point
                        
                        if not (0 <= seed_y < h and 0 <= seed_x < w):
                            continue
                        
                        if exclusion_mask[seed_y, seed_x] > 0:
                            continue
                        
                        if spaces_mask[seed_y, seed_x] != 255:
                            continue
                        
                        temp_flood_mask = np.zeros((h + 2, w + 2), np.uint8)
                        try:
                            _, _, _, rect = cv2.floodFill(
                                fill_image.copy(),
                                temp_flood_mask, 
                                seed_point, 
                                128,
                                lo_diff, 
                                up_diff, 
                                flood_fill_flags
                            )
                            
                            temp_filled = (temp_flood_mask[1:h+1, 1:w+1] == 255).astype(np.uint8) * 255
                            temp_filled = cv2.bitwise_and(temp_filled, cv2.bitwise_not(exclusion_mask))
                            combined_filled_region = cv2.bitwise_or(combined_filled_region, temp_filled)
                            valid_seeds += 1
                            
                        except Exception as e:
                            print(f"         âš ï¸ Eroare la flood fill din punct {seed_idx + 1}: {e}")
                            continue
                    
                    print(f"         âœ… Flood fill din {valid_seeds}/{len(seed_points)} puncte valide")
                    
                    filled_region = combined_filled_region
                    
                    # VerificÄƒm cÄƒ nu am umplut peste pereÈ›i
                    overlap_with_walls = np.sum((filled_region > 0) & (walls_mask > 0))
                    if overlap_with_walls > 0:
                        print(f"         âš ï¸ Flood fill a depÄƒÈ™it pereÈ›ii ({overlap_with_walls} pixeli). Corectez...")
                        filled_region = cv2.bitwise_and(filled_region, cv2.bitwise_not(walls_mask))
                    
                    filled_area = np.count_nonzero(filled_region)
                    img_total_area = h * w
                    filled_ratio = filled_area / float(img_total_area)
                    
                    # VerificÄƒm dacÄƒ flood fill-ul este prea mare (probabil a trecut prin pereÈ›i È™i iese din plan)
                    # Pentru terasÄƒ, dacÄƒ umple > 50% din imagine, probabil a trecut prin pereÈ›i
                    if not is_garage and filled_ratio > 0.50:
                        print(f"         âš ï¸ Flood fill prea mare ({filled_area}px, {filled_ratio*100:.1f}% din imagine). Probabil a trecut prin pereÈ›i È™i iese din plan. Skip.")
                        if steps_dir:
                            # SalvÄƒm imagine de debug pentru tentativa respinsÄƒ
                            vis_fill_attempt = cv2.cvtColor(walls_mask, cv2.COLOR_GRAY2BGR)
                            cv2.circle(vis_fill_attempt, (center_x, center_y), 8, (0, 0, 255), -1)
                            cv2.rectangle(vis_fill_attempt, (x, y), (x + width, y + height), (0, 255, 0), 2)
                            filled_colored = np.zeros_like(vis_fill_attempt)
                            filled_colored[filled_region > 0] = [0, 255, 255]  # Galben
                            vis_fill_attempt = cv2.addWeighted(vis_fill_attempt, 0.7, filled_colored, 0.3, 0)
                            status_text = f"âŒ REJECTED: Area too large ({filled_area}px, {filled_ratio*100:.1f}%)"
                            font_scale = 0.8
                            font_thickness = 2
                            (text_width, text_height), baseline = cv2.getTextSize(status_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)
                            cv2.rectangle(vis_fill_attempt, 
                                         (x, y + height + 5), 
                                         (x + text_width + 10, y + height + text_height + baseline + 10), 
                                         (255, 255, 255), -1)
                            cv2.putText(vis_fill_attempt, status_text, (x + 5, y + height + text_height + 5), 
                                       cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 255), font_thickness)
                            output_path = Path(steps_dir) / f"{debug_prefix}_02c_flood_fill_attempt_{box_idx + 1}.png"
                            cv2.imwrite(str(output_path), vis_fill_attempt)
                            print(f"         ğŸ’¾ Salvat: {output_path.name} (REJECTED: area too large)")
                        # ActualizÄƒm È™i poza cu best detection
                        if steps_dir and best_box_all:
                            best_x, best_y, best_width, best_height, best_text, best_conf = best_box_all
                            best_center_x = best_x + best_width // 2
                            best_center_y = best_y + best_height // 2
                            vis_best_detection = ocr_image.copy() if ocr_image is not None else cv2.cvtColor(walls_mask, cv2.COLOR_GRAY2BGR)
                            detection_color = (0, 165, 255)  # Portocaliu pentru respins
                            status_label = f"âŒ REJECTED ({best_conf:.1f}%)"
                            cv2.rectangle(vis_best_detection, (best_x, best_y), (best_x + best_width, best_y + best_height), detection_color, 3)
                            cv2.circle(vis_best_detection, (best_center_x, best_center_y), 8, (0, 0, 255), -1)
                            filled_colored = np.zeros_like(vis_best_detection)
                            filled_colored[filled_region > 0] = [0, 255, 255]  # Galben
                            vis_best_detection = cv2.addWeighted(vis_best_detection, 0.7, filled_colored, 0.3, 0)
                            label_text = f"{best_text} - {status_label} | Flood Fill: {filled_area}px ({filled_ratio*100:.1f}%) - TOO LARGE"
                            font_scale = max(0.7, best_height / 30.0)
                            font_thickness = max(2, int(font_scale * 2))
                            (text_width, text_height), baseline = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)
                            text_y = max(text_height + 5, best_y - 5)
                            text_x = best_x
                            cv2.rectangle(vis_best_detection, 
                                         (text_x, text_y - text_height - baseline), 
                                         (text_x + text_width + 10, text_y + baseline), 
                                         (255, 255, 255), -1)
                            cv2.putText(vis_best_detection, label_text, (text_x + 5, text_y), 
                                       cv2.FONT_HERSHEY_SIMPLEX, font_scale, detection_color, font_thickness)
                            output_path = Path(steps_dir) / f"{debug_prefix}_01c_best_detection_with_fill.png"
                            cv2.imwrite(str(output_path), vis_best_detection)
                            print(f"         ğŸ’¾ Salvat: {output_path.name} (best detection: {best_conf:.1f}%, fill: {filled_area}px - REJECTED: too large)")
                        return result
                    
                    # Pentru garaj/carport (care are doar 3 pereÈ›i), folosim o abordare geometricÄƒ
                    if is_garage:
                        print(f"         ğŸš— Detectat garaj/carport - calculez distanÈ›ele pÃ¢nÄƒ la pereÈ›i...")
                        
                        # ÃncÄƒrcÄƒm imaginile pentru cÄƒutare (mai Ã®ntÃ¢i doar pereÈ›ii, apoi overlay cu ghost image)
                        walls_image = None  # Doar pereÈ›ii detectaÈ›i (02_ai_walls_closed.png)
                        overlay_image = None  # PereÈ›ii + ghost image (02d_walls_closed_overlay.png)
                        
                        if steps_dir:
                            # 1. ÃncÄƒrcÄƒm imaginea cu doar pereÈ›ii detectaÈ›i
                            walls_image_path = Path(steps_dir) / "02_ai_walls_closed.png"
                            if walls_image_path.exists():
                                walls_image = cv2.imread(str(walls_image_path), cv2.IMREAD_GRAYSCALE)
                                if walls_image is not None:
                                    if walls_image.shape[:2] != (h, w):
                                        walls_image = cv2.resize(walls_image, (w, h))
                                    print(f"         ğŸ“¸ Am Ã®ncÄƒrcat 02_ai_walls_closed.png (doar pereÈ›ii detectaÈ›i)")
                            
                            # 2. ÃncÄƒrcÄƒm overlay-ul cu ghost image (dacÄƒ existÄƒ)
                            overlay_path = Path(steps_dir) / "02d_walls_closed_overlay.png"
                            if overlay_path.exists():
                                overlay_bgr = cv2.imread(str(overlay_path), cv2.IMREAD_COLOR)
                                if overlay_bgr is not None:
                                    if overlay_bgr.shape[:2] != (h, w):
                                        overlay_bgr = cv2.resize(overlay_bgr, (w, h))
                                    # Convertim la grayscale pentru analizÄƒ
                                    overlay_image = cv2.cvtColor(overlay_bgr, cv2.COLOR_BGR2GRAY)
                                    print(f"         ğŸ“¸ Am Ã®ncÄƒrcat 02d_walls_closed_overlay.png (pereÈ›ii + ghost image)")
                        
                        # Fallback: folosim walls_mask dacÄƒ nu am putut Ã®ncÄƒrca niciuna
                        if walls_image is None:
                            walls_image = walls_mask.copy()
                            print(f"         âš ï¸ Folosesc walls_mask ca fallback pentru walls_image")
                        
                        # Centrul textului
                        center_x = x + width // 2
                        center_y = y + height // 2
                        
                        # CalculÄƒm distanÈ›ele pÃ¢nÄƒ la primul perete Ã®n toate direcÈ›iile
                        # Ãn walls_image, pereÈ›ii sunt albi (255) È™i spaÈ›iile libere sunt negre (0)
                        wall_threshold = 128  # Valori >= 128 = perete
                        
                        distances = {}
                        directions = {
                            'top': (0, -1),      # Sus
                            'bottom': (0, 1),    # Jos
                            'left': (-1, 0),     # StÃ¢nga
                            'right': (1, 0)      # Dreapta
                        }
                        
                        max_search_distance = min(w, h) // 2  # CÄƒutÄƒm pÃ¢nÄƒ la jumÄƒtate din imagine
                        
                        for dir_name, (dx, dy) in directions.items():
                            distance = 0
                            found_wall = False
                            
                            for step in range(1, max_search_distance):
                                check_x = center_x + dx * step
                                check_y = center_y + dy * step
                                
                                if not (0 <= check_y < h and 0 <= check_x < w):
                                    break
                                
                                # VerificÄƒm dacÄƒ am gÄƒsit un perete (valoare >= threshold = perete)
                                pixel_value = walls_image[check_y, check_x]
                                if pixel_value >= wall_threshold:
                                    distance = step
                                    found_wall = True
                                    break
                            
                            if found_wall:
                                distances[dir_name] = distance
                                print(f"         ğŸ“ DistanÈ›Äƒ {dir_name}: {distance}px")
                            else:
                                distances[dir_name] = max_search_distance  # Nu am gÄƒsit perete
                                print(f"         âš ï¸ Nu am gÄƒsit perete Ã®n direcÈ›ia {dir_name}")
                        
                        # AnalizÄƒm distanÈ›ele pentru a identifica pereÈ›ii paraleli È™i cel lipsÄƒ
                        dist_values = list(distances.values())
                        dist_sorted = sorted(set(dist_values))
                        
                        print(f"         ğŸ“Š DistanÈ›e unice: {dist_sorted}")
                        
                        # IdentificÄƒm distanÈ›a care este mult diferitÄƒ (probabil unde lipseÈ™te peretele)
                        if len(dist_sorted) >= 2:
                            # GÄƒsim distanÈ›a care este cel mai diferitÄƒ
                            # ComparÄƒm fiecare distanÈ›Äƒ cu celelalte
                            max_diff = 0
                            outlier_dir = None
                            outlier_value = None
                            
                            for dir_name, dist in distances.items():
                                # CalculÄƒm diferenÈ›a medie faÈ›Äƒ de celelalte distanÈ›e
                                other_dists = [d for d_name, d in distances.items() if d_name != dir_name]
                                avg_diff = sum(abs(dist - d) for d in other_dists) / len(other_dists) if other_dists else 0
                                
                                if avg_diff > max_diff:
                                    max_diff = avg_diff
                                    outlier_dir = dir_name
                                    outlier_value = dist
                            
                            # DacÄƒ am gÄƒsit o distanÈ›Äƒ outlier, cÄƒutÄƒm artefacte (2 linii mici) pentru al 4-lea perete
                            # CÄƒutÄƒm Ã®n direcÈ›ia opusÄƒ celui de-al 3-lea perete (direcÈ›ia outlier_dir)
                            if outlier_dir and max_diff > 50:  # Prag pentru a considera cÄƒ e diferitÄƒ
                                print(f"         ğŸ” DistanÈ›a outlier: {outlier_dir} = {outlier_value}px (diferenÈ›Äƒ medie: {max_diff:.1f}px)")
                                print(f"         ğŸ” Caut artefacte (2 linii mici) pentru peretele lipsÄƒ Ã®n direcÈ›ia {outlier_dir} (opus celui de-al 3-lea perete)...")
                                
                                # GÄƒsim direcÈ›ia paralelÄƒ (al 3-lea perete - top-bottom sau left-right)
                                if outlier_dir in ['top', 'bottom']:
                                    # Peretele lipsÄƒ este sus sau jos, al 3-lea perete este cel paralel
                                    parallel_dir = 'bottom' if outlier_dir == 'top' else 'top'
                                    parallel_value = distances[parallel_dir]
                                    
                                    # Pornim de dupÄƒ textul gÄƒsit, Ã®n direcÈ›ia opusÄƒ celui de-al 3-lea perete (outlier_dir)
                                    if outlier_dir == 'top':
                                        # CÄƒutÄƒm sus, pornind de dupÄƒ text (center_y) Ã®n direcÈ›ia opusÄƒ celui de-al 3-lea perete (bottom)
                                        search_start_y = center_y + parallel_value  # DupÄƒ text, Ã®n direcÈ›ia celui de-al 3-lea perete
                                        search_end_y = center_y - outlier_value  # PÃ¢nÄƒ la distanÈ›a outlier (direcÈ›ia opusÄƒ)
                                    else:  # bottom
                                        # CÄƒutÄƒm jos, pornind de dupÄƒ text (center_y) Ã®n direcÈ›ia opusÄƒ celui de-al 3-lea perete (top)
                                        search_start_y = center_y - parallel_value  # DupÄƒ text, Ã®n direcÈ›ia celui de-al 3-lea perete
                                        search_end_y = center_y + outlier_value  # PÃ¢nÄƒ la distanÈ›a outlier (direcÈ›ia opusÄƒ)
                                    
                                    # CÄƒutÄƒm 2 linii mici verticale (artefacte) Ã®ntre left_x È™i right_x
                                    left_x = center_x - distances['left']
                                    right_x = center_x + distances['right']
                                    
                                    # CÄƒutÄƒm linii mici verticale (artefacte de perete)
                                    artifact_found = False
                                    artifact_y = None
                                    
                                    # Parcurgem zona Ã®ntre search_start_y È™i search_end_y
                                    search_range = range(min(search_start_y, search_end_y), max(search_start_y, search_end_y))
                                    
                                    # CÄƒutÄƒm linii verticale mici (2-5 pixeli Ã®nÄƒlÈ›ime) care sunt conectate la pereÈ›ii paraleli
                                    min_line_length = 2
                                    max_line_length = 5
                                    
                                    # METODA 1: CÄƒutÄƒm Ã®n walls_image (doar pereÈ›ii detectaÈ›i)
                                    print(f"         ğŸ” Metoda 1: Caut Ã®n 02_ai_walls_closed.png (doar pereÈ›ii detectaÈ›i)...")
                                    for check_y in search_range:
                                        if not (0 <= check_y < h):
                                            continue
                                        
                                        # VerificÄƒm dacÄƒ existÄƒ o linie verticalÄƒ micÄƒ la aceastÄƒ poziÈ›ie
                                        line_pixels = []
                                        for check_x in range(left_x, right_x):
                                            if 0 <= check_x < w and walls_image[check_y, check_x] >= wall_threshold:
                                                line_pixels.append(check_x)
                                        
                                        # VerificÄƒm dacÄƒ avem o linie continuÄƒ de lungime Ã®ntre min_line_length È™i max_line_length
                                        if len(line_pixels) >= min_line_length and len(line_pixels) <= max_line_length:
                                            # VerificÄƒm dacÄƒ linia este conectatÄƒ la pereÈ›ii paraleli (left sau right)
                                            connected_left = False
                                            if left_x > 0:
                                                for conn_y in range(max(0, check_y - 2), min(h, check_y + 3)):
                                                    if walls_image[conn_y, left_x - 1] >= wall_threshold:
                                                        connected_left = True
                                                        break
                                            
                                            # VerificÄƒm conexiunea la dreapta
                                            connected_right = False
                                            if right_x < w - 1:
                                                for conn_y in range(max(0, check_y - 2), min(h, check_y + 3)):
                                                    if walls_image[conn_y, right_x + 1] >= wall_threshold:
                                                        connected_right = True
                                                        break
                                            
                                            # DacÄƒ linia este conectatÄƒ la ambele pereÈ›i paraleli, am gÄƒsit artefactul
                                            if connected_left and connected_right:
                                                artifact_found = True
                                                artifact_y = check_y
                                                print(f"         âœ… GÄƒsit artefact Ã®n walls_image (linie micÄƒ) la y={artifact_y}, conectat la ambele pereÈ›i paraleli")
                                                break
                                    
                                    # METODA 2: DacÄƒ nu am gÄƒsit Ã®n walls_image, cÄƒutÄƒm Ã®n overlay_image (pereÈ›ii + ghost image)
                                    if not artifact_found and overlay_image is not None:
                                        print(f"         ğŸ” Metoda 2: Caut Ã®n 02d_walls_closed_overlay.png (pereÈ›ii + ghost image)...")
                                        # Folosim un threshold mai mic pentru overlay (poate avea valori intermediare)
                                        overlay_threshold = 100  # Threshold mai mic pentru overlay
                                        
                                        for check_y in search_range:
                                            if not (0 <= check_y < h):
                                                continue
                                            
                                            # VerificÄƒm dacÄƒ existÄƒ o linie verticalÄƒ micÄƒ la aceastÄƒ poziÈ›ie
                                            line_pixels = []
                                            for check_x in range(left_x, right_x):
                                                if 0 <= check_x < w and overlay_image[check_y, check_x] >= overlay_threshold:
                                                    line_pixels.append(check_x)
                                            
                                            # VerificÄƒm dacÄƒ avem o linie continuÄƒ de lungime Ã®ntre min_line_length È™i max_line_length
                                            if len(line_pixels) >= min_line_length and len(line_pixels) <= max_line_length:
                                                # VerificÄƒm dacÄƒ linia este conectatÄƒ la pereÈ›ii paraleli (left sau right)
                                                connected_left = False
                                                if left_x > 0:
                                                    for conn_y in range(max(0, check_y - 2), min(h, check_y + 3)):
                                                        if overlay_image[conn_y, left_x - 1] >= overlay_threshold:
                                                            connected_left = True
                                                            break
                                                
                                                # VerificÄƒm conexiunea la dreapta
                                                connected_right = False
                                                if right_x < w - 1:
                                                    for conn_y in range(max(0, check_y - 2), min(h, check_y + 3)):
                                                        if overlay_image[conn_y, right_x + 1] >= overlay_threshold:
                                                            connected_right = True
                                                            break
                                                
                                                # DacÄƒ linia este conectatÄƒ la ambele pereÈ›i paraleli, am gÄƒsit artefactul
                                                if connected_left and connected_right:
                                                    artifact_found = True
                                                    artifact_y = check_y
                                                    print(f"         âœ… GÄƒsit artefact Ã®n overlay_image (linie micÄƒ) la y={artifact_y}, conectat la ambele pereÈ›i paraleli")
                                                    break
                                    
                                    # ActualizÄƒm distanÈ›a sau aplicÄƒm fallback
                                    if artifact_found and artifact_y is not None:
                                        # ActualizÄƒm distanÈ›a outlier cu poziÈ›ia artefactului
                                        if outlier_dir == 'top':
                                            distances[outlier_dir] = center_y - artifact_y
                                        else:  # bottom
                                            distances[outlier_dir] = artifact_y - center_y
                                        print(f"         âœ… Actualizat {outlier_dir} cu distanÈ›a cÄƒtre artefact: {distances[outlier_dir]}px")
                                    else:
                                        # FALLBACK: DacÄƒ nu am gÄƒsit artefacte, folosim distanÈ›a paralelÄƒ
                                        replacement_value = parallel_value
                                        distances[outlier_dir] = replacement_value
                                        print(f"         âš ï¸ Nu am gÄƒsit artefacte Ã®n niciuna dintre imagini, folosesc fallback (distanÈ›a paralelÄƒ): {replacement_value}px")
                                else:
                                    # Peretele lipsÄƒ este stÃ¢nga sau dreapta, al 3-lea perete este cel paralel
                                    parallel_dir = 'right' if outlier_dir == 'left' else 'left'
                                    parallel_value = distances[parallel_dir]
                                    
                                    # Pornim de dupÄƒ textul gÄƒsit, Ã®n direcÈ›ia opusÄƒ celui de-al 3-lea perete (outlier_dir)
                                    if outlier_dir == 'left':
                                        # CÄƒutÄƒm stÃ¢nga, pornind de dupÄƒ text (center_x) Ã®n direcÈ›ia opusÄƒ celui de-al 3-lea perete (right)
                                        search_start_x = center_x + parallel_value  # DupÄƒ text, Ã®n direcÈ›ia celui de-al 3-lea perete
                                        search_end_x = center_x - outlier_value  # PÃ¢nÄƒ la distanÈ›a outlier (direcÈ›ia opusÄƒ)
                                    else:  # right
                                        # CÄƒutÄƒm dreapta, pornind de dupÄƒ text (center_x) Ã®n direcÈ›ia opusÄƒ celui de-al 3-lea perete (left)
                                        search_start_x = center_x - parallel_value  # DupÄƒ text, Ã®n direcÈ›ia celui de-al 3-lea perete
                                        search_end_x = center_x + outlier_value  # PÃ¢nÄƒ la distanÈ›a outlier (direcÈ›ia opusÄƒ)
                                    
                                    # CÄƒutÄƒm 2 linii mici orizontale (artefacte) Ã®ntre top_y È™i bottom_y
                                    top_y = center_y - distances['top']
                                    bottom_y = center_y + distances['bottom']
                                    
                                    # CÄƒutÄƒm linii mici orizontale (artefacte de perete)
                                    artifact_found = False
                                    artifact_x = None
                                    
                                    # Parcurgem zona Ã®ntre search_start_x È™i search_end_x
                                    search_range = range(min(search_start_x, search_end_x), max(search_start_x, search_end_x))
                                    
                                    # CÄƒutÄƒm linii orizontale mici (2-5 pixeli lungime) care sunt conectate la pereÈ›ii paraleli
                                    min_line_length = 2
                                    max_line_length = 5
                                    
                                    # METODA 1: CÄƒutÄƒm Ã®n walls_image (doar pereÈ›ii detectaÈ›i)
                                    print(f"         ğŸ” Metoda 1: Caut Ã®n 02_ai_walls_closed.png (doar pereÈ›ii detectaÈ›i)...")
                                    for check_x in search_range:
                                        if not (0 <= check_x < w):
                                            continue
                                        
                                        # VerificÄƒm dacÄƒ existÄƒ o linie orizontalÄƒ micÄƒ la aceastÄƒ poziÈ›ie
                                        line_pixels = []
                                        for check_y in range(top_y, bottom_y):
                                            if 0 <= check_y < h and walls_image[check_y, check_x] >= wall_threshold:
                                                line_pixels.append(check_y)
                                        
                                        # VerificÄƒm dacÄƒ avem o linie continuÄƒ de lungime Ã®ntre min_line_length È™i max_line_length
                                        if len(line_pixels) >= min_line_length and len(line_pixels) <= max_line_length:
                                            # VerificÄƒm dacÄƒ linia este conectatÄƒ la pereÈ›ii paraleli (top sau bottom)
                                            # VerificÄƒm conexiunea la sus
                                            connected_top = False
                                            if top_y > 0:
                                                for conn_x in range(max(0, check_x - 2), min(w, check_x + 3)):
                                                    if walls_image[top_y - 1, conn_x] >= wall_threshold:
                                                        connected_top = True
                                                        break
                                            
                                            # VerificÄƒm conexiunea la jos
                                            connected_bottom = False
                                            if bottom_y < h - 1:
                                                for conn_x in range(max(0, check_x - 2), min(w, check_x + 3)):
                                                    if walls_image[bottom_y + 1, conn_x] >= wall_threshold:
                                                        connected_bottom = True
                                                        break
                                            
                                            # DacÄƒ linia este conectatÄƒ la ambele pereÈ›i paraleli, am gÄƒsit artefactul
                                            if connected_top and connected_bottom:
                                                artifact_found = True
                                                artifact_x = check_x
                                                print(f"         âœ… GÄƒsit artefact Ã®n walls_image (linie micÄƒ) la x={artifact_x}, conectat la ambele pereÈ›i paraleli")
                                                break
                                    
                                    # METODA 2: DacÄƒ nu am gÄƒsit Ã®n walls_image, cÄƒutÄƒm Ã®n overlay_image (pereÈ›ii + ghost image)
                                    if not artifact_found and overlay_image is not None:
                                        print(f"         ğŸ” Metoda 2: Caut Ã®n 02d_walls_closed_overlay.png (pereÈ›ii + ghost image)...")
                                        # Folosim un threshold mai mic pentru overlay (poate avea valori intermediare)
                                        overlay_threshold = 100  # Threshold mai mic pentru overlay
                                        
                                        for check_x in search_range:
                                            if not (0 <= check_x < w):
                                                continue
                                            
                                            # VerificÄƒm dacÄƒ existÄƒ o linie orizontalÄƒ micÄƒ la aceastÄƒ poziÈ›ie
                                            line_pixels = []
                                            for check_y in range(top_y, bottom_y):
                                                if 0 <= check_y < h and overlay_image[check_y, check_x] >= overlay_threshold:
                                                    line_pixels.append(check_y)
                                            
                                            # VerificÄƒm dacÄƒ avem o linie continuÄƒ de lungime Ã®ntre min_line_length È™i max_line_length
                                            if len(line_pixels) >= min_line_length and len(line_pixels) <= max_line_length:
                                                # VerificÄƒm dacÄƒ linia este conectatÄƒ la pereÈ›ii paraleli (top sau bottom)
                                                # VerificÄƒm conexiunea la sus
                                                connected_top = False
                                                if top_y > 0:
                                                    for conn_x in range(max(0, check_x - 2), min(w, check_x + 3)):
                                                        if overlay_image[top_y - 1, conn_x] >= overlay_threshold:
                                                            connected_top = True
                                                            break
                                                
                                                # VerificÄƒm conexiunea la jos
                                                connected_bottom = False
                                                if bottom_y < h - 1:
                                                    for conn_x in range(max(0, check_x - 2), min(w, check_x + 3)):
                                                        if overlay_image[bottom_y + 1, conn_x] >= overlay_threshold:
                                                            connected_bottom = True
                                                            break
                                                
                                                # DacÄƒ linia este conectatÄƒ la ambele pereÈ›i paraleli, am gÄƒsit artefactul
                                                if connected_top and connected_bottom:
                                                    artifact_found = True
                                                    artifact_x = check_x
                                                    print(f"         âœ… GÄƒsit artefact Ã®n overlay_image (linie micÄƒ) la x={artifact_x}, conectat la ambele pereÈ›i paraleli")
                                                    break
                                    
                                    # ActualizÄƒm distanÈ›a sau aplicÄƒm fallback
                                    if artifact_found and artifact_x is not None:
                                        # ActualizÄƒm distanÈ›a outlier cu poziÈ›ia artefactului
                                        if outlier_dir == 'left':
                                            distances[outlier_dir] = center_x - artifact_x
                                        else:  # right
                                            distances[outlier_dir] = artifact_x - center_x
                                        print(f"         âœ… Actualizat {outlier_dir} cu distanÈ›a cÄƒtre artefact: {distances[outlier_dir]}px")
                                    else:
                                        # FALLBACK: DacÄƒ nu am gÄƒsit artefacte, folosim distanÈ›a paralelÄƒ
                                        replacement_value = parallel_value
                                        distances[outlier_dir] = replacement_value
                                        print(f"         âš ï¸ Nu am gÄƒsit artefacte Ã®n niciuna dintre imagini, folosesc fallback (distanÈ›a paralelÄƒ): {replacement_value}px")
                            
                            # Acum desenÄƒm forma geometricÄƒ bazatÄƒ pe distanÈ›ele corectate
                            print(f"         ğŸ¨ Desenez forma geometricÄƒ pentru garaj...")
                            
                            # CalculÄƒm colÈ›urile dreptunghiului
                            top_y = center_y - distances['top']
                            bottom_y = center_y + distances['bottom']
                            left_x = center_x - distances['left']
                            right_x = center_x + distances['right']
                            
                            # CreÄƒm o mascÄƒ pentru forma geometricÄƒ
                            geometric_mask = np.zeros((h, w), dtype=np.uint8)
                            cv2.rectangle(geometric_mask, (left_x, top_y), (right_x, bottom_y), 255, -1)
                            
                            # Ãnlocuim zona umplutÄƒ cu forma geometricÄƒ
                            filled_region = geometric_mask
                            filled_area = np.count_nonzero(filled_region)
                            
                            print(f"         âœ… FormÄƒ geometricÄƒ: ({left_x}, {top_y}) -> ({right_x}, {bottom_y}), aria: {filled_area}px")
                            
                            # DesenÄƒm peretele lipsÄƒ aproximat
                            if outlier_dir == 'top':
                                wall_thickness = max(3, int(min(w, h) * 0.003))
                                cv2.line(result, (left_x, top_y), (right_x, top_y), 255, wall_thickness)
                                print(f"         âœ… Aproximat perete de sus: linie la y={top_y}")
                            elif outlier_dir == 'bottom':
                                wall_thickness = max(3, int(min(w, h) * 0.003))
                                cv2.line(result, (left_x, bottom_y), (right_x, bottom_y), 255, wall_thickness)
                                print(f"         âœ… Aproximat perete de jos: linie la y={bottom_y}")
                            elif outlier_dir == 'left':
                                wall_thickness = max(3, int(min(w, h) * 0.003))
                                cv2.line(result, (left_x, top_y), (left_x, bottom_y), 255, wall_thickness)
                                print(f"         âœ… Aproximat perete din stÃ¢nga: linie la x={left_x}")
                            elif outlier_dir == 'right':
                                wall_thickness = max(3, int(min(w, h) * 0.003))
                                cv2.line(result, (right_x, top_y), (right_x, bottom_y), 255, wall_thickness)
                                print(f"         âœ… Aproximat perete din dreapta: linie la x={right_x}")
                            
                            # ActualizÄƒm walls_mask cu peretele aproximat
                            walls_mask = result.copy()
                        else:
                            print(f"         âš ï¸ Nu am gÄƒsit suficiente pereÈ›i pentru analizÄƒ geometricÄƒ")
                    
                    # VerificÄƒm cÄƒ zona umplutÄƒ este suficient de mare
                    if not is_garage and filled_area < 1000:
                        print(f"         âš ï¸ Zona detectatÄƒ prea micÄƒ ({filled_area} pixeli). Skip.")
                        # ContinuÄƒm cu urmÄƒtorul text_box
                        if steps_dir:
                            # SalvÄƒm imagine de debug pentru tentativa respinsÄƒ
                            vis_fill_attempt = cv2.cvtColor(walls_mask, cv2.COLOR_GRAY2BGR)
                            cv2.circle(vis_fill_attempt, (center_x, center_y), 8, (0, 0, 255), -1)
                            cv2.rectangle(vis_fill_attempt, (x, y), (x + width, y + height), (0, 255, 0), 2)
                            status_text = f"âŒ REJECTED: Area too small ({filled_area}px)"
                            font_scale = 0.8
                            font_thickness = 2
                            (text_width, text_height), baseline = cv2.getTextSize(status_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)
                            cv2.rectangle(vis_fill_attempt, 
                                         (x, y + height + 5), 
                                         (x + text_width + 10, y + height + text_height + baseline + 10), 
                                         (255, 255, 255), -1)
                            cv2.putText(vis_fill_attempt, status_text, (x + 5, y + height + text_height + 5), 
                                       cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 255), font_thickness)
                            output_path = Path(steps_dir) / f"{debug_prefix}_02c_flood_fill_attempt_{box_idx + 1}.png"
                            cv2.imwrite(str(output_path), vis_fill_attempt)
                            print(f"         ğŸ’¾ Salvat: {output_path.name} (REJECTED: area too small)")
                        # Nu continuÄƒm - procesÄƒm doar primul rezultat, deci returnÄƒm
                        return result
                    
                    if is_garage and filled_area < 1000:
                        print(f"         âš ï¸ Zona geometricÄƒ prea micÄƒ ({filled_area} pixeli). Skip.")
                        # Nu continuÄƒm - procesÄƒm doar primul rezultat, deci returnÄƒm
                        if steps_dir:
                            # SalvÄƒm imagine de debug pentru tentativa respinsÄƒ
                            vis_fill_attempt = cv2.cvtColor(walls_mask, cv2.COLOR_GRAY2BGR)
                            cv2.circle(vis_fill_attempt, (center_x, center_y), 8, (0, 0, 255), -1)
                            cv2.rectangle(vis_fill_attempt, (x, y), (x + width, y + height), (0, 255, 0), 2)
                            status_text = f"âŒ REJECTED: Geometric area too small ({filled_area}px)"
                            font_scale = 0.8
                            font_thickness = 2
                            (text_width, text_height), baseline = cv2.getTextSize(status_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)
                            cv2.rectangle(vis_fill_attempt, 
                                         (x, y + height + 5), 
                                         (x + text_width + 10, y + height + text_height + baseline + 10), 
                                         (255, 255, 255), -1)
                            cv2.putText(vis_fill_attempt, status_text, (x + 5, y + height + text_height + 5), 
                                       cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 255), font_thickness)
                            output_path = Path(steps_dir) / f"{debug_prefix}_02c_flood_fill_attempt_{box_idx + 1}.png"
                            cv2.imwrite(str(output_path), vis_fill_attempt)
                            print(f"         ğŸ’¾ Salvat: {output_path.name} (REJECTED: geometric area too small)")
                        # Nu continuÄƒm - procesÄƒm doar primul rezultat, deci returnÄƒm
                        return result
                    
                    # Pentru garaj, verificÄƒm cÄƒ zona este suficient de mare
                    if not is_garage and filled_area < 1000:
                        print(f"         ğŸš— Detectat garaj/carport - verific pereÈ›ii È™i corectez zona umplutÄƒ (ar trebui sÄƒ fie 3, nu 4)...")
                        
                        # GÄƒsim conturul zonei umplute
                        contours_temp, _ = cv2.findContours(filled_region, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                        if contours_temp:
                            largest_contour = max(contours_temp, key=cv2.contourArea)
                            
                            # ObÈ›inem bounding box-ul zonei umplute
                            bbox_x, bbox_y, bbox_w, bbox_h = cv2.boundingRect(largest_contour)
                            
                            # Extindem zona umplutÄƒ pentru a cÄƒuta pereÈ›ii Ã®n jur
                            expanded_region = cv2.dilate(filled_region, np.ones((30, 30), np.uint8), iterations=1)
                            
                            # VerificÄƒm marginile zonei umplute pentru a vedea unde sunt pereÈ›ii
                            # Folosim bounding box-ul pentru a verifica pereÈ›ii Ã®n jur
                            margin = 30
                            top_wall_check = walls_mask[max(0, bbox_y - margin):bbox_y + bbox_h//4, bbox_x:bbox_x + bbox_w] if bbox_y >= margin else np.array([])
                            bottom_wall_check = walls_mask[bbox_y + 3*bbox_h//4:min(h, bbox_y + bbox_h + margin), bbox_x:bbox_x + bbox_w] if bbox_y + bbox_h + margin <= h else np.array([])
                            left_wall_check = walls_mask[bbox_y:bbox_y + bbox_h, max(0, bbox_x - margin):bbox_x + bbox_w//4] if bbox_x >= margin else np.array([])
                            right_wall_check = walls_mask[bbox_y:bbox_y + bbox_h, bbox_x + 3*bbox_w//4:min(w, bbox_x + bbox_w + margin)] if bbox_x + bbox_w + margin <= w else np.array([])
                            
                            walls_detected = []
                            if top_wall_check.size > 0 and np.any(top_wall_check > 0):
                                walls_detected.append('top')
                            if bottom_wall_check.size > 0 and np.any(bottom_wall_check > 0):
                                walls_detected.append('bottom')
                            if left_wall_check.size > 0 and np.any(left_wall_check > 0):
                                walls_detected.append('left')
                            if right_wall_check.size > 0 and np.any(right_wall_check > 0):
                                walls_detected.append('right')
                            
                            print(f"         ğŸ“ PereÈ›i detectaÈ›i: {len(walls_detected)} ({', '.join(walls_detected)})")
                            
                            # DacÄƒ avem exact 3 pereÈ›i, "tÄƒiem" zona umplutÄƒ la marginea unde lipseÈ™te peretele
                            if len(walls_detected) == 3:
                                print(f"         âœ… Confirmat: garaj/carport cu 3 pereÈ›i. Corectez zona umplutÄƒ...")
                                
                                # DeterminÄƒm care perete lipseÈ™te
                                all_sides = ['top', 'bottom', 'left', 'right']
                                missing_wall = [side for side in all_sides if side not in walls_detected][0]
                                
                                # AnalizÄƒm forma zonei umplute pentru a determina unde sÄƒ o "tÄƒiem"
                                contour_points = largest_contour.reshape(-1, 2)
                                
                                # CreÄƒm o mascÄƒ pentru a "tÄƒia" zona dincolo de marginea lipsÄƒ
                                cut_mask = np.ones((h, w), dtype=np.uint8) * 255
                                
                                if missing_wall == 'top':
                                    # Peretele de sus lipseÈ™te - "tÄƒiem" zona deasupra
                                    # GÄƒsim punctele de pe marginea de sus a zonei (unde se opresc cei 3 pereÈ›i)
                                    top_points = contour_points[contour_points[:, 1] <= bbox_y + bbox_h//3]
                                    if len(top_points) > 0:
                                        # GÄƒsim linia care conecteazÄƒ punctele extreme de sus
                                        min_x = int(np.min(top_points[:, 0]))
                                        max_x = int(np.max(top_points[:, 0]))
                                        # Folosim y-ul minim al punctelor de sus ca limitÄƒ
                                        cut_y = int(np.min(top_points[:, 1]))
                                        # "TÄƒiem" tot ce este deasupra acestei linii
                                        cut_mask[:cut_y, :] = 0
                                        print(f"         âœ‚ï¸ TÄƒiat zona deasupra y={cut_y}")
                                elif missing_wall == 'bottom':
                                    # Peretele de jos lipseÈ™te - "tÄƒiem" zona de jos
                                    bottom_points = contour_points[contour_points[:, 1] >= bbox_y + 2*bbox_h//3]
                                    if len(bottom_points) > 0:
                                        cut_y = int(np.max(bottom_points[:, 1]))
                                        cut_mask[cut_y:, :] = 0
                                        print(f"         âœ‚ï¸ TÄƒiat zona de jos y={cut_y}")
                                elif missing_wall == 'left':
                                    # Peretele din stÃ¢nga lipseÈ™te - "tÄƒiem" zona din stÃ¢nga
                                    left_points = contour_points[contour_points[:, 0] <= bbox_x + bbox_w//3]
                                    if len(left_points) > 0:
                                        cut_x = int(np.min(left_points[:, 0]))
                                        cut_mask[:, :cut_x] = 0
                                        print(f"         âœ‚ï¸ TÄƒiat zona din stÃ¢nga x={cut_x}")
                                elif missing_wall == 'right':
                                    # Peretele din dreapta lipseÈ™te - "tÄƒiem" zona din dreapta
                                    right_points = contour_points[contour_points[:, 0] >= bbox_x + 2*bbox_w//3]
                                    if len(right_points) > 0:
                                        cut_x = int(np.max(right_points[:, 0]))
                                        cut_mask[:, cut_x:] = 0
                                        print(f"         âœ‚ï¸ TÄƒiat zona din dreapta x={cut_x}")
                                
                                # AplicÄƒm masca de tÄƒiere pe zona umplutÄƒ
                                filled_region = cv2.bitwise_and(filled_region, cut_mask)
                                filled_area = np.count_nonzero(filled_region)
                                print(f"         âœ… Zona corectatÄƒ: {filled_area} pixeli (dupÄƒ tÄƒiere)")
                                
                                # Acum aproximÄƒm peretele lipsÄƒ bazÃ¢ndu-ne pe conturul corectat
                                contours_corrected, _ = cv2.findContours(filled_region, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                                if contours_corrected:
                                    largest_contour_corrected = max(contours_corrected, key=cv2.contourArea)
                                    contour_points_corrected = largest_contour_corrected.reshape(-1, 2)
                                    
                                    if missing_wall == 'top':
                                        top_points = contour_points_corrected[contour_points_corrected[:, 1] <= bbox_y + bbox_h//3]
                                        if len(top_points) > 0:
                                            min_x = int(np.min(top_points[:, 0]))
                                            max_x = int(np.max(top_points[:, 0]))
                                            avg_y = int(np.mean(top_points[:, 1]))
                                            wall_thickness = max(3, int(min(w, h) * 0.003))
                                            cv2.line(result, (min_x, avg_y), (max_x, avg_y), 255, wall_thickness)
                                            print(f"         âœ… Aproximat perete de sus: linie la y={avg_y} Ã®ntre x={min_x}-{max_x}")
                                    elif missing_wall == 'bottom':
                                        bottom_points = contour_points_corrected[contour_points_corrected[:, 1] >= bbox_y + 2*bbox_h//3]
                                        if len(bottom_points) > 0:
                                            min_x = int(np.min(bottom_points[:, 0]))
                                            max_x = int(np.max(bottom_points[:, 0]))
                                            avg_y = int(np.mean(bottom_points[:, 1]))
                                            wall_thickness = max(3, int(min(w, h) * 0.003))
                                            cv2.line(result, (min_x, avg_y), (max_x, avg_y), 255, wall_thickness)
                                            print(f"         âœ… Aproximat perete de jos: linie la y={avg_y} Ã®ntre x={min_x}-{max_x}")
                                    elif missing_wall == 'left':
                                        left_points = contour_points_corrected[contour_points_corrected[:, 0] <= bbox_x + bbox_w//3]
                                        if len(left_points) > 0:
                                            min_y = int(np.min(left_points[:, 1]))
                                            max_y = int(np.max(left_points[:, 1]))
                                            avg_x = int(np.mean(left_points[:, 0]))
                                            wall_thickness = max(3, int(min(w, h) * 0.003))
                                            cv2.line(result, (avg_x, min_y), (avg_x, max_y), 255, wall_thickness)
                                            print(f"         âœ… Aproximat perete din stÃ¢nga: linie la x={avg_x} Ã®ntre y={min_y}-{max_y}")
                                    elif missing_wall == 'right':
                                        right_points = contour_points_corrected[contour_points_corrected[:, 0] >= bbox_x + 2*bbox_w//3]
                                        if len(right_points) > 0:
                                            min_y = int(np.min(right_points[:, 1]))
                                            max_y = int(np.max(right_points[:, 1]))
                                            avg_x = int(np.mean(right_points[:, 0]))
                                            wall_thickness = max(3, int(min(w, h) * 0.003))
                                            cv2.line(result, (avg_x, min_y), (avg_x, max_y), 255, wall_thickness)
                                            print(f"         âœ… Aproximat perete din dreapta: linie la x={avg_x} Ã®ntre y={min_y}-{max_y}")
                                
                                # ActualizÄƒm walls_mask cu peretele aproximat pentru a fi folosit Ã®n completarea golurilor
                                walls_mask = result.copy()
                    
                    # SalvÄƒm imagine suplimentarÄƒ: detecÈ›ia cu cel mai mare procent + flood fill (chiar dacÄƒ e respins)
                    if steps_dir and best_box_all:
                        best_x, best_y, best_width, best_height, best_text, best_conf = best_box_all
                        best_center_x = best_x + best_width // 2
                        best_center_y = best_y + best_height // 2
                        
                        vis_best_detection = ocr_image.copy() if ocr_image is not None else cv2.cvtColor(walls_mask, cv2.COLOR_GRAY2BGR)
                        
                        # DesenÄƒm detecÈ›ia cu cel mai mare procent (verde pentru acceptat, portocaliu pentru respins)
                        filled_ratio_best = filled_area / float(h * w) if filled_area > 0 else 0
                        if filled_area > 1000 and (is_garage or filled_ratio_best <= 0.50):
                            detection_color = (0, 255, 0)  # Verde pentru acceptat
                            status_label = f"âœ… ACCEPTED ({best_conf:.1f}%)"
                        else:
                            detection_color = (0, 165, 255)  # Portocaliu pentru respins
                            if filled_area > 0 and filled_ratio_best > 0.50:
                                status_label = f"âŒ REJECTED ({best_conf:.1f}%) - Too large"
                            else:
                                status_label = f"âŒ REJECTED ({best_conf:.1f}%)"
                        
                        # DesenÄƒm dreptunghiul detecÈ›iei
                        cv2.rectangle(vis_best_detection, (best_x, best_y), (best_x + best_width, best_y + best_height), detection_color, 3)
                        
                        # DesenÄƒm centrul detecÈ›iei
                        cv2.circle(vis_best_detection, (best_center_x, best_center_y), 8, (0, 0, 255), -1)
                        
                        # DesenÄƒm flood fill-ul dacÄƒ existÄƒ (galben)
                        if filled_area > 0:
                            filled_colored = np.zeros_like(vis_best_detection)
                            filled_colored[filled_region > 0] = [0, 255, 255]  # Galben
                            vis_best_detection = cv2.addWeighted(vis_best_detection, 0.7, filled_colored, 0.3, 0)
                        
                        # AdÄƒugÄƒm text cu informaÈ›ii
                        label_text = f"{best_text} - {status_label}"
                        if filled_area > 0:
                            label_text += f" | Flood Fill: {filled_area}px"
                        
                        font_scale = max(0.7, best_height / 30.0)
                        font_thickness = max(2, int(font_scale * 2))
                        (text_width, text_height), baseline = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)
                        
                        # Fundal pentru text
                        text_y = max(text_height + 5, best_y - 5)
                        text_x = best_x
                        cv2.rectangle(vis_best_detection, 
                                     (text_x, text_y - text_height - baseline), 
                                     (text_x + text_width + 10, text_y + baseline), 
                                     (255, 255, 255), -1)
                        
                        cv2.putText(vis_best_detection, label_text, (text_x + 5, text_y), 
                                   cv2.FONT_HERSHEY_SIMPLEX, font_scale, detection_color, font_thickness)
                        
                        output_path = Path(steps_dir) / f"{debug_prefix}_01c_best_detection_with_fill.png"
                        cv2.imwrite(str(output_path), vis_best_detection)
                        print(f"         ğŸ’¾ Salvat: {output_path.name} (best detection: {best_conf:.1f}%, fill: {filled_area}px)")
                    
                    # SalvÄƒm imagine de debug pentru TOATE tentativele de flood fill
                    if steps_dir:
                            vis_fill_attempt = cv2.cvtColor(walls_mask, cv2.COLOR_GRAY2BGR)
                            filled_colored = np.zeros_like(vis_fill_attempt)
                            filled_colored[filled_region > 0] = [0, 255, 255]  # Galben
                            vis_fill_attempt = cv2.addWeighted(vis_fill_attempt, 0.7, filled_colored, 0.3, 0)
                            
                            for seed_point in seed_points:
                                seed_x, seed_y = seed_point
                                if 0 <= seed_y < h and 0 <= seed_x < w:
                                    if exclusion_mask[seed_y, seed_x] == 0 and spaces_mask[seed_y, seed_x] == 255:
                                        cv2.circle(vis_fill_attempt, (seed_x, seed_y), 5, (255, 0, 0), -1)
                                    else:
                                        cv2.circle(vis_fill_attempt, (seed_x, seed_y), 5, (128, 128, 128), -1)
                            
                            cv2.circle(vis_fill_attempt, (center_x, center_y), 8, (0, 0, 255), -1)
                            cv2.rectangle(vis_fill_attempt, (x, y), (x + width, y + height), (0, 255, 0), 2)
                            
                            exclusion_colored = np.zeros_like(vis_fill_attempt)
                            exclusion_colored[exclusion_mask > 0] = [255, 0, 255]  # Magenta
                            vis_fill_attempt = cv2.addWeighted(vis_fill_attempt, 0.8, exclusion_colored, 0.2, 0)
                            
                            filled_ratio_debug = filled_area / float(h * w)
                            status_text = f"Area: {filled_area}px ({filled_ratio_debug*100:.1f}%)"
                            if filled_area > 1000 and (is_garage or filled_ratio_debug <= 0.50):
                                status_text += " âœ… ACCEPTED"
                                status_color = (0, 255, 0)
                            elif filled_area <= 1000:
                                status_text += f" âŒ REJECTED (< 1000px)"
                                status_color = (0, 0, 255)
                            else:
                                status_text += f" âŒ REJECTED (> 50% of image)"
                                status_color = (0, 0, 255)
                            
                            font_scale = 0.8
                            font_thickness = 2
                            (text_width, text_height), baseline = cv2.getTextSize(status_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)
                            cv2.rectangle(vis_fill_attempt, 
                                         (x, y + height + 5), 
                                         (x + text_width + 10, y + height + text_height + baseline + 10), 
                                         (255, 255, 255), -1)
                            cv2.putText(vis_fill_attempt, status_text, (x + 5, y + height + text_height + 5), 
                                       cv2.FONT_HERSHEY_SIMPLEX, font_scale, status_color, font_thickness)
                            
                            if overlap_with_walls > 0:
                                overlap_text = f"Overlap: {overlap_with_walls}px"
                                cv2.putText(vis_fill_attempt, overlap_text, (x + 5, y + height + text_height + baseline + 20), 
                                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 165, 255), 2)
                            
                            output_path = Path(steps_dir) / f"{debug_prefix}_02c_flood_fill_attempt_{box_idx + 1}.png"
                            cv2.imwrite(str(output_path), vis_fill_attempt)
                            print(f"         ğŸ’¾ Salvat: {output_path.name} (area={filled_area}px, {'ACCEPTED' if filled_area > 1000 else 'REJECTED'})")
                    
                    # VerificÄƒm cÄƒ zona umplutÄƒ este suficient de mare dar nu prea mare (pentru terasÄƒ)
                    if filled_area > 1000 and (is_garage or filled_ratio <= 0.50):
                        print(f"         ğŸ” Extrag conturul zonei detectate pentru a completa golurile...")
                        
                        gaps = None
                        wall_border = None
                        contours = None
                        
                        contours, _ = cv2.findContours(filled_region, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                        
                        if contours:
                            largest_contour = max(contours, key=cv2.contourArea)
                            contour_mask = np.zeros((h, w), dtype=np.uint8)
                            wall_thickness = max(3, int(min(w, h) * 0.003))
                            cv2.drawContours(contour_mask, [largest_contour], -1, 255, wall_thickness)
                            gaps = cv2.bitwise_and(contour_mask, cv2.bitwise_not(walls_mask))
                            walls_to_add = gaps
                            result = cv2.bitwise_or(result, walls_to_add)
                            gaps_area = np.count_nonzero(gaps)
                            print(f"         âœ… Completat {gaps_area} pixeli de goluri Ã®n pereÈ›i conform conturului")
                        else:
                            print(f"         âš ï¸ Nu s-au gÄƒsit contururi Ã®n zona umplutÄƒ")
                            kernel_size = max(3, int(min(w, h) * 0.005))
                            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
                            filled_dilated = cv2.dilate(filled_region, kernel, iterations=1)
                            wall_border = cv2.subtract(filled_dilated, filled_region)
                            result = cv2.bitwise_or(result, wall_border)
                        
                        rooms_filled += 1
                        print(f"         âœ… Umplut camera '{text}': {filled_area} pixeli")
                        
                        # VizualizÄƒm zona umplutÄƒ È™i golurile completate
                        if steps_dir:
                            vis_fill = cv2.cvtColor(walls_mask, cv2.COLOR_GRAY2BGR)
                            filled_colored = np.zeros_like(vis_fill)
                            filled_colored[filled_region > 0] = [0, 255, 255]  # Galben
                            vis_fill = cv2.addWeighted(vis_fill, 0.7, filled_colored, 0.3, 0)
                            
                            if contours and len(contours) > 0:
                                largest_contour = max(contours, key=cv2.contourArea)
                                cv2.drawContours(vis_fill, [largest_contour], -1, (255, 0, 0), 2)
                            
                            if gaps is not None:
                                gaps_colored = np.zeros_like(vis_fill)
                                gaps_colored[gaps > 0] = [0, 255, 0]
                                vis_fill = cv2.addWeighted(vis_fill, 0.5, gaps_colored, 0.5, 0)
                            elif wall_border is not None:
                                wall_border_colored = np.zeros_like(vis_fill)
                                wall_border_colored[wall_border > 0] = [0, 255, 0]
                                vis_fill = cv2.addWeighted(vis_fill, 0.5, wall_border_colored, 0.5, 0)
                            
                            cv2.circle(vis_fill, (center_x, center_y), 5, (0, 0, 255), -1)
                            cv2.rectangle(vis_fill, (x, y), (x + width, y + height), (0, 255, 0), 2)
                            
                            output_path = Path(steps_dir) / f"{debug_prefix}_02_{room_name}_fill_{box_idx + 1}.png"
                            cv2.imwrite(str(output_path), vis_fill)
                            print(f"         ğŸ’¾ Salvat: {output_path.name}")
                        
                        print(f"         âœ… Gata! Am umplut camera {room_name}.")
                    else:
                        if filled_area > 0 and filled_ratio > 0.50:
                            print(f"         âš ï¸ Zona detectatÄƒ prea mare ({filled_area} pixeli, {filled_ratio*100:.1f}% din imagine). Probabil a trecut prin pereÈ›i. Skip.")
                        else:
                            print(f"         âš ï¸ Zona detectatÄƒ prea micÄƒ ({filled_area} pixeli). Skip.")
                        
                        # SalvÄƒm È™i imaginea cu detecÈ›ia cu cel mai mare procent (chiar dacÄƒ nu s-a fÄƒcut flood fill)
                        if best_box_all:
                            best_x, best_y, best_width, best_height, best_text, best_conf = best_box_all
                            best_center_x = best_x + best_width // 2
                            best_center_y = best_y + best_height // 2
                            
                            vis_best_detection = ocr_image.copy() if ocr_image is not None else cv2.cvtColor(walls_mask, cv2.COLOR_GRAY2BGR)
                            
                            # DesenÄƒm detecÈ›ia cu cel mai mare procent (portocaliu pentru respins - centru pe perete)
                            detection_color = (0, 165, 255)  # Portocaliu
                            status_label = f"âŒ REJECTED: Center on wall ({best_conf:.1f}%)"
                            
                            cv2.rectangle(vis_best_detection, (best_x, best_y), (best_x + best_width, best_y + best_height), detection_color, 3)
                            cv2.circle(vis_best_detection, (best_center_x, best_center_y), 8, (0, 0, 255), -1)
                            
                            label_text = f"{best_text} - {status_label} | No Flood Fill"
                            font_scale = max(0.7, best_height / 30.0)
                            font_thickness = max(2, int(font_scale * 2))
                            (text_width, text_height), baseline = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)
                            
                            text_y = max(text_height + 5, best_y - 5)
                            text_x = best_x
                            cv2.rectangle(vis_best_detection, 
                                         (text_x, text_y - text_height - baseline), 
                                         (text_x + text_width + 10, text_y + baseline), 
                                         (255, 255, 255), -1)
                            
                            cv2.putText(vis_best_detection, label_text, (text_x + 5, text_y), 
                                       cv2.FONT_HERSHEY_SIMPLEX, font_scale, detection_color, font_thickness)
                            
                            output_path = Path(steps_dir) / f"{debug_prefix}_01c_best_detection_with_fill.png"
                            cv2.imwrite(str(output_path), vis_best_detection)
                            print(f"         ğŸ’¾ Salvat: {output_path.name} (best detection: {best_conf:.1f}%, no flood fill)")
        
        if rooms_filled > 0:
            print(f"         âœ… Umplut {rooms_filled} camere de tip '{room_name}'")
        else:
            print(f"         âš ï¸ Nu s-au umplut camere (zone prea mici sau pe pereÈ›i)")
        
        # Pas 5: SalvÄƒm rezultatul final
        if steps_dir:
            vis_final = cv2.cvtColor(result, cv2.COLOR_GRAY2BGR)
            diff = cv2.subtract(result, walls_mask)
            diff_colored = np.zeros_like(vis_final)
            diff_colored[diff > 0] = [0, 255, 0]  # Verde pentru pereÈ›ii noi
            vis_final = cv2.addWeighted(vis_final, 0.7, diff_colored, 0.3, 0)
            cv2.imwrite(str(Path(steps_dir) / f"{debug_prefix}_03_final_result.png"), vis_final)
            print(f"         ğŸ’¾ Salvat: {debug_prefix}_03_final_result.png (verde=pereÈ›i noi)")
    
    except Exception as e:
        print(f"         âŒ Eroare la detectarea/umplerea {room_name}: {e}")
        import traceback
        traceback.print_exc()
        return result
    
    return result




# FuncÈ›iile mutate Ã®n wall_repair.py:
# - repair_house_walls_with_floodfill
# - bridge_wall_gaps
# - smart_wall_closing
# - get_strict_1px_outline

# FuncÈ›ia flood_fill_room este folositÄƒ Ã®n scale_detection.py


# ============================================
# 3D RENDERER (nemodificatÄƒ)
# ============================================

def render_obj_to_image(vertices_raw, faces_raw, output_image_path, width=1024, height=1024):
    """RandeazÄƒ o previzualizare 3D simplÄƒ (PNG, staticÄƒ)."""
    if not vertices_raw or not faces_raw:
        return
    print("   ğŸ“¸ Randez previzualizarea 3D...")
    
    verts = []
    faces = []
    for v_line in vertices_raw: 
        parts = v_line.split()
        verts.append([float(parts[1]), float(parts[2]), float(parts[3])])
    verts = np.array(verts)
    
    for f_line in faces_raw: 
        parts = f_line.split()
        faces.append([int(parts[1])-1, int(parts[2])-1, int(parts[3])-1, int(parts[4])-1])
    
    angle_y = np.radians(45.0)
    angle_x = np.radians(30.0)
    
    Ry = np.array([[np.cos(angle_y), 0, np.sin(angle_y)], [0, 1, 0], [-np.sin(angle_y), 0, np.cos(angle_y)]])
    Rx = np.array([[1, 0, 0], [0, np.cos(angle_x), -np.sin(angle_x)], [0, np.sin(angle_x), np.cos(angle_x)]])
    
    center = verts.mean(axis=0)
    verts_centered = verts - center
    rotated_verts = verts_centered @ Ry.T @ Rx.T
    
    range_val = np.max(rotated_verts) - np.min(rotated_verts)
    if range_val == 0:
        range_val = 1
    
    scale = min(width, height) / range_val * 0.7
    
    projected_2d = rotated_verts[:, :2] * scale
    projected_2d[:, 0] += width / 2
    projected_2d[:, 1] += height / 2
    projected_2d[:, 1] = height - projected_2d[:, 1]

    face_depths = []
    for idx, face in enumerate(faces): 
        face_depths.append((np.mean(rotated_verts[face, 2]), idx))
    face_depths.sort(key=lambda x: x[0])

    canvas = np.zeros((height, width, 3), dtype=np.uint8)
    wall_color = (215, 215, 215)
    edge_color = (60, 60, 60)
    
    for _, face_idx in face_depths:
        pts = projected_2d[faces[face_idx]].astype(np.int32)
        cv2.fillPoly(canvas, [pts], wall_color)
        cv2.polylines(canvas, [pts], True, edge_color, 1, cv2.LINE_AA)
    
    cv2.imwrite(str(output_image_path), canvas)


def export_walls_to_obj(walls_mask, output_path, scale_m_px, wall_height_m=2.5, image_output_path=None):
    """ExportÄƒ masca pereÈ›ilor Ã®ntr-un fiÈ™ier .OBJ 3D."""
    print("   ğŸ—ï¸  Generez model 3D (Smoothed)...")
    contours, _ = cv2.findContours(walls_mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
    vertices_str_list = []
    faces_str_list = []
    vertex_count = 0
    h_img, w_img = walls_mask.shape[:2]

    for cnt in contours:
        epsilon = 0.001 * cv2.arcLength(cnt, True)
        approx = cv2.approxPolyDP(cnt, epsilon, True)

        if len(approx) < 3: continue
        
        base_idx = vertex_count + 1
        num_pts = len(approx)
        
        for pt in approx:
            px, py = pt[0]
            x = (px - w_img/2) * scale_m_px
            z = (h_img - py - h_img/2) * scale_m_px 
            
            vertices_str_list.append(f"v {x:.4f} 0.0000 {-z:.4f}")
            vertices_str_list.append(f"v {x:.4f} {wall_height_m:.4f} {-z:.4f}")
            
        for k in range(num_pts):
            curr = k
            next_p = (k + 1) % num_pts
            
            v_bl = base_idx + 2*curr
            v_tl = base_idx + 2*curr + 1
            v_br = base_idx + 2*next_p
            v_tr = base_idx + 2*next_p + 1
            
            faces_str_list.append(f"f {v_bl} {v_br} {v_tr} {v_tl}")
            
        vertex_count += 2 * num_pts

    with open(output_path, "w") as f:
        f.write(f"# Scale: {scale_m_px} m/px\n")
        f.write(f"# Holzbot Auto-Generated 3D Model\n")
        for v in vertices_str_list: f.write(v + "\n")
        for face in faces_str_list: f.write(face + "\n")
        
    print(f"   âœ… 3D Salvat: {output_path.name}")
    
    if image_output_path:
        render_obj_to_image(vertices_str_list, faces_str_list, image_output_path)


# ============================================
# âœ… NEW: ADAPTIVE TILING FOR LARGE IMAGES (nemodificatÄƒ)
# ============================================

def _process_with_adaptive_tiling(img, model, device, tile_size=512, overlap=64):
    """ProceseazÄƒ imagini mari prin tiling adaptiv."""
    h_orig, w_orig = img.shape[:2]
    print(f"   ğŸ§© TILING Mode: {w_orig}x{h_orig} -> tiles de {tile_size}x{tile_size}")
    
    stride = tile_size - overlap
    n_tiles_h = math.ceil(h_orig / stride)
    n_tiles_w = math.ceil(w_orig / stride)
    
    print(f"   ğŸ“¦ Generez {n_tiles_w}x{n_tiles_h} = {n_tiles_w * n_tiles_h} tiles")
    
    full_pred = np.zeros((h_orig, w_orig), dtype=np.float32)
    weight_map = np.zeros((h_orig, w_orig), dtype=np.float32)
    
    tile_count = 0
    for i in range(n_tiles_h):
        for j in range(n_tiles_w):
            y_start = i * stride
            x_start = j * stride
            y_end = min(y_start + tile_size, h_orig)
            x_end = min(x_start + tile_size, w_orig)
            
            tile = img[y_start:y_end, x_start:x_end]
            
            tile_resized = cv2.resize(tile, (tile_size, tile_size))
            
            norm_tile = 2 * (tile_resized.astype(np.float32) / 255.0) - 1
            tensor = torch.from_numpy(norm_tile).float().permute(2, 0, 1).unsqueeze(0).to(device)
            
            with torch.no_grad():
                output = model(tensor)
                # Am ajustat pentru a rula chiar dacÄƒ modelul nu e Ã®ncÄƒrcat corect, deÈ™i e o problemÄƒ de setup
                if isinstance(output, dict) and output.get('out') is not None:
                     pred_tile = torch.argmax(output['out'][:, 21:33, :, :], dim=1).squeeze().cpu().numpy()
                else:
                    pred_tile = torch.argmax(output[:, 21:33, :, :], dim=1).squeeze().cpu().numpy()
            
            actual_h = y_end - y_start
            actual_w = x_end - x_start
            pred_tile_resized = cv2.resize(
                pred_tile.astype('uint8'),
                (actual_w, actual_h),
                interpolation=cv2.INTER_NEAREST
            ).astype(np.float32)
            
            weight_tile = np.ones((actual_h, actual_w), dtype=np.float32)
            
            if overlap > 0:
                fade = min(overlap // 2, 32)
                for k in range(fade):
                    alpha = k / fade
                    if y_start > 0 and k < actual_h:
                        weight_tile[k, :] *= alpha
                    if y_end < h_orig and k < actual_h:
                        weight_tile[-(k+1), :] *= alpha
                    if x_start > 0 and k < actual_w:
                        weight_tile[:, k] *= alpha
                    if x_end < w_orig and k < actual_w:
                        weight_tile[:, -(k+1)] *= alpha
            
            full_pred[y_start:y_end, x_start:x_end] += pred_tile_resized * weight_tile
            weight_map[y_start:y_end, x_start:x_end] += weight_tile
            
            tile_count += 1
            if tile_count % 10 == 0:
                print(f"      â³ Procesat {tile_count}/{n_tiles_w * n_tiles_h} tiles...")
    
    weight_map[weight_map == 0] = 1
    full_pred = full_pred / weight_map
    
    pred_mask = np.round(full_pred).astype(np.uint8)
    
    print(f"   âœ… Tiling complet: {tile_count} tiles procesate")
    
    return pred_mask


# ============================================
# FUNCÈšIA PRINCIPALÄ‚ (MODIFICATÄ‚ PENTRU CLOSING PUTERNIC)
# ============================================

def run_cubicasa_detection(
    image_path: str,
    model_weights_path: str,
    output_dir: str,
    gemini_api_key: str,
    device: torch.device,
    save_debug_steps: bool = True,
    run_phase: int = 0,
    reused_model=None,
    reused_device=None,
) -> dict:
    """
    RuleazÄƒ detecÈ›ia CubiCasa + mÄƒsurÄƒri + 3D Generation.
    ACUM cu Adaptive Strategy: Resize Inteligent pentru imagini mici, Tiling pentru imagini mari.

    run_phase: 0 = tot pipeline-ul; 1 = doar faza 1 (Raster API + AI walls â†’ 02_ai_walls_closed);
               2 = doar faza 2 (brute force + crop + walls from coords). Pentru tandem: rulezi
               faza 1 pentru toate planurile, apoi faza 2 pentru toate.
    reused_model / reused_device: cÃ¢nd run_phase=1, poÈ›i pasa model/device reÃ®ntors de un plan
                                  anterior ca sÄƒ nu reÃ®ncarci modelul.
    """
    output_dir = Path(output_dir)
    steps_dir = output_dir / "cubicasa_steps"
    walls_result_from_coords = None

    if run_phase == 2:
        # Faza 2: nu Ã®ncÄƒrcÄƒm model sau imagine; folosim doar ce e deja pe disc Ã®n steps_dir
        ensure_dir(steps_dir)
        raster_dir = Path(steps_dir) / "raster"
        ac_path = steps_dir / "02_ai_walls_closed.png"
        ai_walls_closed = cv2.imread(str(ac_path), cv2.IMREAD_GRAYSCALE)
        if ai_walls_closed is None:
            raise RuntimeError(f"LipsÄƒ 02_ai_walls_closed.png Ã®n {steps_dir} (ruleazÄƒ mai Ã®ntÃ¢i faza 1)")
        # Pentru scale detection etc. folosim 00_original.png din steps_dir
        image_path = steps_dir / "00_original.png"
        # ContinuÄƒm direct la secÈ›iunea brute force (mai jos)
    else:
        # Faza 0 (all) sau 1 (doar Raster API + AI walls)
        image_path = Path(image_path)
        model_weights_path = Path(model_weights_path)
        ensure_dir(steps_dir)
        print(f"   ğŸ¤– CubiCasa: Procesez {image_path.name}")
        # 1. SETUP MODEL (sau folosim cel reÃ®ntors)
        if reused_model is not None and reused_device is not None:
            model = reused_model
            device = reused_device
            print(f"   â³ Folosesc modelul deja Ã®ncÄƒrcat pe {device.type}...")
        else:
            print(f"   â³ Ãncarc AI pe {device.type}...")
            model = hg_furukawa_original(n_classes=44)
            if not model_weights_path.exists():
                print(f"âš ï¸  Lipsesc weights: {model_weights_path}. Continuu cu model non-funcÈ›ional.")
            else:
                checkpoint = torch.load(str(model_weights_path), map_location=device, weights_only=False)
                model.load_state_dict(checkpoint['model_state'] if 'model_state' in checkpoint else checkpoint)
            model.to(device)
            model.eval()

        # 2. LOAD IMAGE & DECIDE STRATEGY
        img = cv2.imread(str(image_path))
        if img is None:
            raise RuntimeError(f"Nu pot citi imaginea: {image_path}")
        h_orig, w_orig = img.shape[:2]
        save_step("00_original", img, str(steps_dir))
        if run_phase != 2:
            # 2a. RASTER TO VECTOR API CALL
            if steps_dir:
                try:
                    print(f"   ğŸ”„ Apel RasterScan API pentru vectorizare...")
            
                    # CreÄƒm folderul raster
                    raster_dir = Path(steps_dir) / "raster"
                    raster_dir.mkdir(parents=True, exist_ok=True)
            
                    # âœ… PREPROCESARE: È˜tergem liniile foarte subÈ›iri Ã®nainte de trimitere la RasterScan
                    print(f"      ğŸ§¹ Preprocesare imagine: eliminare linii subÈ›iri...")
                    api_img = img.copy()
            
                    # Convertim la grayscale pentru procesare
                    gray = cv2.cvtColor(api_img, cv2.COLOR_BGR2GRAY)
            
                    # DetectÄƒm liniile subÈ›iri folosind morphological operations
                    # Folosim un kernel mic pentru a identifica liniile subÈ›iri
                    kernel_thin = np.ones((3, 3), np.uint8)
                    thinned = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel_thin, iterations=1)
            
                    # DetectÄƒm contururi È™i eliminÄƒm cele foarte mici (linii subÈ›iri)
                    _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV)
                    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
                    # CreÄƒm o mascÄƒ pentru liniile subÈ›iri (contururi cu aria micÄƒ)
                    thin_lines_mask = np.zeros_like(gray)
                    min_line_area = (gray.shape[0] * gray.shape[1]) * 0.0001  # 0.01% din imagine
            
                    for contour in contours:
                        area = cv2.contourArea(contour)
                        if area < min_line_area:
                            # Este o linie subÈ›ire - o eliminÄƒm
                            cv2.drawContours(thin_lines_mask, [contour], -1, 255, -1)
            
                    # EliminÄƒm liniile subÈ›iri din imagine
                    api_img = cv2.inpaint(api_img, thin_lines_mask, 3, cv2.INPAINT_TELEA)
            
                    # SalvÄƒm copia preprocesatÄƒ Ã®n folderul raster
                    preprocessed_path = raster_dir / "00_original_preprocessed.png"
                    cv2.imwrite(str(preprocessed_path), api_img)
                    print(f"      ğŸ’¾ Salvat: {preprocessed_path.name} (preprocesat - linii subÈ›iri eliminate)")
            
                    # RedimensionÄƒm imaginea dacÄƒ e prea mare (API limit ~4MB)
                    MAX_API_DIM = 2048
                    h_api, w_api = api_img.shape[:2]
                    scale_factor = 1.0
            
                    if max(h_api, w_api) > MAX_API_DIM:
                        scale_factor = MAX_API_DIM / max(h_api, w_api)
                        new_w_api = int(w_api * scale_factor)
                        new_h_api = int(h_api * scale_factor)
                        api_img = cv2.resize(api_img, (new_w_api, new_h_api), interpolation=cv2.INTER_AREA)
                        print(f"      ğŸ“ Redimensionat pentru API: {w_api}x{h_api} -> {new_w_api}x{new_h_api}")
                    else:
                        new_w_api, new_h_api = w_api, h_api
            
                    # SalvÄƒm imaginea pentru API
                    api_img_path = raster_dir / "input_resized.jpg"
                    cv2.imwrite(str(api_img_path), api_img, [cv2.IMWRITE_JPEG_QUALITY, 85])
            
                    # Convertim Ã®n base64 (folosim JPEG comprimat)
                    _, buffer = cv2.imencode('.jpg', api_img, [cv2.IMWRITE_JPEG_QUALITY, 85])
                    image_base64 = base64.b64encode(buffer).decode('utf-8')
                    print(f"      ğŸ“¦ Dimensiune payload: {len(image_base64) / 1024 / 1024:.2f} MB")
            
                    # ApelÄƒm API-ul RasterScan (cu retry dacÄƒ masca e invalidÄƒ â€“ camerÄƒ inundatÄƒ)
                    raster_api_key = os.environ.get('RASTER_API_KEY', '')
                    if raster_api_key:
                        url = "https://backend.rasterscan.com/raster-to-vector-base64"
                        payload = {"image": image_base64}
                        headers = {
                            "x-api-key": raster_api_key,
                            "Content-Type": "application/json"
                        }
                        max_attempts = 3
                        raster_valid = False
                        for attempt in range(max_attempts):
                            if attempt > 0:
                                print(f"      ğŸ”„ ReÃ®ncerc RasterScan API ({attempt + 1}/{max_attempts})...")
                            response = requests.post(url, json=payload, headers=headers, timeout=120)
                            if response.status_code != 200:
                                print(f"      âš ï¸ RasterScan API eroare: {response.status_code} - {response.text[:200]}")
                                break
                            result = response.json()
                            print(f"      âœ… RasterScan API rÄƒspuns primit")
                        
                            # SalvÄƒm rÄƒspunsul JSON
                            json_path = raster_dir / "response.json"
                            with open(json_path, 'w') as f:
                                json.dump(result, f, indent=2)
                            print(f"      ğŸ“„ Salvat: {json_path.name}")
                        
                            # DacÄƒ rÄƒspunsul conÈ›ine SVG sau alte fiÈ™iere, le salvÄƒm
                            if isinstance(result, dict):
                                # SalvÄƒm fiecare cÃ¢mp relevant
                                for key, value in result.items():
                                    if key == 'svg' and isinstance(value, str):
                                        svg_path = raster_dir / "output.svg"
                                        with open(svg_path, 'w') as f:
                                            f.write(value)
                                        print(f"      ğŸ“„ Salvat: {svg_path.name}")
                                    elif key == 'dxf' and isinstance(value, str):
                                        # DXF poate fi base64 encoded
                                        dxf_path = raster_dir / "output.dxf"
                                        try:
                                            dxf_data = base64.b64decode(value)
                                            with open(dxf_path, 'wb') as f:
                                                f.write(dxf_data)
                                        except:
                                            with open(dxf_path, 'w') as f:
                                                f.write(value)
                                        print(f"      ğŸ“„ Salvat: {dxf_path.name}")
                                    elif key == 'image' and isinstance(value, str):
                                        # Imagine procesatÄƒ (probabil base64)
                                        try:
                                            # EliminÄƒm prefixul data:image/... dacÄƒ existÄƒ
                                            img_str = value
                                            if ',' in img_str:
                                                img_str = img_str.split(',')[1]
                                            img_data = base64.b64decode(img_str)
                                            img_path = raster_dir / "processed_image.jpg"
                                            with open(img_path, 'wb') as f:
                                                f.write(img_data)
                                            print(f"      ğŸ“„ Salvat: {img_path.name}")
                                        except Exception as e:
                                            print(f"      âš ï¸ Eroare salvare imagine: {e}")
                            
                                # GenerÄƒm imagini din datele vectoriale
                                data = result.get('data', result)
                            
                                # CalculÄƒm factorul de scalare invers pentru overlay pe original
                                # Coordonatele din API sunt pentru imaginea redimensionatÄƒ
                                def scale_coord(x, y, for_original=False):
                                    """ScaleazÄƒ coordonatele Ã®napoi la original"""
                                    if for_original:
                                        # ScalÄƒm Ã®napoi la dimensiunile originale
                                        orig_x = int(x / scale_factor)
                                        orig_y = int(y / scale_factor)
                                        return orig_x, orig_y
                                    return int(x), int(y)
                            
                                # Dimensiunile pentru imaginile pe coordonate API
                                raster_h, raster_w = new_h_api, new_w_api
                            
                                # 1. Imagine cu pereÈ›ii (generaÈ›i din contururile camerelor)
                                # API-ul nu returneazÄƒ walls separat, dar le putem genera din contururile rooms
                                if 'rooms' in data and data['rooms']:
                                    walls_img = np.zeros((raster_h, raster_w, 3), dtype=np.uint8)
                                    walls_img.fill(255)  # Fundal alb
                                
                                    wall_count = 0
                                    for room in data['rooms']:
                                        points = []
                                        for point in room:
                                            if 'x' in point and 'y' in point:
                                                points.append([int(point['x']), int(point['y'])])
                                    
                                        if len(points) >= 3:
                                            pts = np.array(points, np.int32)
                                            # DesenÄƒm conturul camerei ca pereÈ›i
                                            cv2.polylines(walls_img, [pts], True, (0, 0, 0), 3)
                                            wall_count += len(points)
                                
                                    walls_path = raster_dir / "walls.png"
                                    cv2.imwrite(str(walls_path), walls_img)
                                    print(f"      ğŸ“„ Salvat: {walls_path.name} ({wall_count} segmente perete din {len(data['rooms'])} camere)")
                            
                                # âš ï¸ NU mai generÄƒm rooms.png aici - va fi generat DUPÄ‚ validarea pereÈ›ilor Ã®n raster_processing
                            
                                # 3. Imagine cu deschiderile (uÈ™i/ferestre - API nu face distincÈ›ie)
                                if 'doors' in data and data['doors']:
                                    doors_img = np.zeros((raster_h, raster_w, 3), dtype=np.uint8)
                                    doors_img.fill(255)  # Fundal alb
                                
                                    for idx, door in enumerate(data['doors']):
                                        if 'bbox' in door and len(door['bbox']) == 4:
                                            x1, y1, x2, y2 = map(int, door['bbox'])
                                            width = x2 - x1
                                            height = y2 - y1
                                        
                                            # ÃncercÄƒm sÄƒ determinÄƒm tipul bazat pe dimensiuni
                                            # Ferestrele tind sÄƒ fie mai late È™i mai puÈ›in Ã®nalte
                                            aspect = width / max(1, height)
                                            if aspect > 2.5 or (width > 60 and height < 30):
                                                label = "Window"
                                                color_fill = (200, 220, 255)  # Albastru deschis pentru ferestre
                                                color_border = (150, 180, 220)
                                            else:
                                                label = "Door"
                                                color_fill = (0, 150, 255)  # Portocaliu pentru uÈ™i
                                                color_border = (0, 100, 200)
                                        
                                            cv2.rectangle(doors_img, (x1, y1), (x2, y2), color_fill, -1)
                                            cv2.rectangle(doors_img, (x1, y1), (x2, y2), color_border, 2)
                                        
                                            # AdÄƒugÄƒm etichetÄƒ
                                            font = cv2.FONT_HERSHEY_SIMPLEX
                                            font_scale = 0.35
                                            thickness = 1
                                            cv2.putText(doors_img, label, (x1, y1 - 5 if y1 > 20 else y2 + 12),
                                                       font, font_scale, (0, 0, 150), thickness)
                                
                                    doors_path = raster_dir / "doors.png"
                                    cv2.imwrite(str(doors_path), doors_img)
                                    print(f"      ğŸ“„ Salvat: {doors_path.name} ({len(data['doors'])} deschideri uÈ™i/ferestre)")
                            
                                # 4. Imagine combinatÄƒ (pereÈ›i + camere + uÈ™i)
                                combined_img = np.zeros((raster_h, raster_w, 3), dtype=np.uint8)
                                combined_img.fill(255)
                            
                                # DesenÄƒm camerele mai Ã®ntÃ¢i (fundal)
                                if 'rooms' in data and data['rooms']:
                                    for idx, room in enumerate(data['rooms']):
                                        color = room_colors[idx % len(room_colors)] if 'room_colors' in dir() else (220, 220, 220)
                                        points = []
                                        for point in room:
                                            if 'x' in point and 'y' in point:
                                                points.append([int(point['x']), int(point['y'])])
                                        if len(points) >= 3:
                                            pts = np.array(points, np.int32)
                                            cv2.fillPoly(combined_img, [pts], color)
                            
                                # DesenÄƒm pereÈ›ii (din contururile camerelor)
                                if 'rooms' in data and data['rooms']:
                                    for room in data['rooms']:
                                        points = []
                                        for point in room:
                                            if 'x' in point and 'y' in point:
                                                points.append([int(point['x']), int(point['y'])])
                                        if len(points) >= 3:
                                            pts = np.array(points, np.int32)
                                            cv2.polylines(combined_img, [pts], True, (0, 0, 0), 3)
                            
                                # DesenÄƒm uÈ™ile
                                if 'doors' in data and data['doors']:
                                    for door in data['doors']:
                                        if 'bbox' in door and len(door['bbox']) == 4:
                                            x1, y1, x2, y2 = map(int, door['bbox'])
                                            cv2.rectangle(combined_img, (x1, y1), (x2, y2), (0, 150, 255), -1)
                                            cv2.rectangle(combined_img, (x1, y1), (x2, y2), (0, 100, 200), 2)
                            
                                combined_path = raster_dir / "combined.png"
                                cv2.imwrite(str(combined_path), combined_img)
                                print(f"      ğŸ“„ Salvat: {combined_path.name}")
                            
                                # 5. Overlay pe imaginea ORIGINALÄ‚ (cu coordonate scalate corect)
                                # Folosim imaginea originalÄƒ, nu cea redimensionatÄƒ
                                overlay_img = img.copy()
                            
                                # Overlay camere cu transparenÈ›Äƒ
                                if 'rooms' in data and data['rooms']:
                                    rooms_overlay = np.zeros_like(overlay_img)
                                    for idx, room in enumerate(data['rooms']):
                                        color = room_colors[idx % len(room_colors)] if 'room_colors' in dir() else (220, 220, 220)
                                        points = []
                                        for point in room:
                                            if 'x' in point and 'y' in point:
                                                ox, oy = scale_coord(point['x'], point['y'], for_original=True)
                                                # Clamp la dimensiunile imaginii
                                                ox = max(0, min(ox, h_orig - 1))
                                                oy = max(0, min(oy, w_orig - 1))
                                                points.append([ox, oy])
                                        if len(points) >= 3:
                                            pts = np.array(points, np.int32)
                                            cv2.fillPoly(rooms_overlay, [pts], color)
                                
                                    # Blend cu original
                                    mask = (rooms_overlay.sum(axis=2) > 0).astype(np.uint8)
                                    mask = np.stack([mask, mask, mask], axis=2)
                                    overlay_img = np.where(mask, cv2.addWeighted(overlay_img, 0.6, rooms_overlay, 0.4, 0), overlay_img)
                            
                                # DesenÄƒm pereÈ›ii din contururile camerelor (scalaÈ›i la original)
                                if 'rooms' in data and data['rooms']:
                                    for room in data['rooms']:
                                        points = []
                                        for point in room:
                                            if 'x' in point and 'y' in point:
                                                ox, oy = scale_coord(point['x'], point['y'], for_original=True)
                                                ox = max(0, min(ox, w_orig - 1))
                                                oy = max(0, min(oy, h_orig - 1))
                                                points.append([ox, oy])
                                        if len(points) >= 3:
                                            pts = np.array(points, np.int32)
                                            cv2.polylines(overlay_img, [pts], True, (0, 0, 255), 2)
                            
                                # DesenÄƒm deschiderile (uÈ™i/ferestre) scalate la original, cu etichete
                                if 'doors' in data and data['doors']:
                                    for door in data['doors']:
                                        if 'bbox' in door and len(door['bbox']) == 4:
                                            x1, y1, x2, y2 = door['bbox']
                                            ox1, oy1 = scale_coord(x1, y1, for_original=True)
                                            ox2, oy2 = scale_coord(x2, y2, for_original=True)
                                        
                                            # DeterminÄƒm tipul bazat pe dimensiuni
                                            width = abs(ox2 - ox1)
                                            height = abs(oy2 - oy1)
                                            aspect = width / max(1, height)
                                            if aspect > 2.5 or (width > 60 and height < 30):
                                                label = "Win"
                                                color = (220, 180, 0)  # Cyan pentru ferestre
                                            else:
                                                label = "Door"
                                                color = (255, 100, 0)  # Portocaliu pentru uÈ™i
                                        
                                            cv2.rectangle(overlay_img, (ox1, oy1), (ox2, oy2), color, 2)
                                        
                                            # EtichetÄƒ
                                            font = cv2.FONT_HERSHEY_SIMPLEX
                                            cv2.putText(overlay_img, label, (ox1, oy1 - 5 if oy1 > 20 else oy2 + 15),
                                                       font, 0.4, color, 1)
                            
                                overlay_path = raster_dir / "overlay.png"
                                cv2.imwrite(str(overlay_path), overlay_img)
                                print(f"      ğŸ“„ Salvat: {overlay_path.name}")
                            
                                # 6. RENDER 3D IZOMETRIC (Ã®mbunÄƒtÄƒÈ›it)
                                print(f"      ğŸ¨ Generez render 3D izometric...")
                            
                                # Parametri pentru proiecÈ›ia izometricÄƒ
                                wall_height = 60  # ÃnÄƒlÈ›imea pereÈ›ilor Ã®n pixeli
                            
                                # CalculÄƒm bounding box-ul datelor pentru centrare
                                all_points = []
                                if 'walls' in data and data['walls']:
                                    for wall in data['walls']:
                                        if 'position' in wall:
                                            for pt in wall['position']:
                                                all_points.append(pt)
                                if 'rooms' in data and data['rooms']:
                                    for room in data['rooms']:
                                        for point in room:
                                            if 'x' in point and 'y' in point:
                                                all_points.append([point['x'], point['y']])
                            
                                if all_points:
                                    all_points = np.array(all_points)
                                    min_x, min_y = all_points.min(axis=0)
                                    max_x, max_y = all_points.max(axis=0)
                                
                                    # ScalÄƒm pentru a Ã®ncÄƒpea Ã®n canvas
                                    data_w = max_x - min_x
                                    data_h = max_y - min_y
                                
                                    # Canvas size
                                    canvas_w = int(data_w * 1.5 + data_h * 0.5 + 200)
                                    canvas_h = int(data_h * 0.7 + wall_height + 150)
                                
                                    # Offset pentru centrare
                                    offset_x = 50
                                    offset_y = wall_height + 30
                                
                                    # FuncÈ›ie pentru transformare izometricÄƒ (proiecÈ›ie oblicÄƒ)
                                    def to_iso_3d(x, y, z=0):
                                        # NormalizÄƒm coordonatele
                                        nx = x - min_x
                                        ny = y - min_y
                                        # ProiecÈ›ie izometricÄƒ simplificatÄƒ
                                        iso_x = int(offset_x + nx + ny * 0.4)
                                        iso_y = int(offset_y + ny * 0.6 - z)
                                        return (iso_x, iso_y)
                                
                                    # Canvas cu fundal gradient (cer)
                                    iso_img = np.zeros((canvas_h, canvas_w, 3), dtype=np.uint8)
                                    for row in range(canvas_h):
                                        ratio = row / canvas_h
                                        b = int(250 - ratio * 20)
                                        g = int(248 - ratio * 15)
                                        r = int(245 - ratio * 10)
                                        iso_img[row, :] = [b, g, r]
                                
                                    # Culori pentru podele camerelor
                                    iso_room_colors = [
                                        (210, 225, 210),  # Verde deschis
                                        (210, 210, 225),  # Albastru deschis
                                        (225, 210, 210),  # RoÈ™u deschis
                                        (225, 225, 210),  # Galben deschis
                                        (210, 225, 225),  # Cyan deschis
                                        (225, 210, 225),  # Magenta deschis
                                        (220, 220, 220),  # Gri deschis
                                    ]
                                
                                    # DesenÄƒm podelele camerelor (sortate de la spate la faÈ›Äƒ)
                                    if 'rooms' in data and data['rooms']:
                                        sorted_rooms = []
                                        for idx, room in enumerate(data['rooms']):
                                            points = []
                                            for point in room:
                                                if 'x' in point and 'y' in point:
                                                    points.append([int(point['x']), int(point['y'])])
                                            if len(points) >= 3:
                                                # Folosim Y minim pentru sortare (spate -> faÈ›Äƒ)
                                                min_room_y = min(p[1] for p in points)
                                                sorted_rooms.append((min_room_y, idx, points))
                                    
                                        sorted_rooms.sort(key=lambda x: x[0])
                                    
                                        for min_room_y, idx, points in sorted_rooms:
                                            color = iso_room_colors[idx % len(iso_room_colors)]
                                            floor_pts = np.array([to_iso_3d(p[0], p[1], 0) for p in points], np.int32)
                                            cv2.fillPoly(iso_img, [floor_pts], color)
                                            cv2.polylines(iso_img, [floor_pts], True, (180, 180, 180), 1)
                                
                                    # DesenÄƒm pereÈ›ii 3D (sortaÈ›i de la spate la faÈ›Äƒ)
                                    if 'walls' in data and data['walls']:
                                        sorted_walls = []
                                        for wall in data['walls']:
                                            if 'position' in wall and len(wall['position']) >= 2:
                                                pt1 = wall['position'][0]
                                                pt2 = wall['position'][1]
                                                # SortÄƒm dupÄƒ Y minim
                                                min_wall_y = min(pt1[1], pt2[1])
                                                sorted_walls.append((min_wall_y, pt1, pt2))
                                    
                                        sorted_walls.sort(key=lambda x: x[0])
                                    
                                        for min_wall_y, pt1, pt2 in sorted_walls:
                                            x1, y1 = int(pt1[0]), int(pt1[1])
                                            x2, y2 = int(pt2[0]), int(pt2[1])
                                        
                                            # Punctele peretelui 3D
                                            bl = to_iso_3d(x1, y1, 0)  # bottom-left
                                            br = to_iso_3d(x2, y2, 0)  # bottom-right
                                            tl = to_iso_3d(x1, y1, wall_height)  # top-left
                                            tr = to_iso_3d(x2, y2, wall_height)  # top-right
                                        
                                            # DeterminÄƒm culoarea bazat pe orientare
                                            dx = abs(x2 - x1)
                                            dy = abs(y2 - y1)
                                        
                                            if dy < dx:  # Perete orizontal
                                                wall_color = (230, 230, 230)  # Mai luminos
                                            else:  # Perete vertical
                                                wall_color = (200, 200, 200)  # Mai Ã®ntunecat
                                        
                                            # DesenÄƒm faÈ›a frontalÄƒ a peretelui
                                            wall_pts = np.array([bl, br, tr, tl], np.int32)
                                            cv2.fillPoly(iso_img, [wall_pts], wall_color)
                                            cv2.polylines(iso_img, [wall_pts], True, (120, 120, 120), 1)
                                        
                                            # Partea de sus a peretelui (opÈ›ional, pentru grosime)
                                            thickness_offset = 6
                                            if dy < dx:  # Perete orizontal - adÄƒugÄƒm grosime Ã®n Y
                                                tl2 = to_iso_3d(x1, y1 + thickness_offset, wall_height)
                                                tr2 = to_iso_3d(x2, y2 + thickness_offset, wall_height)
                                                top_pts = np.array([tl, tr, tr2, tl2], np.int32)
                                                cv2.fillPoly(iso_img, [top_pts], (240, 240, 240))
                                                cv2.polylines(iso_img, [top_pts], True, (150, 150, 150), 1)
                                            else:  # Perete vertical - adÄƒugÄƒm grosime Ã®n X
                                                tl2 = to_iso_3d(x1 + thickness_offset, y1, wall_height)
                                                tr2 = to_iso_3d(x2 + thickness_offset, y2, wall_height)
                                                top_pts = np.array([tl, tr, tr2, tl2], np.int32)
                                                cv2.fillPoly(iso_img, [top_pts], (240, 240, 240))
                                                cv2.polylines(iso_img, [top_pts], True, (150, 150, 150), 1)
                                
                                    iso_path = raster_dir / "render_3d.png"
                                    cv2.imwrite(str(iso_path), iso_img)
                                    print(f"      ğŸ“„ Salvat: {iso_path.name}")
                            
                                # AfiÈ™Äƒm statistici
                                if 'area' in data:
                                    print(f"      ğŸ“Š Arie totalÄƒ: {data['area']}")
                                if 'perimeter' in data:
                                    print(f"      ğŸ“Š Perimetru: {data['perimeter']:.2f}")
                            
                                # NotÄƒ: Brute force pentru api_walls_mask va fi executat mai tÃ¢rziu,
                                # dupÄƒ generarea 02_ai_walls_closed.png (vezi linia ~2801)
                                # Aici doar generÄƒm api_walls_mask.png
                                api_walls_mask = None
                                try:
                                    # 1. GenerÄƒm api_walls_mask.png din imaginea procesatÄƒ de API
                                    if 'image' in result.get('data', result):
                                        img_str = result['data']['image']
                                        if ',' in img_str:
                                            img_str = img_str.split(',')[1]
                                        img_data = base64.b64decode(img_str)
                                        nparr = np.frombuffer(img_data, np.uint8)
                                        api_processed_img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
                                    
                                        # DetectÄƒm pereÈ›ii din imaginea API (gri, nu coloraÈ›i)
                                        api_gray = cv2.cvtColor(api_processed_img, cv2.COLOR_BGR2GRAY)
                                        api_hsv = cv2.cvtColor(api_processed_img, cv2.COLOR_BGR2HSV)
                                        saturation = api_hsv[:, :, 1]
                                    
                                        # Pixelii cu saturaÈ›ie micÄƒ È™i gri mediu sunt pereÈ›i
                                        api_walls_mask = ((api_gray > 100) & (api_gray < 180) & (saturation < 30)).astype(np.uint8) * 255
                                    
                                        api_walls_path = raster_dir / "api_walls_mask.png"
                                        cv2.imwrite(str(api_walls_path), api_walls_mask)
                                        print(f"      ğŸ“„ Salvat: {api_walls_path.name}")
                                        # NotÄƒ: Brute force pentru api_walls_mask va fi executat mai tÃ¢rziu,
                                        # dupÄƒ generarea 02_ai_walls_closed.png (vezi linia ~2814)
                                        
                                except Exception as e:
                                    import traceback
                                    print(f"      âš ï¸ Eroare brute force: {e}")
                                    traceback.print_exc()
                            
                                # Validare mascÄƒ: camere nu trebuie â€inundateâ€ de pixeli pereÈ›i
                                if api_walls_mask is not None and data.get('rooms'):
                                    raster_valid, msg = validate_api_walls_mask(
                                        api_walls_mask, data.get('rooms', [])
                                    )
                                    if raster_valid:
                                        break
                                    if attempt < max_attempts - 1:
                                        print(f"      âš ï¸ Raster mascÄƒ invalidÄƒ ({msg}). ReÃ®ncerc...")
                                    else:
                                        raise RuntimeError(
                                            f"RasterScan a returnat mascÄƒ invalidÄƒ de {max_attempts} ori: {msg}"
                                        )
                                else:
                                    break
                            else:
                                print(f"      âš ï¸ RasterScan API eroare: {response.status_code} - {response.text[:200]}")
                    else:
                        print(f"      âš ï¸ RASTER_API_KEY nu este setat Ã®n environment")
                
                except requests.exceptions.Timeout:
                    print(f"      âš ï¸ RasterScan API timeout (120s)")
                except Exception as e:
                    print(f"      âš ï¸ RasterScan API eroare: {e}")
    
        # âœ… ADAPTIVE STRATEGY (tot Ã®n run_phase != 2)
        LARGE_IMAGE_THRESHOLD = 3000  # px
        USE_TILING = h_orig > LARGE_IMAGE_THRESHOLD or w_orig > LARGE_IMAGE_THRESHOLD
        
        if USE_TILING:
            print(f"   ğŸš€ LARGE IMAGE ({w_orig}x{h_orig}) -> Folosesc TILING ADAPTIV")
            pred_mask = _process_with_adaptive_tiling(
                img, 
                model, 
                device, 
                tile_size=512,
                overlap=64
            )
        else:
            print(f"   ğŸš€ SMALL IMAGE ({w_orig}x{h_orig}) -> Resize Standard la 2048px")
            max_dim = 2048
            scale = min(max_dim / w_orig, max_dim / h_orig, 1.0)
            new_w = int(w_orig * scale)
            new_h = int(h_orig * scale)
            print(f"      Resize: {w_orig}x{h_orig} -> {new_w}x{new_h}")
            input_img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)
            norm_img = 2 * (input_img.astype(np.float32) / 255.0) - 1
            tensor = torch.from_numpy(norm_img).float().permute(2, 0, 1).unsqueeze(0).to(device)
            with torch.no_grad():
                output = model(tensor)
                pred_mask_small = torch.argmax(output[:, 21:33, :, :], dim=1).squeeze().cpu().numpy()
            pred_mask = cv2.resize(
                pred_mask_small.astype('uint8'),
                (w_orig, h_orig),
                interpolation=cv2.INTER_NEAREST
            )
    
    if run_phase != 2:
        # 3. EXTRACT WALLS & FILTER THIN LINES (doar phase 0/1; phase 2 are deja ai_walls_closed pe disc)
        ai_walls_raw = (pred_mask == 2).astype('uint8') * 255
        save_step("01_ai_walls_raw", ai_walls_raw, str(steps_dir))
        
        # ============================================================================
        # FILTRARE LINII SUBÈšIRI + CLOSING ADAPTIV (UNIFIED & ULTRA-PUTERNIC)
        # ============================================================================
        
        min_dim = min(h_orig, w_orig)
    
        # âœ… FILTRARE LINII SUBÈšIRI ADAPTIVÄ‚
        print("      ğŸ§¹ Filtrez linii subÈ›iri false-positive...")
        
        # ADAPTIVE THRESHOLD: Imagini mici = filtrare BALANCED
        if min_dim > 2500:
            # Imagini mari: filtrare normalÄƒ (0.4%)
            min_wall_thickness = max(3, int(min_dim * 0.004))
            iterations = 1
            print(f"         Mode: LARGE IMAGE â†’ Thin filter: {min_wall_thickness}px (0.4%), iter={iterations}")
        else:
            # Imagini mici: filtrare BALANCED (0.7%)
            min_wall_thickness = max(5, int(min_dim * 0.007))
            iterations = 1
            print(f"         Mode: SMALL IMAGE â†’ Balanced filter: {min_wall_thickness}px (0.7%), iter={iterations}")
    
        filter_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (min_wall_thickness, min_wall_thickness))
        walls_eroded = cv2.erode(ai_walls_raw, filter_kernel, iterations=iterations)
        ai_walls_raw = cv2.dilate(walls_eroded, filter_kernel, iterations=iterations)
        
        pixels_removed_pct = 100 * (1 - np.count_nonzero(ai_walls_raw) / (np.count_nonzero(((pred_mask == 2).astype('uint8') * 255)) + 1))
        print(f"         Eliminat {pixels_removed_pct:.1f}% pixeli (linii subÈ›iri)")
        save_step("01a_walls_filtered", ai_walls_raw, str(steps_dir))
    
        # âœ… CLOSING ADAPTIV ULTRA-PUTERNIC (UNIFICAT) - ÃMBUNÄ‚TÄ‚ÈšIT PENTRU VPS
        print("      ğŸ”— Ãnchid gÄƒuri (closing adaptiv)...")
    
        if min_dim > 2500:
            # Imagini mari: closing redus pentru a nu uni pereÈ›i paraleli
            close_kernel_size = max(5, int(min_dim * 0.003))  # Redus Ã®napoi la 0.3%
            close_iterations = 2  # Redus Ã®napoi la 2 iteraÈ›ii
            print(f"         Mode: LARGE IMAGE â†’ Close: {close_kernel_size}px (0.3%), iter={close_iterations}")
        else:
            # Imagini mici: closing redus pentru a nu uni pereÈ›i paraleli
            close_kernel_size = max(12, int(min_dim * 0.010))  # Redus Ã®napoi la 1.0%
            close_iterations = 5  # Redus Ã®napoi la 5 iteraÈ›ii
            print(f"         Mode: SMALL IMAGE â†’ Close: {close_kernel_size}px (1.0%), iter={close_iterations}")
    
        close_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (close_kernel_size, close_kernel_size))
        ai_walls_raw = cv2.morphologyEx(ai_walls_raw, cv2.MORPH_CLOSE, close_kernel, iterations=close_iterations)
        save_step("01b_walls_closed_adaptive", ai_walls_raw, str(steps_dir))
    
        # âœ… PENTRU IMAGINI MARI: ErodÄƒm pereÈ›ii groÈ™i detectaÈ›i de AI
        if h_orig > 1000 or w_orig > 1000:
            print("      ğŸ”ª SubÈ›iez pereÈ›ii detectaÈ›i de AI (Large Image)...")
            thin_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
            ai_walls_raw = cv2.erode(ai_walls_raw, thin_kernel, iterations=1)
            save_step("01c_ai_walls_thinned", ai_walls_raw, str(steps_dir))
    
        # 4. REPARARE PEREÈšI (FINALA)
        print("   ğŸ“ Repar pereÈ›ii...")
    
        LARGE_IMAGE_THRESHOLD = 1000
        
        # Acum, `ai_walls_raw` conÈ›ine deja closing-ul adaptiv
        # Redus agresivitatea: skip bridge_wall_gaps pentru a nu uni pereÈ›i paraleli
        print(f"      ğŸ”§ Skip extra bridging (adaptive closing is enough, bridge_wall_gaps e prea agresiv)")
        ai_walls_closed = ai_walls_raw.copy()
        
        save_step("02_ai_walls_closed", ai_walls_closed, str(steps_dir))
        if run_phase == 1:
            return {"model": model, "device": device}
    
    # ============================================================
    # ğŸ”¥ BRUTE FORCE ALGORITM PENTRU TRANSFORMARE COORDONATE
    # (DupÄƒ generarea 02_ai_walls_closed.png)
    # Folosim cache pentru a evita rularea de mai multe ori
    # ============================================================
    best_config = None
    if steps_dir:
        raster_dir = Path(steps_dir) / "raster"
        if raster_dir.exists():
            # VerificÄƒm dacÄƒ existÄƒ deja configuraÈ›ia salvatÄƒ (cache)
            config_path = raster_dir / "brute_force_best_config.json"
            if config_path.exists():
                try:
                    with open(config_path, 'r') as f:
                        best_config = json.load(f)
                    print(f"\n      âœ… Folosesc configuraÈ›ia brute force din cache")
                except Exception as e:
                    print(f"      âš ï¸ Eroare la citirea cache-ului: {e}")
                    best_config = None
            
            # DacÄƒ nu existÄƒ cache, rulÄƒm brute force pentru api_walls_mask
            if best_config is None:
                try:
                    api_walls_path = raster_dir / "api_walls_mask.png"
                    orig_walls_path = Path(steps_dir) / "02_ai_walls_closed.png"
                    
                    if api_walls_path.exists() and orig_walls_path.exists():
                        api_walls_mask = cv2.imread(str(api_walls_path), cv2.IMREAD_GRAYSCALE)
                        orig_walls = cv2.imread(str(orig_walls_path), cv2.IMREAD_GRAYSCALE)
                        
                        if api_walls_mask is not None and orig_walls is not None:
                            best_config = brute_force_alignment(
                                api_walls_mask,
                                orig_walls,
                                raster_dir,
                                str(steps_dir)
                            )
                except Exception as e:
                    import traceback
                    print(f"      âš ï¸ Eroare brute force pentru api_walls_mask: {e}")
                    traceback.print_exc()
            
            # DacÄƒ avem configuraÈ›ia, aplicÄƒm transformarea È™i generÄƒm crop-ul
            if best_config is not None:
                try:
                    # AplicÄƒm transformarea È™i generÄƒm overlay-ul pe original
                    original_path = Path(steps_dir) / "00_original.png"
                    response_json_path = raster_dir / "response.json"
                    
                    if original_path.exists() and response_json_path.exists():
                        original_img = cv2.imread(str(original_path), cv2.IMREAD_COLOR)
                        if original_img is not None:
                            # Folosim funcÈ›ia existentÄƒ pentru overlay È™i crop
                            api_result = {'raster_dir': raster_dir}
                            api_walls_mask = cv2.imread(str(raster_dir / "api_walls_mask.png"), cv2.IMREAD_GRAYSCALE)
                            
                            if api_walls_mask is not None:
                                # AplicÄƒm transformarea È™i generÄƒm overlay-ul
                                apply_alignment_and_generate_overlay(
                                    best_config,
                                    api_result,
                                    original_img,
                                    str(steps_dir)
                                )
                                
                                # GenerÄƒm crop-ul
                                generate_crop_from_raster(
                                    best_config,
                                    api_walls_mask,
                                    original_img,
                                    api_result
                                )
                                
                                # ============================================================
                                # GENEREZ PEREÈšI DIN COORDONATELE CAMERELOR
                                # (folosind coordonatele din overlay_on_original.png)
                                # ============================================================
                                from .raster_processing import generate_walls_from_room_coordinates
                                
                                # âœ… Wrap Ã®n try-except pentru a permite workflow-ul sÄƒ continue chiar dacÄƒ generarea pereÈ›ilor eÈ™ueazÄƒ
                                walls_result = None
                                try:
                                    walls_result = generate_walls_from_room_coordinates(
                                        original_img,
                                        best_config,
                                        raster_dir,
                                        str(steps_dir),
                                        gemini_api_key
                                    )
                                except Exception as walls_error:
                                    import traceback
                                    print(f"      âš ï¸ Eroare la generarea pereÈ›ilor din coordonate: {walls_error}")
                                    traceback.print_exc()
                                    # âœ… VerificÄƒm dacÄƒ room_scales.json a fost salvat Ã®n ciuda erorii
                                    room_scales_path = Path(steps_dir) / "raster_processing" / "walls_from_coords" / "room_scales.json"
                                    if room_scales_path.exists():
                                        print(f"      âœ… room_scales.json a fost salvat Ã®n ciuda erorii, workflow-ul poate continua")
                                    else:
                                        print(f"      âš ï¸ room_scales.json nu existÄƒ, workflow-ul va folosi fallback-ul")
                                
                                if walls_result:
                                    print(f"      âœ… Generat pereÈ›i din coordonatele camerelor")
                                    # StocÄƒm walls_result pentru a-l folosi la calculul mÄƒsurÄƒtorilor
                                    walls_result_from_coords = walls_result
                except Exception as e:
                    import traceback
                    print(f"      âš ï¸ Eroare aplicare transformare: {e}")
                    traceback.print_exc()
    
    # 4b. WORKFLOW REORGANIZAT:
    # 1. Detectare scÄƒri + completare pereÈ›i scÄƒri
    # 2. Umplere gÄƒuri mici dintre pereÈ›i
    
    print("   ğŸ¡ Pas 1: Detectare scÄƒri + completare pereÈ›i...")
    # DetecteazÄƒ scÄƒrile folosind detecÈ›iile Roboflow È™i completeazÄƒ pereÈ›ii
    # ÃncercÄƒm sÄƒ citim detecÈ›iile pentru scÄƒri din export_objects/detections.json
    stairs_bboxes = []
    try:
        # CÄƒutÄƒm directorul de output pentru a gÄƒsi detecÈ›iile
        detections_json_path = Path(output_dir) / "export_objects" / "detections.json"
        if not detections_json_path.exists():
            # ÃncercÄƒm È™i varianta cu count_objects
            detections_json_path = Path(output_dir).parent / "count_objects" / "export_objects" / "detections.json"
        
        if detections_json_path.exists():
            with open(detections_json_path, 'r', encoding='utf-8') as f:
                detections_data = json.load(f)
            
            # Extragem detecÈ›iile pentru scÄƒri
            predictions = detections_data.get("predictions", [])
            for pred in predictions:
                if pred.get("class", "").lower() == "stairs" or pred.get("class_name", "").lower() == "stairs":
                    x = pred.get("x", 0)
                    y = pred.get("y", 0)
                    width = pred.get("width", 0)
                    height = pred.get("height", 0)
                    # Convertim din format (cx, cy, w, h) la (x1, y1, x2, y2)
                    x1 = x - width / 2
                    y1 = y - height / 2
                    x2 = x + width / 2
                    y2 = y + height / 2
                    stairs_bboxes.append((x1, y1, x2, y2))
            
            if stairs_bboxes:
                print(f"         ğŸ“ GÄƒsit {len(stairs_bboxes)} detecÈ›ie/ii pentru scÄƒri Ã®n {detections_json_path.name}")
            else:
                print(f"         âš ï¸ Nu s-au gÄƒsit detecÈ›ii pentru scÄƒri Ã®n {detections_json_path.name}")
        else:
            print(f"         âš ï¸ Nu s-a gÄƒsit fiÈ™ierul de detecÈ›ii: {detections_json_path}")
    except Exception as e:
        print(f"         âš ï¸ Eroare la citirea detecÈ›iilor pentru scÄƒri: {e}")
    
    # DetecteazÄƒ scÄƒrile È™i completeazÄƒ pereÈ›ii
    ai_walls_stairs = fill_stairs_room(ai_walls_closed, stairs_bboxes, steps_dir=str(steps_dir))
    if ai_walls_stairs is None:
        print(f"      âš ï¸ fill_stairs_room a returnat None. Folosesc ai_walls_closed.")
        ai_walls_stairs = ai_walls_closed.copy()
    
    # Pas 1b: Repar pereÈ›ii exteriori folosind envelope-ul casei (doar completare pereÈ›i, nu final)
    # Acest pas completeazÄƒ golurile din pereÈ›ii exteriori Ã®nainte de paÈ™ii normali de procesare
    # ai_walls_stairs include deja pereÈ›ii adÄƒugaÈ›i pentru terasÄƒ/garaj/scÄƒri, deci envelope-ul
    # va include automat aceste zone Ã®n calcul
    ai_walls_repaired_house = repair_house_walls_with_floodfill(ai_walls_stairs, steps_dir=str(steps_dir))
    if ai_walls_repaired_house is None:
        print("      âš ï¸ repair_house_walls_with_floodfill a eÈ™uat. Folosesc ai_walls_stairs.")
        ai_walls_repaired_house = ai_walls_stairs.copy()
    
    # Folosim direct rezultatul de la reparare
    ai_walls_final = ai_walls_repaired_house.copy()
    
    # VerificÄƒm dacÄƒ existÄƒ crop-ul generat de RasterScan
    raster_dir = Path(steps_dir) / "raster" if steps_dir else None
    crop_path = raster_dir / "00_original_crop.png" if raster_dir and raster_dir.exists() else None
    crop_info_path = raster_dir / "crop_info.json" if raster_dir and raster_dir.exists() else None
    
    use_crop = False
    crop_img = None
    crop_info = None
    api_walls_mask_crop = None
    
    if crop_path and crop_path.exists() and crop_info_path and crop_info_path.exists():
        try:
            crop_img = cv2.imread(str(crop_path), cv2.IMREAD_COLOR)
            if crop_img is not None:
                with open(crop_info_path, 'r') as f:
                    crop_info = json.load(f)
                
                # ÃncÄƒrcÄƒm È™i api_walls_mask pentru a-l folosi Ã®n loc de ai_walls_final
                api_walls_path = raster_dir / "api_walls_mask.png"
                if api_walls_path.exists():
                    api_walls_mask_crop = cv2.imread(str(api_walls_path), cv2.IMREAD_GRAYSCALE)
                    if api_walls_mask_crop is not None:
                        use_crop = True
                        print(f"   âœ… Folosesc crop-ul generat de RasterScan ({crop_info['width']}x{crop_info['height']}px)")
                        # Folosim api_walls_mask_crop Ã®n loc de ai_walls_final pentru calcule
                        ai_walls_final = api_walls_mask_crop.copy()
                        h_orig, w_orig = crop_img.shape[:2]
                        # ActualizÄƒm È™i img pentru a folosi crop-ul
                        img = crop_img.copy()
                    else:
                        print(f"   âš ï¸ Nu am putut Ã®ncÄƒrca api_walls_mask.png, folosesc workflow-ul normal")
                else:
                    print(f"   âš ï¸ api_walls_mask.png nu existÄƒ, folosesc workflow-ul normal")
            else:
                print(f"   âš ï¸ Nu am putut Ã®ncÄƒrca crop-ul, folosesc workflow-ul normal")
        except Exception as e:
            print(f"   âš ï¸ Eroare la Ã®ncÄƒrcarea crop-ului: {e}, folosesc workflow-ul normal")
    
    if use_crop:
        # WORKFLOW CU RASTERSCAN CROP
        print(f"   ğŸ”„ Workflow cu RasterScan crop...")
        
        # 1. Generez imagine cu masca RasterScan peste crop
        if crop_img is not None and api_walls_mask_crop is not None:
            # SalvÄƒm Ã®n folderul raster (unde sunt È™i celelalte imagini RasterScan)
            raster_output_path = raster_dir / "walls_overlay_on_crop.png"
            generate_raster_walls_overlay(
                crop_img,
                api_walls_mask_crop,
                raster_output_path
            )
            print(f"      âœ… Generat overlay: {raster_output_path.name}")
        
        # âš ï¸ NU mai generÄƒm rooms_overlay_on_crop.png aici - rooms.png nu mai este generat la pasul 1
        # rooms.png va fi generat DUPÄ‚ validarea pereÈ›ilor Ã®n raster_processing
        
        # 2. Detectare interior/exterior folosind masca RasterScan
        indoor_mask, outdoor_mask = detect_interior_exterior_from_raster(
            api_walls_mask_crop,
            steps_dir=str(steps_dir)
        )
        
        # 3. Citim scala din room_scales.json generat de RasterScan (NU calculÄƒm din nou!)
        if crop_img is not None:
            # âœ… Scala a fost deja calculatÄƒ de RasterScan Ã®n generate_walls_from_room_coordinates
            # Citim direct din room_scales.json
            room_scales_path = Path(steps_dir) / "raster_processing" / "walls_from_coords" / "room_scales.json"
            
            if room_scales_path.exists():
                try:
                    with open(room_scales_path, 'r', encoding='utf-8') as f:
                        room_scales_data = json.load(f)
                    
                    # ÃncercÄƒm sÄƒ citim m_px direct
                    m_px = room_scales_data.get('m_px')
                    
                    # DacÄƒ nu existÄƒ m_px, calculÄƒm din total_area_m2 È™i total_area_px
                    if m_px is None or m_px <= 0:
                        total_area_m2 = room_scales_data.get('total_area_m2', 0)
                        total_area_px = room_scales_data.get('total_area_px', 0)
                        if total_area_px > 0 and total_area_m2 > 0:
                            m_px = np.sqrt(total_area_m2 / total_area_px)
                            print(f"   âœ… Calculat m_px din total_area: {m_px:.9f} m/px")
                        else:
                            raise RuntimeError("Nu am putut determina scala din room_scales.json (lipsesc total_area_m2 sau total_area_px)")
                    else:
                        print(f"   âœ… Scala din RasterScan (room_scales.json): {m_px:.9f} m/px")
                    
                    # VerificÄƒm cÄƒ avem m_px valid
                    if m_px is None or m_px <= 0:
                        raise RuntimeError("m_px invalid din room_scales.json")
                    
                    # NumÄƒrÄƒm camerele folosite pentru calcularea scalei
                    room_scales = room_scales_data.get('room_scales', {})
                    rooms_used = len(room_scales) if isinstance(room_scales, dict) else 0
                    
                    # âœ… Construim scale_result pentru return (compatibil cu workflow-ul normal)
                    scale_result = {
                        "meters_per_pixel": float(m_px),
                        "method": "raster_scan",
                        "confidence": "high" if rooms_used >= 3 else "medium",
                        "source": "room_scales.json",
                        "rooms_used": rooms_used,  # âœ… Necesar pentru scale/jobs.py
                        "optimization_info": {
                            "method": "raster_scan_direct",
                            "rooms_count": rooms_used
                        },
                        "per_room": []  # ListÄƒ goalÄƒ pentru compatibilitate
                    }
                    
                except Exception as e:
                    import traceback
                    print(f"   âš ï¸ Eroare la citirea room_scales.json: {e}")
                    traceback.print_exc()
                    # âœ… ÃncercÄƒm sÄƒ creÄƒm un fiÈ™ier minimal pentru a permite workflow-ul sÄƒ continue
                    try:
                        output_dir = Path(steps_dir) / "raster_processing" / "walls_from_coords"
                        output_dir.mkdir(parents=True, exist_ok=True)
                        minimal_data = {
                            'rooms': {},
                            'total_area_m2': 0.0,
                            'total_area_px': 0,
                            'm_px': None,
                            'weighted_average_m_px': None,
                            'room_scales': {},
                            'error': f"Eroare la citire: {str(e)}"
                        }
                        with open(room_scales_path, 'w', encoding='utf-8') as f:
                            json.dump(minimal_data, f, indent=2, ensure_ascii=False)
                        print(f"   âš ï¸ Creat room_scales.json minimal pentru compatibilitate")
                    except Exception as e2:
                        print(f"   âŒ Nu am putut crea room_scales.json minimal: {e2}")
                    raise RuntimeError(f"Nu am putut citi scala din RasterScan: {e}")
            else:
                # âœ… Ãn loc sÄƒ aruncÄƒm eroare imediat, Ã®ncercÄƒm sÄƒ creÄƒm un fiÈ™ier minimal
                print(f"   âš ï¸ room_scales.json nu existÄƒ la {room_scales_path}")
                try:
                    output_dir = Path(steps_dir) / "raster_processing" / "walls_from_coords"
                    output_dir.mkdir(parents=True, exist_ok=True)
                    minimal_data = {
                        'rooms': {},
                        'total_area_m2': 0.0,
                        'total_area_px': 0,
                        'm_px': None,
                        'weighted_average_m_px': None,
                        'room_scales': {},
                        'error': 'FiÈ™ierul nu a fost generat de RasterScan'
                    }
                    with open(room_scales_path, 'w', encoding='utf-8') as f:
                        json.dump(minimal_data, f, indent=2, ensure_ascii=False)
                    print(f"   âš ï¸ Creat room_scales.json minimal pentru compatibilitate")
                    print(f"   âš ï¸ Workflow-ul va continua, dar scale-ul va trebui calculat altfel")
                except Exception as e2:
                    print(f"   âŒ Nu am putut crea room_scales.json minimal: {e2}")
                raise RuntimeError(f"room_scales.json nu existÄƒ la {room_scales_path}. RasterScan trebuie sÄƒ genereze acest fiÈ™ier Ã®nainte.")
        else:
            raise RuntimeError("crop_img este None!")
        
        # 4. Generez pereÈ›i interiori È™i exteriori cu 1px
        walls_int_1px, walls_ext_1px = generate_walls_interior_exterior(
            api_walls_mask_crop,
            indoor_mask,
            outdoor_mask,
            steps_dir=str(steps_dir)
        )
        
        # 5. Generez structurÄƒ pereÈ›i interiori
        walls_int_structure = generate_interior_structure_walls(
            api_walls_mask_crop,
            walls_int_1px,
            steps_dir=str(steps_dir)
        )
        
        # ActualizÄƒm ai_walls_final pentru mÄƒsurÄƒtori
        ai_walls_final = api_walls_mask_crop.copy()
        
        # Variabile pentru mÄƒsurÄƒtori (folosim pereÈ›ii cu 1px)
        walls_int_1px_for_measurements = walls_int_1px
        walls_ext_1px_for_measurements = walls_ext_1px
        walls_int_structure_for_measurements = walls_int_structure
        
    else:
        # WORKFLOW NORMAL (FÄ‚RÄ‚ CROP RASTERSCAN)
        print(f"   â„¹ï¸ Folosesc workflow-ul normal (fÄƒrÄƒ crop RasterScan)")
        
        # Kernel repair pentru restul procesÄƒrii
        min_dim = min(h_orig, w_orig) 
        rep_k = max(3, int(min_dim * 0.005))
        if rep_k % 2 == 0: rep_k += 1
        kernel_repair = cv2.getStructuringElement(cv2.MORPH_RECT, (rep_k, rep_k))

        # 7. ZONE
        print("   ğŸŒŠ Analizez zonele...")
        
        walls_thick = cv2.dilate(ai_walls_final, kernel_repair, iterations=3)
        
        h_pad, w_pad = h_orig + 2, w_orig + 2
        pad_walls = np.zeros((h_pad, w_pad), dtype=np.uint8)
        pad_walls[1:h_orig+1, 1:w_orig+1] = walls_thick
        
        inv_pad_walls = cv2.bitwise_not(pad_walls)
        flood_mask = np.zeros((h_pad+2, w_pad+2), dtype=np.uint8)
        cv2.floodFill(inv_pad_walls, flood_mask, (0, 0), 128)
        
        outdoor_mask = (inv_pad_walls[1:h_orig+1, 1:w_orig+1] == 128).astype(np.uint8) * 255
        
        kernel_grow = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        free_space = cv2.bitwise_not(ai_walls_final)
        
        for _ in range(30):
            outdoor_mask = cv2.bitwise_and(cv2.dilate(outdoor_mask, kernel_grow), free_space)
        
        save_step("03_outdoor_mask", outdoor_mask, str(steps_dir))
        
        total_space = np.ones_like(outdoor_mask) * 255
        occupied = cv2.bitwise_or(outdoor_mask, ai_walls_final)
        indoor_mask = cv2.subtract(total_space, occupied)
        
        vis_indoor = np.zeros((h_orig, w_orig, 3), dtype=np.uint8)
        vis_indoor[indoor_mask > 0] = [0, 255, 255]
        save_step("debug_zone_interior", vis_indoor, str(steps_dir))

        # 8. SCALE DETECTION
        print("   ğŸ” Determin scala...")
        image_for_scale = str(image_path)
        scale_result = detect_scale_from_room_labels(
            image_for_scale,
            indoor_mask,
            ai_walls_final,
            str(steps_dir),
            api_key=gemini_api_key
        )
        
        if not scale_result:
            raise RuntimeError("Nu am putut determina scala!")
        
        m_px = scale_result["meters_per_pixel"]
        
        # Variabile pentru mÄƒsurÄƒtori (workflow normal)
        walls_int_1px_for_measurements = None
        walls_ext_1px_for_measurements = None
        walls_int_structure_for_measurements = None

    # 9. MÄ‚SURÄ‚TORI
    print("   ğŸ“ Calculez mÄƒsurÄƒtori...")
    
    # IniÈ›ializÄƒm variabilele pentru mÄƒsurÄƒtori
    px_len_ext = 0
    px_len_int = 0
    px_len_skeleton_ext = 0
    px_len_skeleton_structure_int = 0
    
    # VerificÄƒm dacÄƒ avem rezultate din raster_processing (pereÈ›i din coordonatele camerelor)
    use_raster_measurements = False
    if walls_result_from_coords and walls_result_from_coords.get('m_px'):
        use_raster_measurements = True
        print(f"      âœ… Folosesc mÄƒsurÄƒtorile din raster_processing (pereÈ›i din coordonatele camerelor)")
        
        # ÃncÄƒrcÄƒm imaginile generate
        raster_processing_dir = Path(steps_dir) / "raster_processing" / "walls_from_coords"
        
        # Lungimi structurÄƒ (din imagini 11 È™i 12)
        interior_structure_img_path = raster_processing_dir / "11_interior_structure.png"
        exterior_structure_img_path = raster_processing_dir / "12_exterior_structure.png"
        
        # Suprafete finisaje (din imagini 07 È™i 08)
        walls_interior_img_path = raster_processing_dir / "07_walls_interior.png"
        walls_exterior_img_path = raster_processing_dir / "08_walls_exterior.png"
        
        # Metri per pixel din room_scales.json
        m_px_raster = walls_result_from_coords.get('m_px')
        
        if m_px_raster and interior_structure_img_path.exists() and exterior_structure_img_path.exists():
            # ÃncÄƒrcÄƒm imaginile
            interior_structure_img = cv2.imread(str(interior_structure_img_path), cv2.IMREAD_GRAYSCALE)
            exterior_structure_img = cv2.imread(str(exterior_structure_img_path), cv2.IMREAD_GRAYSCALE)
            
            if interior_structure_img is not None and exterior_structure_img is not None:
                # CalculÄƒm lungimile structurii (numÄƒr de pixeli * m_px)
                px_len_skeleton_structure_int = int(np.count_nonzero(interior_structure_img > 0))
                px_len_skeleton_ext = int(np.count_nonzero(exterior_structure_img > 0))
                
                # Folosim m_px din room_scales.json
                m_px = m_px_raster
                
                # CalculÄƒm lungimile structurii Ã®n metri
                walls_skeleton_structure_int_m = px_len_skeleton_structure_int * m_px
                walls_skeleton_ext_m = px_len_skeleton_ext * m_px
                
                print(f"         ğŸ“ StructurÄƒ interior: {px_len_skeleton_structure_int} px = {walls_skeleton_structure_int_m:.2f} m")
                print(f"         ğŸ“ StructurÄƒ exterior: {px_len_skeleton_ext} px = {walls_skeleton_ext_m:.2f} m")
        
        # Suprafete finisaje (din imagini 07 È™i 08)
        if walls_interior_img_path.exists() and walls_exterior_img_path.exists():
            walls_interior_img = cv2.imread(str(walls_interior_img_path), cv2.IMREAD_GRAYSCALE)
            walls_exterior_img = cv2.imread(str(walls_exterior_img_path), cv2.IMREAD_GRAYSCALE)
            
            if walls_interior_img is not None and walls_exterior_img is not None:
                # CalculÄƒm lungimile pentru finisaje (numÄƒr de pixeli * m_px)
                px_len_int = int(np.count_nonzero(walls_interior_img > 0))
                px_len_ext = int(np.count_nonzero(walls_exterior_img > 0))
                
                # CalculÄƒm lungimile Ã®n metri
                walls_int_m = px_len_int * m_px
                walls_ext_m = px_len_ext * m_px
                
                print(f"         ğŸ¨ Finisaje interior: {px_len_int} px = {walls_int_m:.2f} m")
                print(f"         ğŸ¨ Finisaje exterior: {px_len_ext} px = {walls_ext_m:.2f} m")
        
        # Suprafete camere din room_scales.json
        room_scales = walls_result_from_coords.get('room_scales', {})
        if room_scales:
            total_area_m2_raster = walls_result_from_coords.get('total_area_m2', 0.0)
            total_area_px_raster = walls_result_from_coords.get('total_area_px', 0)
            
            print(f"         ğŸ  Suprafete camere: {total_area_m2_raster:.2f} mÂ² ({len(room_scales)} camere)")
    
    if not use_raster_measurements:
        if use_crop:
            # Folosim pereÈ›ii cu 1px generaÈ›i anterior
            px_len_ext = int(np.count_nonzero(walls_ext_1px_for_measurements))
            px_len_int = int(np.count_nonzero(walls_int_1px_for_measurements))
            px_len_skeleton_ext = px_len_ext  # Pentru consistenÈ›Äƒ
            px_len_skeleton_structure_int = int(np.count_nonzero(walls_int_structure_for_measurements))
        else:
            # Workflow normal - calculÄƒm outline
            outline = get_strict_1px_outline(ai_walls_final)
            touch_zone = cv2.dilate(outdoor_mask, kernel_grow, iterations=2)
            
            outline_ext_mask = cv2.bitwise_and(outline, touch_zone)
            outline_int_mask = cv2.subtract(outline, outline_ext_mask)
            
            # CalculÄƒm lungimea pereÈ›ilor exteriori (din outline)
            px_len_skeleton_ext = int(np.count_nonzero(outline_ext_mask))
            
            # Lungimea structurii pereÈ›ilor interiori (folosim outline interior)
            px_len_skeleton_structure_int = int(np.count_nonzero(outline_int_mask))
            
            # Lungimi din outline (pentru finisaje)
            px_len_ext = int(np.count_nonzero(outline_ext_mask))
            px_len_int = int(np.count_nonzero(outline_int_mask))
    
    # Arii
    px_area_indoor = int(np.count_nonzero(indoor_mask))
    px_area_total = int(np.count_nonzero(cv2.bitwise_not(outdoor_mask)))

    # Conversii Ã®n metri
    walls_ext_m = px_len_ext * m_px  # Pentru finisaje
    walls_int_m = px_len_int * m_px  # Pentru finisaje
    
    # Lungimi din skeleton (pentru structurÄƒ)
    walls_skeleton_ext_m = px_len_skeleton_ext * m_px
    walls_skeleton_structure_int_m = px_len_skeleton_structure_int * m_px  # StructurÄƒ pereÈ›i interiori (din outline)
    
    area_indoor_m2 = px_area_indoor * (m_px ** 2)
    area_total_m2 = px_area_total * (m_px ** 2)

    measurements = {
        "pixels": {
            "walls_len_ext": int(px_len_ext),
            "walls_len_int": int(px_len_int),
            "walls_skeleton_ext": int(px_len_skeleton_ext),
            "walls_skeleton_structure_int": int(px_len_skeleton_structure_int),
            "indoor_area": int(px_area_indoor),
            "total_area": int(px_area_total)
        },
        "metrics": {
            "scale_m_per_px": float(m_px),
            "walls_ext_m": float(round(walls_ext_m, 2)),  # Pentru finisaje
            "walls_int_m": float(round(walls_int_m, 2)),  # Pentru finisaje
            "walls_skeleton_ext_m": float(round(walls_skeleton_ext_m, 2)),
            "walls_skeleton_structure_int_m": float(round(walls_skeleton_structure_int_m, 2)),  # Pentru structurÄƒ pereÈ›i interiori
            "area_indoor_m2": float(round(area_indoor_m2, 2)),
            "area_total_m2": float(round(area_total_m2, 2))
        }
    }

    print(f"   âœ… ScarÄƒ: {m_px:.9f} m/px")
    print(f"   ğŸ  Arie Indoor: {area_indoor_m2:.2f} mÂ²")
    print(f"   ğŸ“ Lungimi pereÈ›i:")
    print(f"      - Exterior (outline): {walls_ext_m:.2f} m (pentru finisaje)")
    print(f"      - Interior (outline): {walls_int_m:.2f} m (pentru finisaje)")
    print(f"      - Skeleton exterior (din outline): {walls_skeleton_ext_m:.2f} m")
    print(f"      - StructurÄƒ interior (din outline): {walls_skeleton_structure_int_m:.2f} m")
    
    # âœ… SalveazÄƒ walls_measurements Ã®ntr-un fiÈ™ier separat pentru pricing (FÄ‚RÄ‚ dependenÈ›Äƒ de CubiCasa)
    if steps_dir:
        raster_processing_dir = Path(steps_dir) / "raster_processing" / "walls_from_coords"
        raster_processing_dir.mkdir(parents=True, exist_ok=True)
        walls_measurements_file = raster_processing_dir / "walls_measurements.json"
        walls_measurements_data = {
            "estimations": {
                "average_result": {
                    "interior_meters": float(round(walls_int_m, 2)),
                    "exterior_meters": float(round(walls_ext_m, 2)),
                    "interior_meters_structure": float(round(walls_skeleton_structure_int_m, 2))
                }
            }
        }
        with open(walls_measurements_file, "w", encoding="utf-8") as f:
            json.dump(walls_measurements_data, f, indent=2, ensure_ascii=False)
        print(f"   ğŸ’¾ Salvat: walls_measurements.json (pentru pricing)")
    
    # 10. FILTRARE ZGOMOT CU MASCÄ‚ ZONÄ‚ INTERIOARÄ‚ (Ã®nainte de generarea 3D)
    print("   ğŸ¨ Filtrez zgomotul de fundal cu masca zonei interioare...")
    
    # ÃncÄƒrcÄƒm masca din debug_zone_interior.png
    debug_mask_path = Path(steps_dir) / "debug_zone_interior.png"
    interior_zone_mask = None
    
    if debug_mask_path.exists():
        debug_mask_img = cv2.imread(str(debug_mask_path), cv2.IMREAD_COLOR)
        if debug_mask_img is not None:
            # debug_zone_interior are culoarea galbenÄƒ (cyan Ã®n BGR: [0, 255, 255]) pentru zona interioarÄƒ
            b, g, r = cv2.split(debug_mask_img)
            # Extragem masca: zona interioarÄƒ este unde componenta verde este mare
            interior_zone_mask = (g > 128).astype(np.uint8) * 255
            
            # RedimensionÄƒm dacÄƒ e necesar
            if interior_zone_mask.shape[:2] != ai_walls_final.shape[:2]:
                interior_zone_mask = cv2.resize(interior_zone_mask, (ai_walls_final.shape[1], ai_walls_final.shape[0]), interpolation=cv2.INTER_NEAREST)
            
            # CalculÄƒm grosimea medie a pereÈ›ilor pentru marjÄƒ de eroare
            dist_from_edge = cv2.distanceTransform(ai_walls_final, cv2.DIST_L2, 5)
            wall_thicknesses = dist_from_edge[ai_walls_final > 0] * 2
            if len(wall_thicknesses) > 0:
                avg_thickness = np.median(wall_thicknesses)
                margin_size = max(3, int(round(avg_thickness)))
                
                print(f"      ğŸ“ Grosime medie pereÈ›i: {avg_thickness:.2f}px, marjÄƒ de eroare: {margin_size}px")
                
                # DilatÄƒm masca zonei interioare cu marja de eroare (grosimea pereÈ›ilor)
                kernel_margin = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (margin_size * 2 + 1, margin_size * 2 + 1))
                interior_zone_mask_dilated = cv2.dilate(interior_zone_mask, kernel_margin, iterations=1)
                
                # AplicÄƒm masca pe pereÈ›i: pÄƒstrÄƒm doar pereÈ›ii din zona interioarÄƒ (cu marjÄƒ)
                ai_walls_final_filtered = cv2.bitwise_and(ai_walls_final, interior_zone_mask_dilated)
                
                # Folosim pereÈ›ii filtraÈ›i pentru generarea 3D
                ai_walls_for_3d = ai_walls_final_filtered
                
                removed_pixels = np.count_nonzero(ai_walls_final) - np.count_nonzero(ai_walls_final_filtered)
                print(f"      âœ… Eliminat {removed_pixels:,} pixeli de zgomot din afara zonei interioare")
            else:
                ai_walls_for_3d = ai_walls_final
                print(f"      âš ï¸ Nu s-a putut calcula grosimea, folosesc pereÈ›ii fÄƒrÄƒ filtrare")
        else:
            ai_walls_for_3d = ai_walls_final
            print(f"      âš ï¸ Nu s-a putut Ã®ncÄƒrca masca, folosesc pereÈ›ii fÄƒrÄƒ filtrare")
    else:
        ai_walls_for_3d = ai_walls_final
        print(f"      âš ï¸ MascÄƒ lipsÄƒ, folosesc pereÈ›ii fÄƒrÄƒ filtrare")
    
    # 10. GENERARE 3D (cu pereÈ›ii filtraÈ›i - zgomotul a fost eliminat Ã®nainte)
    export_walls_to_obj(
        ai_walls_for_3d, 
        output_dir / "walls_3d.obj", 
        m_px, 
        image_output_path=output_dir / "walls_3d_view.png"
    )

    # 11. VIZUALIZÄ‚RI
    overlay = img.copy()
    # VerificÄƒm dacÄƒ outline_ext_mask È™i outline_int_mask sunt definite
    try:
        if 'outline_ext_mask' in locals() and outline_ext_mask is not None:
            overlay[outline_ext_mask > 0] = [255, 0, 0]
        if 'outline_int_mask' in locals() and outline_int_mask is not None:
            overlay[outline_int_mask > 0] = [0, 255, 0]
        cv2.imwrite(str(output_dir / "visualization_overlay.png"), overlay)
    except (NameError, UnboundLocalError):
        # DacÄƒ nu sunt definite (workflow cu RasterScan crop), folosim pereÈ›ii direct dacÄƒ existÄƒ
        try:
            if 'walls_ext_1px_for_measurements' in locals() and walls_ext_1px_for_measurements is not None:
                overlay[walls_ext_1px_for_measurements > 0] = [255, 0, 0]
            if 'walls_int_1px_for_measurements' in locals() and walls_int_1px_for_measurements is not None:
                overlay[walls_int_1px_for_measurements > 0] = [0, 255, 0]
            cv2.imwrite(str(output_dir / "visualization_overlay.png"), overlay)
        except (NameError, UnboundLocalError):
            # DacÄƒ niciunul nu este disponibil, salvÄƒm overlay-ul fÄƒrÄƒ modificÄƒri
            cv2.imwrite(str(output_dir / "visualization_overlay.png"), overlay)
    
    return {
        "scale_result": scale_result,
        "measurements": measurements,
        "masks": {
            "visualization": str(output_dir / "visualization_overlay.png"),
            "visualization_3d": str(output_dir / "walls_3d_view.png"),
            "interior_walls_skeleton": str(steps_dir / "04_interior_walls_skeleton.png")
        }
    }