# file: engine/cubicasa_detector/ocr_room_filling.py
"""
Module pentru detectarea textului prin OCR È™i umplerea camerelor (terasÄƒ, garaj, scÄƒri).
"""

from __future__ import annotations

import cv2
import numpy as np
from pathlib import Path

# OCR pentru detectarea textului
try:
    import pytesseract
    TESSERACT_AVAILABLE = True
except ImportError:
    TESSERACT_AVAILABLE = False
    print("âš ï¸ pytesseract nu este disponibil. Detectarea textului va fi dezactivatÄƒ.")


def preprocess_image_for_ocr(image: np.ndarray) -> np.ndarray:
    """
    PreproceseazÄƒ imaginea pentru a Ã®mbunÄƒtÄƒÈ›i detecÈ›ia OCR.
    
    AplicÄƒ:
    - Conversie la grayscale dacÄƒ este color
    - Contrast enhancement (CLAHE)
    - Sharpening
    - Thresholding adaptiv pentru text clar
    
    Args:
        image: Imaginea de preprocesat (BGR sau grayscale)
    
    Returns:
        Imaginea preprocesatÄƒ (grayscale)
    """
    # Convertim la grayscale dacÄƒ este color
    if len(image.shape) == 3:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray = image.copy()
    
    # 1. Contrast enhancement cu CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(gray)
    
    # 2. Sharpening pentru a face textul mai clar
    kernel_sharpen = np.array([[-1, -1, -1],
                               [-1,  9, -1],
                               [-1, -1, -1]])
    sharpened = cv2.filter2D(enhanced, -1, kernel_sharpen)
    
    # 3. Denoising (reducere zgomot)
    denoised = cv2.fastNlMeansDenoising(sharpened, None, h=10, templateWindowSize=7, searchWindowSize=21)
    
    # 4. Thresholding adaptiv pentru text clar (opÈ›ional, dar poate ajuta)
    # Nu aplicÄƒm thresholding direct, ci pÄƒstrÄƒm imaginea grayscale pentru OCR
    # OCR-ul funcÈ›ioneazÄƒ mai bine pe imagini grayscale cu contrast bun
    
    return denoised


def _reconstruct_word_from_chars(chars_list, search_terms, max_horizontal_distance=50, max_vertical_distance=10):
    """
    Reconstituie cuvÃ¢ntul complet din caracterele detectate individual.
    
    Args:
        chars_list: Lista de caractere detectate: [(x, y, width, height, text, conf), ...]
        search_terms: Lista de termeni de cÄƒutat
        max_horizontal_distance: DistanÈ›a maximÄƒ orizontalÄƒ Ã®ntre caractere pentru a fi considerate parte din acelaÈ™i cuvÃ¢nt
        max_vertical_distance: DistanÈ›a maximÄƒ verticalÄƒ Ã®ntre caractere pentru a fi considerate pe aceeaÈ™i linie
    
    Returns:
        Lista de cuvinte reconstituite: [(x, y, width, height, text, conf), ...]
    """
    if not chars_list:
        return []
    
    # SortÄƒm caracterele de la stÃ¢nga la dreapta, apoi de sus Ã®n jos
    sorted_chars = sorted(chars_list, key=lambda c: (c[1], c[0]))  # Sort by y, then x
    
    reconstructed_words = []
    
    # Pentru fiecare termen cÄƒutat, Ã®ncercÄƒm sÄƒ reconstituim cuvÃ¢ntul
    for search_term in search_terms:
        search_term_lower = search_term.lower()
        term_length = len(search_term_lower)
        
        # GrupÄƒm caracterele care sunt pe aceeaÈ™i linie (aproximativ)
        lines = []
        current_line = [sorted_chars[0]]
        
        for char in sorted_chars[1:]:
            prev_char = current_line[-1]
            # VerificÄƒm dacÄƒ caracterul este pe aceeaÈ™i linie (similar y)
            y_diff = abs(char[1] - prev_char[1])
            if y_diff <= max_vertical_distance:
                current_line.append(char)
            else:
                if current_line:
                    lines.append(current_line)
                current_line = [char]
        
        if current_line:
            lines.append(current_line)
        
        # Pentru fiecare linie, Ã®ncercÄƒm sÄƒ gÄƒsim secvenÈ›a care formeazÄƒ cuvÃ¢ntul
        for line in lines:
            # SortÄƒm caracterele din linie de la stÃ¢nga la dreapta
            line_sorted = sorted(line, key=lambda c: c[0])
            
            # CÄƒutÄƒm secvenÈ›e de caractere care pot forma cuvÃ¢ntul
            for start_idx in range(len(line_sorted)):
                # VerificÄƒm dacÄƒ primul caracter face parte din cuvÃ¢ntul cÄƒutat
                first_char_text = line_sorted[start_idx][4].lower()  # text
                
                # VerificÄƒm dacÄƒ primul caracter se potriveÈ™te cu prima literÄƒ din termen
                # OCR poate detecta un singur caracter sau un grup de caractere
                if search_term_lower[0] not in first_char_text:
                    continue
                
                # Construim cuvÃ¢ntul de la acest caracter
                used_indices = [start_idx]
                x_start = line_sorted[start_idx][0]
                y_start = line_sorted[start_idx][1]
                x_end = x_start + line_sorted[start_idx][2]
                y_end = y_start + line_sorted[start_idx][3]
                conf_sum = line_sorted[start_idx][5]
                conf_count = 1
                
                # CÄƒutÄƒm caracterele urmÄƒtoare
                # Construim cuvÃ¢ntul caracter cu caracter, verificÃ¢nd dacÄƒ fiecare caracter detectat
                # se potriveÈ™te cu urmÄƒtoarea literÄƒ din termenul cÄƒutat
                reconstructed_chars = list(first_char_text)  # Lista de caractere reconstituite
                
                for term_idx in range(1, term_length):
                    target_char = search_term_lower[term_idx]
                    
                    # VerificÄƒm dacÄƒ avem deja caracterul Ã®n reconstructed
                    if term_idx < len(reconstructed_chars):
                        # Caracterul a fost deja adÄƒugat (poate fi parte dintr-un grup de caractere detectat)
                        continue
                    
                    # CÄƒutÄƒm urmÄƒtorul caracter care se potriveÈ™te
                    best_match = None
                    best_distance = float('inf')
                    
                    for char_idx, char in enumerate(line_sorted):
                        if char_idx in used_indices:
                            continue
                        
                        char_text = char[4].lower()
                        char_x = char[0]
                        
                        # VerificÄƒm dacÄƒ caracterul conÈ›ine litera cÄƒutatÄƒ
                        # Poate fi un singur caracter sau un grup de caractere
                        if target_char in char_text:
                            # VerificÄƒm distanÈ›a orizontalÄƒ faÈ›Äƒ de ultimul caracter folosit
                            last_char = line_sorted[used_indices[-1]]
                            last_x_end = last_char[0] + last_char[2]
                            distance = char_x - last_x_end
                            
                            # Caracterul trebuie sÄƒ fie la dreapta ultimului È™i la o distanÈ›Äƒ rezonabilÄƒ
                            if distance >= 0 and distance <= max_horizontal_distance:
                                if distance < best_distance:
                                    best_match = char_idx
                                    best_distance = distance
                    
                    if best_match is not None:
                        char = line_sorted[best_match]
                        char_text_lower = char[4].lower()
                        
                        # AdÄƒugÄƒm doar caracterul care se potriveÈ™te (nu Ã®ntregul grup)
                        # DacÄƒ grupul conÈ›ine mai multe caractere, adÄƒugÄƒm doar primul care se potriveÈ™te
                        char_added = False
                        for c in char_text_lower:
                            if c == target_char and len(reconstructed_chars) < term_length:
                                reconstructed_chars.append(c)
                                char_added = True
                                break
                        
                        # DacÄƒ nu am gÄƒsit caracterul exact, Ã®ncercÄƒm sÄƒ adÄƒugÄƒm primul caracter din grup
                        # (poate OCR a detectat greÈ™it sau caracterul este similar)
                        if not char_added and len(reconstructed_chars) < term_length:
                            # AdÄƒugÄƒm primul caracter din grup dacÄƒ este similar cu cel cÄƒutat
                            if len(char_text_lower) > 0:
                                reconstructed_chars.append(char_text_lower[0])
                                char_added = True
                        
                        if char_added:
                            used_indices.append(best_match)
                            x_end = char[0] + char[2]
                            y_end = max(y_end, char[1] + char[3])
                            conf_sum += char[5]
                            conf_count += 1
                        else:
                            # Nu am putut adÄƒuga caracterul, Ã®ncercÄƒm sÄƒ continuÄƒm
                            break
                    else:
                        # Nu am gÄƒsit urmÄƒtorul caracter, Ã®ncercÄƒm sÄƒ continuÄƒm cu ce avem
                        break
                
                # Reconstruim string-ul din caracterele colectate
                reconstructed = ''.join(reconstructed_chars[:term_length])
                
                # VerificÄƒm dacÄƒ cuvÃ¢ntul reconstituit se potriveÈ™te cu termenul cÄƒutat
                if reconstructed == search_term_lower:
                    # CalculÄƒm bounding box-ul pentru Ã®ntregul cuvÃ¢nt
                    width = x_end - x_start
                    height = y_end - y_start
                    avg_conf = conf_sum / conf_count if conf_count > 0 else 0
                    
                    if avg_conf > 60:
                        reconstructed_words.append((x_start, y_start, width, height, search_term, avg_conf))
                        print(f"         ğŸ”¤ Reconstituit cuvÃ¢ntul '{search_term}' din {conf_count} caractere (confidenÈ›Äƒ medie: {avg_conf:.1f}%)")
                        break  # Nu mai cÄƒutÄƒm Ã®n aceastÄƒ linie dacÄƒ am gÄƒsit deja cuvÃ¢ntul
    
    return reconstructed_words


def run_ocr_on_zones(image: np.ndarray, search_terms: list, steps_dir: str = None, 
                     grid_rows: int = 3, grid_cols: int = 3, zoom_factor: float = 2.0) -> tuple:
    """
    RuleazÄƒ OCR pe zone diferite ale imaginii cu zoom pentru a detecta mai bine textul mic.
    
    Ãmparte imaginea Ã®n grid È™i ruleazÄƒ OCR pe fiecare zonÄƒ, eventual cu zoom.
    DacÄƒ detecteazÄƒ caractere individuale, Ã®ncearcÄƒ sÄƒ reconstituie cuvÃ¢ntul complet.
    
    Args:
        image: Imaginea de analizat (grayscale sau BGR)
        search_terms: Lista de termeni de cÄƒutat
        steps_dir: Director pentru debug (opÈ›ional)
        grid_rows: NumÄƒr de rÃ¢nduri Ã®n grid
        grid_cols: NumÄƒr de coloane Ã®n grid
        zoom_factor: Factor de zoom pentru fiecare zonÄƒ (1.0 = fÄƒrÄƒ zoom)
    
    Returns:
        Tuple: (lista de text_boxes detectate, lista cu toate detecÈ›iile OCR)
    """
    if not TESSERACT_AVAILABLE:
        return [], []
    
    h, w = image.shape[:2]
    text_boxes = []
    all_chars = []  # ColectÄƒm toate caracterele detectate pentru reconstituire
    all_detections = []  # ColectÄƒm TOATE detecÈ›iile OCR pentru debug (nu doar cele care se potrivesc)
    all_words = []  # ColectÄƒm TOATE cuvintele detectate pentru comparaÈ›ie ulterioarÄƒ
    
    # PreprocesÄƒm Ã®ntreaga imagine
    processed_full = preprocess_image_for_ocr(image)
    
    # 1. OCR pe Ã®ntreaga imagine preprocesatÄƒ
    # Folosim PSM 11 (Sparse text) pentru a detecta cÃ¢t mai mult text posibil Ã®n planuri
    print(f"         ğŸ“ OCR pe Ã®ntreaga imagine (preprocesatÄƒ)...")
    ocr_data_full = pytesseract.image_to_data(processed_full, output_type=pytesseract.Output.DICT, lang='deu+eng', config='--psm 11')
    
    for i, text in enumerate(ocr_data_full['text']):
        if text.strip():
            text_clean = text.strip()
            text_lower = text_clean.lower()
            
            x = ocr_data_full['left'][i]
            y = ocr_data_full['top'][i]
            width = ocr_data_full['width'][i]
            height = ocr_data_full['height'][i]
            conf = ocr_data_full['conf'][i]
            
            # ColectÄƒm TOATE detecÈ›iile pentru debug
            all_detections.append((x, y, width, height, text_clean, conf))
            
            # VerificÄƒm direct dacÄƒ textul detectat se potriveÈ™te cu termenii cÄƒutaÈ›i (EXACT CA LA TERASA)
            found_term = None
            for term in search_terms:
                term_lower = term.lower()
                text_lower = text_clean.lower()
                
                # Match exact (case-insensitive)
                if term_lower == text_lower:
                    found_term = term
                    break
                
                # Match dacÄƒ termenul este conÈ›inut Ã®n text (ex: "carport" Ã®n "Carport 22.40 mÂ²")
                if term_lower in text_lower:
                    found_term = term
                    break
            
            if found_term:
                # AdÄƒugÄƒm detecÈ›ia chiar dacÄƒ are confidence < 60% (pentru poza de debug)
                # Dar o marchem ca neacceptatÄƒ dacÄƒ confidence < 60%
                text_boxes.append((x, y, width, height, text_clean, conf))
                if conf > 60:
                    print(f"         âœ… Detectat (full): '{text_clean}' la ({x}, {y}) cu confidenÈ›Äƒ {conf:.1f}%")
                else:
                    print(f"         âš ï¸ Detectat (full, LOW CONF): '{text_clean}' la ({x}, {y}) cu confidenÈ›Äƒ {conf:.1f}% (< 60%)")
            else:
                # ColectÄƒm È™i caracterele individuale pentru reconstituire
                # VerificÄƒm dacÄƒ caracterul face parte din unul dintre termenii cÄƒutaÈ›i
                for term in search_terms:
                    term_lower = term.lower()
                    if any(char in text_lower for char in term_lower):
                        all_chars.append((x, y, width, height, text_clean, conf))
                        break
    
    # 2. Ãntotdeauna Ã®ncercÄƒm È™i pe zone pentru a gÄƒsi textul mai mic sau mai clar
    # (chiar dacÄƒ am gÄƒsit ceva pe Ã®ntreaga imagine, zonele pot gÄƒsi mai multe detecÈ›ii)
    print(f"         ğŸ” ÃmpÄƒrÈ›im imaginea Ã®n {grid_rows}x{grid_cols} zone pentru OCR detaliat...")
    
    overlap = 50  # pixeli de overlap Ã®ntre zone
    
    # CalculÄƒm dimensiunile de bazÄƒ ale unei zone (folosind diviziune realÄƒ pentru acoperire completÄƒ)
    zone_height_base = h / grid_rows
    zone_width_base = w / grid_cols
    
    for row in range(grid_rows):
        for col in range(grid_cols):
            # CalculÄƒm coordonatele zonei astfel Ã®ncÃ¢t sÄƒ acopere complet imaginea
            # Prima zonÄƒ Ã®ncepe de la 0
            if row == 0:
                y_start = 0
            else:
                # Zonele intermediare au overlap cu zona anterioarÄƒ
                y_start = max(0, int(row * zone_height_base) - overlap)
            
            # Ultima zonÄƒ merge pÃ¢nÄƒ la marginea imaginii (h)
            if row == grid_rows - 1:
                y_end = h
            else:
                # Zonele intermediare se terminÄƒ cu overlap pentru urmÄƒtoarea zonÄƒ
                y_end = min(h, int((row + 1) * zone_height_base) + overlap)
            
            # AcelaÈ™i lucru pentru coloane
            if col == 0:
                x_start = 0
            else:
                x_start = max(0, int(col * zone_width_base) - overlap)
            
            if col == grid_cols - 1:
                x_end = w
            else:
                x_end = min(w, int((col + 1) * zone_width_base) + overlap)
            
            # VerificÄƒm cÄƒ zona este validÄƒ
            if x_start >= x_end or y_start >= y_end:
                print(f"         âš ï¸ Zona ({row+1},{col+1}) invalidÄƒ: x=[{x_start},{x_end}), y=[{y_start},{y_end})")
                continue
            
            # Extragem zona
            zone = image[y_start:y_end, x_start:x_end]
            
            if zone.size == 0:
                continue
            
            # Dimensiunile zonei originale (Ã®nainte de zoom)
            zone_orig_h, zone_orig_w = zone.shape[:2]
            
            # PreprocesÄƒm zona
            zone_processed = preprocess_image_for_ocr(zone)
            
            # AplicÄƒm zoom dacÄƒ este necesar
            if zoom_factor > 1.0:
                zone_h_scaled = int(zone_processed.shape[0] * zoom_factor)
                zone_w_scaled = int(zone_processed.shape[1] * zoom_factor)
                zone_zoomed = cv2.resize(zone_processed, (zone_w_scaled, zone_h_scaled), 
                                        interpolation=cv2.INTER_CUBIC)
            else:
                zone_zoomed = zone_processed
            
            # SalvÄƒm zonele procesate pentru debug (toate zonele)
            if steps_dir:
                debug_path = Path(steps_dir) / f"02g_zone_{row+1}_{col+1}_processed.png"
                cv2.imwrite(str(debug_path), zone_zoomed)
                # SalvÄƒm È™i zona originalÄƒ pentru comparaÈ›ie
                debug_path_orig = Path(steps_dir) / f"02g_zone_{row+1}_{col+1}_original.png"
                cv2.imwrite(str(debug_path_orig), zone)
            
            # OCR pe zonÄƒ
            try:
                # Folosim PSM 11 (Sparse text) pentru a detecta cÃ¢t mai mult text posibil
                ocr_data_zone = pytesseract.image_to_data(zone_zoomed, output_type=pytesseract.Output.DICT, lang='deu+eng', config='--psm 11')
                
                for i, text in enumerate(ocr_data_zone['text']):
                    if text.strip():
                        text_clean = text.strip()
                        text_lower = text_clean.lower()
                        
                        # Coordonatele Ã®n zona zoomed
                        rel_x_zoomed = ocr_data_zone['left'][i]
                        rel_y_zoomed = ocr_data_zone['top'][i]
                        rel_width_zoomed = ocr_data_zone['width'][i]
                        rel_height_zoomed = ocr_data_zone['height'][i]
                        
                        # Convertim coordonatele din zona zoomed la zona originalÄƒ (fÄƒrÄƒ zoom)
                        if zoom_factor > 1.0:
                            # Coordonatele relative Ã®n zona originalÄƒ (fÄƒrÄƒ zoom)
                            rel_x = rel_x_zoomed / zoom_factor
                            rel_y = rel_y_zoomed / zoom_factor
                            rel_width = rel_width_zoomed / zoom_factor
                            rel_height = rel_height_zoomed / zoom_factor
                        else:
                            rel_x = rel_x_zoomed
                            rel_y = rel_y_zoomed
                            rel_width = rel_width_zoomed
                            rel_height = rel_height_zoomed
                        
                        # Convertim la coordonatele absolute Ã®n imaginea completÄƒ
                        orig_x = int(rel_x) + x_start
                        orig_y = int(rel_y) + y_start
                        orig_width = int(rel_width)
                        orig_height = int(rel_height)
                        
                        # VerificÄƒm cÄƒ coordonatele sunt Ã®n limitele imaginii
                        orig_x = max(0, min(orig_x, w - 1))
                        orig_y = max(0, min(orig_y, h - 1))
                        orig_width = min(orig_width, w - orig_x)
                        orig_height = min(orig_height, h - orig_y)
                        
                        conf = ocr_data_zone['conf'][i]
                        
                        # ColectÄƒm TOATE detecÈ›iile pentru debug
                        all_detections.append((orig_x, orig_y, orig_width, orig_height, text_clean, conf))
                        
                        # VerificÄƒm direct dacÄƒ textul detectat se potriveÈ™te cu termenii cÄƒutaÈ›i (EXACT CA LA TERASA)
                        found_term = None
                        for term in search_terms:
                            term_lower = term.lower()
                            text_lower = text_clean.lower()
                            
                            # Match exact (case-insensitive)
                            if term_lower == text_lower:
                                found_term = term
                                break
                            
                            # Match dacÄƒ termenul este conÈ›inut Ã®n text (ex: "carport" Ã®n "Carport 22.40 mÂ²")
                            if term_lower in text_lower:
                                found_term = term
                                break
                        
                        if found_term:
                            if conf > 60:
                                text_boxes.append((orig_x, orig_y, orig_width, orig_height, text_clean, conf))
                                print(f"         âœ… Detectat (zona {row+1},{col+1}): '{text_clean}' la ({orig_x}, {orig_y}) cu confidenÈ›Äƒ {conf:.1f}%")
                            else:
                                # AdÄƒugÄƒm È™i detecÈ›iile cu confidence < 60% pentru poza de debug
                                text_boxes.append((orig_x, orig_y, orig_width, orig_height, text_clean, conf))
                                print(f"         âš ï¸ Detectat (zona {row+1},{col+1}, LOW CONF): '{text_clean}' la ({orig_x}, {orig_y}) cu confidenÈ›Äƒ {conf:.1f}% (< 60%)")
                        else:
                            # ColectÄƒm È™i caracterele individuale pentru reconstituire
                            # VerificÄƒm dacÄƒ caracterul face parte din unul dintre termenii cÄƒutaÈ›i
                            for term in search_terms:
                                term_lower = term.lower()
                                if any(char in text_lower for char in term_lower):
                                    all_chars.append((orig_x, orig_y, orig_width, orig_height, text_clean, conf))
                                    break
            except Exception as e:
                print(f"         âš ï¸ Eroare OCR pe zona {row+1},{col+1}: {e}")
                continue
    
    # 3. DacÄƒ nu am gÄƒsit cuvinte complete, Ã®ncercÄƒm sÄƒ reconstituim din caractere
    if not text_boxes and all_chars:
        print(f"         ğŸ”¤ Am detectat {len(all_chars)} caractere individuale. Ãncerc sÄƒ reconstitui cuvÃ¢ntul...")
        reconstructed = _reconstruct_word_from_chars(all_chars, search_terms)
        text_boxes.extend(reconstructed)
    
    # 4. GenerÄƒm imagine de debug cu TOATE detecÈ›iile OCR
    if steps_dir and all_detections:
        # Convertim imaginea la BGR dacÄƒ este grayscale
        if len(image.shape) == 2:
            debug_img = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
        elif len(image.shape) == 3 and image.shape[2] == 3:
            debug_img = image.copy()
        else:
            debug_img = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)
        
        print(f"         ğŸ“Š GenerÃ¢nd imagine de debug cu {len(all_detections)} detecÈ›ii OCR...")
        
        # DesenÄƒm toate detecÈ›iile
        for x, y, width, height, text, conf in all_detections:
            # VerificÄƒm dacÄƒ detecÈ›ia se potriveÈ™te cu unul dintre termenii cÄƒutaÈ›i
            text_lower = text.lower()
            is_match = False
            for term in search_terms:
                if term.lower() == text_lower:
                    is_match = True
                    break
            
            # Culoare: verde pentru match-uri, albastru pentru restul
            color = (0, 255, 0) if is_match else (255, 0, 0)
            thickness = 3 if is_match else 2
            
            # DesenÄƒm dreptunghiul
            cv2.rectangle(debug_img, (x, y), (x + width, y + height), color, thickness)
            
            # DesenÄƒm textul cu procentajul
            label = f"{text} ({conf:.0f}%)"
            
            # CalculÄƒm dimensiunea fontului Ã®n funcÈ›ie de Ã®nÄƒlÈ›imea detecÈ›iei
            font_scale = max(0.4, height / 30.0)
            font_thickness = max(1, int(font_scale * 2))
            
            # CalculÄƒm dimensiunea textului pentru a-l poziÈ›iona corect
            (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)
            
            # PoziÈ›ionÄƒm textul deasupra dreptunghiului (sau dedesubt dacÄƒ nu Ã®ncape)
            text_y = y - 5 if y - 5 > text_height else y + height + text_height + 5
            
            # DesenÄƒm fundal pentru text (pentru lizibilitate)
            cv2.rectangle(debug_img, 
                         (x, text_y - text_height - baseline), 
                         (x + text_width, text_y + baseline), 
                         color, -1)
            
            # DesenÄƒm textul
            cv2.putText(debug_img, label, (x, text_y), 
                       cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), font_thickness)
        
        # SalvÄƒm imaginea de debug
        debug_path = Path(steps_dir) / "02g_02_all_ocr_detections.png"
        cv2.imwrite(str(debug_path), debug_img)
        print(f"         ğŸ’¾ Salvat: 02g_02_all_ocr_detections.png ({len(all_detections)} detecÈ›ii)")
    
    return text_boxes, all_detections


# NOTE: FuncÈ›ia fill_room_by_ocr este foarte mare (peste 1200 linii) È™i este definitÄƒ Ã®n detector.py.
# Pentru moment, o importÄƒm din detector.py folosind TYPE_CHECKING pentru a evita importuri circulare.
# Ãn viitor, va fi mutatÄƒ complet aici.
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    # Pentru type checking, importÄƒm tipurile
    pass

def fill_room_by_ocr(walls_mask: np.ndarray, search_terms: list, room_name: str, 
                     steps_dir: str = None, debug_prefix: str = "02g") -> np.ndarray:
    """
    FuncÈ›ie genericÄƒ pentru detectarea È™i umplerea camerelor prin OCR.
    
    DetecteazÄƒ cuvintele din search_terms Ã®n plan È™i umple camera respectivÄƒ cu flood fill.
    
    Args:
        walls_mask: Masca pereÈ›ilor (255 = perete, 0 = spaÈ›iu liber)
        search_terms: Lista de termeni de cÄƒutat (ex: ["terasa", "Terasa", "TERASA"])
        room_name: Numele camerei pentru mesaje (ex: "terasa", "garage")
        steps_dir: Director pentru salvarea step-urilor de debug (opÈ›ional)
        debug_prefix: Prefix pentru fiÈ™ierele de debug (ex: "02g" pentru terasa, "02h" pentru garaje)
    
    Returns:
        Masca pereÈ›ilor cu camera umplutÄƒ (dacÄƒ a fost detectatÄƒ)
    """
    if walls_mask is None:
        print(f"      âš ï¸ walls_mask este None. Skip detectarea {room_name}.")
        return None
    
    try:
        h, w = walls_mask.shape[:2]
    except AttributeError:
        print(f"      âš ï¸ walls_mask nu are atributul shape. Skip detectarea {room_name}.")
        return None
    
    # Folosim o metodÄƒ alternativÄƒ dacÄƒ OCR nu este disponibil
    use_ocr = TESSERACT_AVAILABLE
    if not use_ocr:
        print(f"      âš ï¸ pytesseract nu este disponibil. Skip detectarea {room_name}.")
        return walls_mask.copy()
    
    result = walls_mask.copy()
    
    print(f"      ğŸ¡ Detectez È™i umplu camere ({room_name})...")
    
    # CreÄƒm folder pentru output-uri structurate
    room_output_dir = None
    if steps_dir:
        room_output_dir = Path(steps_dir) / "ocr_room_filling" / room_name
        room_output_dir.mkdir(parents=True, exist_ok=True)
    
    # Pas 1: ÃncÄƒrcÄƒm overlay-ul sau original-ul pentru OCR
    overlay_path = None
    original_path = None
    if steps_dir:
        overlay_path = Path(steps_dir) / "02d_walls_closed_overlay.png"
        original_path = Path(steps_dir) / "00_original.png"
    
    # PreferÄƒm imaginea originalÄƒ pentru detectarea textului (textul este mai clar acolo)
    ocr_image = None
    if original_path and original_path.exists():
        ocr_image = cv2.imread(str(original_path), cv2.IMREAD_COLOR)
        if ocr_image is None:
            ocr_image = cv2.imread(str(original_path), cv2.IMREAD_GRAYSCALE)
            if ocr_image is not None:
                ocr_image = cv2.cvtColor(ocr_image, cv2.COLOR_GRAY2BGR)
        print(f"         ğŸ“¸ Folosesc original pentru OCR: {original_path.name}")
    elif overlay_path and overlay_path.exists():
        ocr_image = cv2.imread(str(overlay_path), cv2.IMREAD_COLOR)
        print(f"         ğŸ“¸ Folosesc overlay pentru OCR (fallback): {overlay_path.name}")
    
    if ocr_image is None:
        print(f"         âš ï¸ Nu s-a gÄƒsit overlay sau original. Skip detectarea {room_name}.")
        return result
    
    # RedimensionÄƒm dacÄƒ este necesar
    if ocr_image.shape[:2] != (h, w):
        ocr_image = cv2.resize(ocr_image, (w, h))
    
    # Pas 2: DetectÄƒm textul folosind OCR cu preprocesare È™i analizÄƒ pe zone
    print(f"         ğŸ” Pas 1: Detectez text ({room_name})...")
    
    text_found = False
    text_boxes = []
    all_detections = []
    
    try:
        if use_ocr:
            # Metoda Ã®mbunÄƒtÄƒÈ›itÄƒ: OCR cu preprocesare È™i analizÄƒ pe zone
            print(f"         ğŸ“ Folosesc OCR cu preprocesare È™i analizÄƒ pe zone...")
            
            # Salvez imaginea preprocesatÄƒ pentru debug
            if steps_dir:
                processed_img = preprocess_image_for_ocr(ocr_image)
                if room_output_dir:
                    cv2.imwrite(str(room_output_dir / "00_preprocessed.png"), processed_img)
                    print(f"         ğŸ’¾ Salvat: {room_output_dir.name}/00_preprocessed.png (imagine preprocesatÄƒ)")
            
            # RuleazÄƒ OCR pe zone cu zoom
            text_boxes, all_detections = run_ocr_on_zones(ocr_image, search_terms, steps_dir, 
                                         grid_rows=3, grid_cols=3, zoom_factor=2.0)
            
            if text_boxes:
                text_found = True
        else:
            print(f"         âš ï¸ FÄƒrÄƒ OCR nu pot identifica specific cuvÃ¢ntul '{room_name}'.")
            text_found = False
            text_boxes = []
            all_detections = []
        
        # SelectÄƒm rezultatul cu confidence maxim (dacÄƒ existÄƒ)
        accepted_boxes = []  # DetecÈ›iile acceptate È™i folosite (confidence > 60%)
        best_box_all = None  # Cea mai bunÄƒ detecÈ›ie (chiar dacÄƒ are confidence < 60%)
        
        if text_boxes:
            # SortÄƒm dupÄƒ confidence (descrescÄƒtor)
            text_boxes.sort(key=lambda box: box[5], reverse=True)  # box[5] = confidence
            best_box_all = text_boxes[0]  # Cea mai bunÄƒ detecÈ›ie (chiar dacÄƒ e < 60%)
            
            # Filtram doar detecÈ›iile cu confidence > 60% pentru procesare
            accepted_boxes = [box for box in text_boxes if box[5] > 60]
            
            if accepted_boxes:
                best_box = accepted_boxes[0]
                print(f"         ğŸ¯ Selectat rezultatul cu confidence maxim: '{best_box[4]}' cu {best_box[5]:.1f}%")
                text_boxes = accepted_boxes.copy()  # ActualizÄƒm text_boxes pentru procesare
            else:
                print(f"         âš ï¸ Cea mai bunÄƒ detecÈ›ie: '{best_box_all[4]}' cu {best_box_all[5]:.1f}% (< 60%, nu acceptatÄƒ)")
                text_boxes = []  # Nu avem detecÈ›ii acceptate pentru procesare
        elif use_ocr and all_detections:
            # DacÄƒ nu am gÄƒsit detecÈ›ii care se potrivesc cu termenii, folosim cea mai bunÄƒ detecÈ›ie din toate
            all_detections.sort(key=lambda box: box[5], reverse=True)  # box[5] = confidence
            best_box_all = all_detections[0]
            print(f"         âš ï¸ Nu s-au gÄƒsit detecÈ›ii care se potrivesc cu termenii, dar am gÄƒsit '{best_box_all[4]}' cu {best_box_all[5]:.1f}%")
        
        # SalvÄƒm poza cu cea mai bunÄƒ detecÈ›ie (chiar dacÄƒ nu e acceptatÄƒ)
        if steps_dir and best_box_all:
            vis_best_detection = ocr_image.copy() if ocr_image is not None else cv2.cvtColor(walls_mask, cv2.COLOR_GRAY2BGR)
            best_x, best_y, best_width, best_height, best_text, best_conf = best_box_all
            best_center_x = best_x + best_width // 2
            best_center_y = best_y + best_height // 2
            
            # Culoare: verde dacÄƒ e acceptatÄƒ, portocaliu dacÄƒ nu
            if best_conf > 60:
                detection_color = (0, 255, 0)  # Verde
                status_label = f"âœ… ACCEPTED ({best_conf:.1f}%)"
            else:
                detection_color = (0, 165, 255)  # Portocaliu
                status_label = f"âŒ REJECTED ({best_conf:.1f}% < 60%)"
            
            cv2.rectangle(vis_best_detection, (best_x, best_y), (best_x + best_width, best_y + best_height), detection_color, 3)
            cv2.circle(vis_best_detection, (best_center_x, best_center_y), 8, (0, 0, 255), -1)
            
            label_text = f"{best_text} - {status_label} | No Flood Fill"
            font_scale = max(0.7, best_height / 30.0)
            font_thickness = max(2, int(font_scale * 2))
            (text_width, text_height), baseline = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)
            
            text_y = max(text_height + 5, best_y - 5)
            text_x = best_x
            cv2.rectangle(vis_best_detection, 
                         (text_x, text_y - text_height - baseline), 
                         (text_x + text_width + 10, text_y + baseline), 
                         (255, 255, 255), -1)
            
            cv2.putText(vis_best_detection, label_text, (text_x + 5, text_y), 
                       cv2.FONT_HERSHEY_SIMPLEX, font_scale, detection_color, font_thickness)
            
            if room_output_dir:
                output_path = room_output_dir / "01c_best_detection_with_fill.png"
                cv2.imwrite(str(output_path), vis_best_detection)
                print(f"         ğŸ’¾ Salvat: {room_output_dir.name}/01c_best_detection_with_fill.png (best detection: {best_conf:.1f}%, no flood fill)")
        
        if not text_found or not accepted_boxes:
            if not text_found:
                print(f"         âš ï¸ Nu s-a detectat text ({room_name}) Ã®n plan.")
            else:
                print(f"         âš ï¸ Nu s-a detectat text ({room_name}) cu confidence > 60%.")
            if steps_dir:
                vis_ocr = ocr_image.copy() if ocr_image is not None else cv2.cvtColor(walls_mask, cv2.COLOR_GRAY2BGR)
                if room_output_dir:
                    cv2.imwrite(str(room_output_dir / "01_ocr_result.png"), vis_ocr)
                    print(f"         ğŸ’¾ Salvat: {room_output_dir.name}/01_ocr_result.png")
            return result
        
        # Pas 3: VizualizÄƒm textul detectat (toate detecÈ›iile)
        if steps_dir:
            vis_ocr = ocr_image.copy()
            for x, y, width, height, text, conf in text_boxes:
                cv2.rectangle(vis_ocr, (x, y), (x + width, y + height), (0, 255, 0), 2)
                cv2.putText(vis_ocr, f"{text} ({conf:.0f}%)", (x, y - 5), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            if room_output_dir:
                cv2.imwrite(str(room_output_dir / "01_ocr_result.png"), vis_ocr)
                print(f"         ğŸ’¾ Salvat: {room_output_dir.name}/01_ocr_result.png (text detectat)")
        
        # Pas 3b: VizualizÄƒm DOAR detecÈ›iile acceptate (cele care sunt luate Ã®n calcul)
        if steps_dir and accepted_boxes:
            vis_accepted = ocr_image.copy()
            for x, y, width, height, text, conf in accepted_boxes:
                # DesenÄƒm dreptunghiul cu culoare verde mai intensÄƒ
                cv2.rectangle(vis_accepted, (x, y), (x + width, y + height), (0, 255, 0), 3)
                
                # DesenÄƒm centrul textului (punctul de start pentru flood fill)
                center_x = x + width // 2
                center_y = y + height // 2
                cv2.circle(vis_accepted, (center_x, center_y), 8, (0, 0, 255), -1)  # RoÈ™u pentru centru
                
                # DesenÄƒm textul cu fundal pentru lizibilitate
                label = f"{text} ({conf:.0f}%)"
                font_scale = max(0.6, height / 25.0)
                font_thickness = max(2, int(font_scale * 2))
                (text_width, text_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)
                
                # PoziÈ›ionÄƒm textul deasupra dreptunghiului
                text_y = max(text_height + 5, y - 5)
                text_x = x
                
                # DesenÄƒm fundal pentru text
                cv2.rectangle(vis_accepted, 
                             (text_x, text_y - text_height - baseline), 
                             (text_x + text_width, text_y + baseline), 
                             (0, 255, 0), -1)
                
                # DesenÄƒm textul
                cv2.putText(vis_accepted, label, (text_x, text_y), 
                           cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 0), font_thickness)
            
            if room_output_dir:
                cv2.imwrite(str(room_output_dir / "01b_accepted_detections.png"), vis_accepted)
                print(f"         ğŸ’¾ Salvat: {room_output_dir.name}/01b_accepted_detections.png ({len(accepted_boxes)} detecÈ›ie/ii acceptatÄƒ/e)")
        
        # Pas 4: Pentru fiecare text detectat, gÄƒsim zona camerei È™i facem flood fill
        print(f"         ğŸ” Pas 2: GÄƒsesc zona camerei È™i fac flood fill...")
        
        # ÃncÄƒrcÄƒm overlay-ul combinat (pereti + original cu 50% transparency)
        overlay_combined = None
        if steps_dir:
            overlay_path = Path(steps_dir) / "02d_walls_closed_overlay.png"
            if overlay_path.exists():
                overlay_combined = cv2.imread(str(overlay_path), cv2.IMREAD_COLOR)
                if overlay_combined is not None:
                    # RedimensionÄƒm dacÄƒ este necesar
                    if overlay_combined.shape[:2] != (h, w):
                        overlay_combined = cv2.resize(overlay_combined, (w, h))
                    print(f"         ğŸ“¸ Folosesc overlay combinat (pereti + original 50%) pentru flood fill")
                else:
                    print(f"         âš ï¸ Nu pot Ã®ncÄƒrca overlay-ul. Folosesc walls_mask simplu.")
        
        # DacÄƒ nu avem overlay, folosim walls_mask simplu
        if overlay_combined is None:
            # CreÄƒm o mascÄƒ pentru spaÈ›iile libere (inversul pereÈ›ilor)
            spaces_mask = cv2.bitwise_not(walls_mask)
        else:
            # Convertim overlay-ul la grayscale
            overlay_gray = cv2.cvtColor(overlay_combined, cv2.COLOR_BGR2GRAY)
            
            # BinarizÄƒm overlay-ul pentru a identifica pereÈ›ii
            # PereÈ›ii Ã®n overlay sunt mai Ã®nchiÈ™i (din combinaÈ›ia de 50% original + 50% walls)
            # Folosim un threshold adaptiv pentru a separa pereÈ›ii de spaÈ›iile libere
            _, overlay_binary = cv2.threshold(overlay_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
            
            # InversÄƒm pentru a obÈ›ine spaÈ›iile libere (0 = perete, 255 = spaÈ›iu liber)
            spaces_mask = cv2.bitwise_not(overlay_binary)
            print(f"         ğŸ“Š Overlay binarizat: pereÈ›i identificaÈ›i din combinaÈ›ie")
        
        # ProcesÄƒm DOAR rezultatul cu confidence maxim (dacÄƒ existÄƒ)
        rooms_filled = 0
        if text_boxes:
            # ProcesÄƒm doar primul (È™i singurul) rezultat - cel cu confidence maxim
            box_idx = 0
            x, y, width, height, text, conf = text_boxes[0]
            # Centrul textului
            center_x = x + width // 2
            center_y = y + height // 2
            
            # DeterminÄƒm dacÄƒ este garaj/carport (care are doar 3 pereÈ›i)
            is_garage = room_name.lower() in ['garage', 'garaj', 'carport']
            
            if not use_ocr:
                print(f"         âš ï¸ FÄƒrÄƒ OCR nu pot identifica specific cuvÃ¢ntul. Skip.")
                return result
            else:
                print(f"         ğŸ¯ GÄƒsit cuvÃ¢ntul '{text}' (confidence {conf:.1f}%) - fac flood fill Ã®n jurul textului...")
                # Facem flood fill DIN JURUL textului, nu din interiorul lui
                
                # CalculÄƒm o zonÄƒ buffer Ã®n jurul textului pentru a gÄƒsi puncte de start
                buffer_size = max(20, int(max(width, height) * 1.5))  # Buffer de ~1.5x dimensiunea textului
                
                # IdentificÄƒm puncte de start Ã®n jurul textului (sus, jos, stÃ¢nga, dreapta, colÈ›uri)
                seed_points = []
                
                # Puncte pe laturile dreptunghiului textului (la distanÈ›Äƒ buffer_size)
                seed_y_top = max(0, y - buffer_size)
                seed_points.append((center_x, seed_y_top))
                seed_y_bottom = min(h - 1, y + height + buffer_size)
                seed_points.append((center_x, seed_y_bottom))
                seed_x_left = max(0, x - buffer_size)
                seed_points.append((seed_x_left, center_y))
                seed_x_right = min(w - 1, x + width + buffer_size)
                seed_points.append((seed_x_right, center_y))
                
                # ColÈ›uri (diagonal)
                seed_points.append((seed_x_left, seed_y_top))
                seed_points.append((seed_x_right, seed_y_top))
                seed_points.append((seed_x_left, seed_y_bottom))
                seed_points.append((seed_x_right, seed_y_bottom))
                
                # VerificÄƒm dacÄƒ existÄƒ cel puÈ›in un seed point valid Ã®n jurul textului (nu verificÄƒm centrul!)
                valid_seed_found = False
                for seed_x, seed_y in seed_points:
                    if 0 <= seed_y < h and 0 <= seed_x < w:
                        if spaces_mask[seed_y, seed_x] == 255:  # SpaÈ›iu liber
                            valid_seed_found = True
                            break
                
                if not valid_seed_found:
                    print(f"         âš ï¸ Nu s-au gÄƒsit seed points valide Ã®n jurul textului '{text}'. Skip.")
                    return result
                
                # Creez o mascÄƒ care exclude textul (pentru a nu umple interiorul textului)
                text_mask = np.zeros((h, w), dtype=np.uint8)
                cv2.rectangle(text_mask, (x, y), (x + width, y + height), 255, -1)
                
                # MascÄƒ combinatÄƒ: pereÈ›i + text (nu vrem sÄƒ umplem nici pereÈ›ii, nici textul)
                exclusion_mask = cv2.bitwise_or(walls_mask, text_mask)
                
                flood_mask = np.zeros((h + 2, w + 2), np.uint8)
                flood_fill_flags = 4  # 4-conectivitate
                flood_fill_flags |= cv2.FLOODFILL_MASK_ONLY
                flood_fill_flags |= (255 << 8)  # Fill value
                
                # Folosim overlay-ul combinat pentru flood fill
                if overlay_combined is not None:
                    overlay_for_fill = cv2.cvtColor(overlay_combined, cv2.COLOR_BGR2GRAY)
                    lo_diff = 30
                    up_diff = 30
                    fill_image = overlay_for_fill.copy()
                    print(f"         ğŸ¨ Folosesc overlay combinat pentru flood fill")
                else:
                    fill_image = spaces_mask.copy()
                    lo_diff = 0
                    up_diff = 0
                    print(f"         âš ï¸ Folosesc spaces_mask simplu (overlay indisponibil)")
                
                # Facem flood fill din toate punctele din jurul textului
                combined_filled_region = np.zeros((h, w), dtype=np.uint8)
                valid_seeds = 0
                
                print(f"         ğŸ” Ãncerc flood fill din {len(seed_points)} puncte Ã®n jurul textului...")
                
                for seed_idx, seed_point in enumerate(seed_points):
                    seed_x, seed_y = seed_point
                    
                    if not (0 <= seed_y < h and 0 <= seed_x < w):
                        continue
                    
                    if exclusion_mask[seed_y, seed_x] > 0:
                        continue
                    
                    if spaces_mask[seed_y, seed_x] != 255:
                        continue
                    
                    temp_flood_mask = np.zeros((h + 2, w + 2), np.uint8)
                    try:
                        _, _, _, rect = cv2.floodFill(
                            fill_image.copy(),
                            temp_flood_mask, 
                            seed_point, 
                            128,
                            lo_diff, 
                            up_diff, 
                            flood_fill_flags
                        )
                        
                        temp_filled = (temp_flood_mask[1:h+1, 1:w+1] == 255).astype(np.uint8) * 255
                        temp_filled = cv2.bitwise_and(temp_filled, cv2.bitwise_not(exclusion_mask))
                        combined_filled_region = cv2.bitwise_or(combined_filled_region, temp_filled)
                        valid_seeds += 1
                        
                    except Exception as e:
                        print(f"         âš ï¸ Eroare la flood fill din punct {seed_idx + 1}: {e}")
                        continue
                
                print(f"         âœ… Flood fill din {valid_seeds}/{len(seed_points)} puncte valide")
                
                filled_region = combined_filled_region
                
                # VerificÄƒm cÄƒ nu am umplut peste pereÈ›i
                overlap_with_walls = np.sum((filled_region > 0) & (walls_mask > 0))
                if overlap_with_walls > 0:
                    print(f"         âš ï¸ Flood fill a depÄƒÈ™it pereÈ›ii ({overlap_with_walls} pixeli). Corectez...")
                    filled_region = cv2.bitwise_and(filled_region, cv2.bitwise_not(walls_mask))
                
                filled_area = np.count_nonzero(filled_region)
                img_total_area = h * w
                filled_ratio = filled_area / float(img_total_area)
                
                # VerificÄƒm dacÄƒ flood fill-ul este prea mare (probabil a trecut prin pereÈ›i È™i iese din plan)
                # Pentru terasÄƒ, dacÄƒ umple > 50% din imagine, probabil a trecut prin pereÈ›i
                if not is_garage and filled_ratio > 0.50:
                    print(f"         âš ï¸ Flood fill prea mare ({filled_area}px, {filled_ratio*100:.1f}% din imagine). Probabil a trecut prin pereÈ›i È™i iese din plan. Skip.")
                    return result
                
                # VerificÄƒm cÄƒ zona umplutÄƒ este suficient de mare
                if not is_garage and filled_area < 1000:
                    print(f"         âš ï¸ Zona detectatÄƒ prea micÄƒ ({filled_area} pixeli). Skip.")
                    return result
                
                # Pentru garaj/carport, folosim o abordare geometricÄƒ simplificatÄƒ
                if is_garage:
                    print(f"         ğŸš— Detectat garaj/carport - folosesc abordare geometricÄƒ simplificatÄƒ...")
                    # Pentru garaj, folosim direct zona umplutÄƒ de flood fill
                    # (logica geometricÄƒ complexÄƒ este Ã®n blocul orfan, dar nu o mutÄƒm)
                    if filled_area < 1000:
                        print(f"         âš ï¸ Zona geometricÄƒ prea micÄƒ ({filled_area} pixeli). Skip.")
                        return result
                
                # VerificÄƒm cÄƒ zona umplutÄƒ este suficient de mare dar nu prea mare (pentru terasÄƒ)
                if filled_area > 1000 and (is_garage or filled_ratio <= 0.50):
                    print(f"         ğŸ” Extrag conturul zonei detectate pentru a completa golurile...")
                    
                    contours, _ = cv2.findContours(filled_region, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    
                    if contours:
                        largest_contour = max(contours, key=cv2.contourArea)
                        contour_mask = np.zeros((h, w), dtype=np.uint8)
                        wall_thickness = max(3, int(min(w, h) * 0.003))
                        cv2.drawContours(contour_mask, [largest_contour], -1, 255, wall_thickness)
                        gaps = cv2.bitwise_and(contour_mask, cv2.bitwise_not(walls_mask))
                        walls_to_add = gaps
                        result = cv2.bitwise_or(result, walls_to_add)
                        gaps_area = np.count_nonzero(gaps)
                        print(f"         âœ… Completat {gaps_area} pixeli de goluri Ã®n pereÈ›i conform conturului")
                    else:
                        print(f"         âš ï¸ Nu s-au gÄƒsit contururi Ã®n zona umplutÄƒ")
                        kernel_size = max(3, int(min(w, h) * 0.005))
                        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
                        filled_dilated = cv2.dilate(filled_region, kernel, iterations=1)
                        wall_border = cv2.subtract(filled_dilated, filled_region)
                        result = cv2.bitwise_or(result, wall_border)
                    
                    rooms_filled += 1
                    print(f"         âœ… Umplut camera '{text}': {filled_area} pixeli")
                    
                    # VizualizÄƒm zona umplutÄƒ È™i golurile completate
                    if steps_dir:
                        vis_fill = cv2.cvtColor(walls_mask, cv2.COLOR_GRAY2BGR)
                        filled_colored = np.zeros_like(vis_fill)
                        filled_colored[filled_region > 0] = [0, 255, 255]  # Galben
                        vis_fill = cv2.addWeighted(vis_fill, 0.7, filled_colored, 0.3, 0)
                        
                        if contours and len(contours) > 0:
                            largest_contour = max(contours, key=cv2.contourArea)
                            cv2.drawContours(vis_fill, [largest_contour], -1, (255, 0, 0), 2)
                        
                        gaps = cv2.bitwise_and(contour_mask, cv2.bitwise_not(walls_mask)) if contours else None
                        if gaps is not None:
                            gaps_colored = np.zeros_like(vis_fill)
                            gaps_colored[gaps > 0] = [0, 255, 0]
                            vis_fill = cv2.addWeighted(vis_fill, 0.5, gaps_colored, 0.5, 0)
                        
                        cv2.circle(vis_fill, (center_x, center_y), 5, (0, 0, 255), -1)
                        cv2.rectangle(vis_fill, (x, y), (x + width, y + height), (0, 255, 0), 2)
                        
                        if room_output_dir:
                            output_path = room_output_dir / f"02_fill_attempt_{box_idx + 1}.png"
                            cv2.imwrite(str(output_path), vis_fill)
                            print(f"         ğŸ’¾ Salvat: {room_output_dir.name}/{output_path.name}")
                    
                    print(f"         âœ… Gata! Am umplut camera {room_name}.")
                else:
                    if filled_area > 0 and filled_ratio > 0.50:
                        print(f"         âš ï¸ Zona detectatÄƒ prea mare ({filled_area} pixeli, {filled_ratio*100:.1f}% din imagine). Probabil a trecut prin pereÈ›i. Skip.")
                    else:
                        print(f"         âš ï¸ Zona detectatÄƒ prea micÄƒ ({filled_area} pixeli). Skip.")
        
        if rooms_filled > 0:
            print(f"         âœ… Umplut {rooms_filled} camere de tip '{room_name}'")
        else:
            print(f"         âš ï¸ Nu s-au umplut camere (zone prea mici sau pe pereÈ›i)")
        
        # Pas 5: SalvÄƒm rezultatul final
        if steps_dir:
            vis_final = cv2.cvtColor(result, cv2.COLOR_GRAY2BGR)
            diff = cv2.subtract(result, walls_mask)
            diff_colored = np.zeros_like(vis_final)
            diff_colored[diff > 0] = [0, 255, 0]  # Verde pentru pereÈ›ii noi
            vis_final = cv2.addWeighted(vis_final, 0.7, diff_colored, 0.3, 0)
            if room_output_dir:
                cv2.imwrite(str(room_output_dir / "03_final_result.png"), vis_final)
                print(f"         ğŸ’¾ Salvat: {room_output_dir.name}/03_final_result.png (verde=pereÈ›i noi)")
    
    except Exception as e:
        print(f"         âŒ Eroare la detectarea/umplerea {room_name}: {e}")
        import traceback
        traceback.print_exc()
        return result
    
    return result


def fill_stairs_room(walls_mask: np.ndarray, stairs_bboxes: list, steps_dir: str = None) -> np.ndarray:
    """
    DetecteazÄƒ scÄƒrile folosind detecÈ›iile Roboflow È™i reconstruieÈ™te pereÈ›ii din jurul lor.
    NU face flood fill, doar reconstruieÈ™te pereÈ›ii care lipsesc Ã®n jurul scÄƒrilor.
    
    Args:
        walls_mask: Masca pereÈ›ilor (255 = perete, 0 = spaÈ›iu liber)
        stairs_bboxes: Lista de bounding boxes pentru scÄƒri detectate de Roboflow
                      Format: [(x1, y1, x2, y2), ...]
        steps_dir: Director pentru salvarea step-urilor de debug (opÈ›ional)
    
    Returns:
        Masca pereÈ›ilor cu pereÈ›ii reconstruiÈ›i Ã®n jurul scÄƒrilor (dacÄƒ au fost detectate)
    """
    # VerificÄƒ dacÄƒ walls_mask este None sau invalid
    if walls_mask is None:
        print(f"      âš ï¸ walls_mask este None. Skip reconstruirea pereÈ›ilor pentru scÄƒri.")
        return None
    
    try:
        h, w = walls_mask.shape[:2]
    except AttributeError:
        print(f"      âš ï¸ walls_mask nu are atributul shape. Skip reconstruirea pereÈ›ilor pentru scÄƒri.")
        return None
    
    result = walls_mask.copy()
    
    # CreÄƒm folder pentru output-uri structurate
    stairs_output_dir = None
    if steps_dir:
        stairs_output_dir = Path(steps_dir) / "ocr_room_filling" / "stairs"
        stairs_output_dir.mkdir(parents=True, exist_ok=True)
    
    if not stairs_bboxes:
        print(f"      ğŸ  Nu s-au detectat scÄƒri. Skip reconstruirea pereÈ›ilor pentru scÄƒri.")
        return result
    
    print(f"      ğŸ  Reconstruiesc pereÈ›ii Ã®n jurul scÄƒrilor ({len(stairs_bboxes)} detectate)...")
    
    stairs_processed = 0
    
    for stair_idx, bbox in enumerate(stairs_bboxes):
        x1, y1, x2, y2 = map(int, bbox)
        
        # AsigurÄƒm cÄƒ coordonatele sunt Ã®n limitele imaginii
        x1, y1 = max(0, x1), max(0, y1)
        x2, y2 = min(w, x2), min(h, y2)
        
        if x2 <= x1 or y2 <= y1:
            print(f"         âš ï¸ Scara #{stair_idx + 1}: bbox invalid. Skip.")
            continue
        
        print(f"         ğŸ¯ Scara #{stair_idx + 1}: verific È™i reconstruiesc pereÈ›ii Ã®n jurul scÄƒrii...")
        
        # CalculÄƒm o zonÄƒ buffer Ã®n jurul scÄƒrii pentru a cÄƒuta pereÈ›i
        width_bbox = x2 - x1
        height_bbox = y2 - y1
        # Buffer mai mic - doar pentru a detecta pereÈ›ii imediat Ã®n jurul scÄƒrii
        buffer_size = max(20, int(max(width_bbox, height_bbox) * 0.3))  # 30% din dimensiunea scÄƒrii
        
        # CreÄƒm o zonÄƒ extinsÄƒ Ã®n jurul scÄƒrii pentru a cÄƒuta pereÈ›i
        search_x1 = max(0, x1 - buffer_size)
        search_y1 = max(0, y1 - buffer_size)
        search_x2 = min(w, x2 + buffer_size)
        search_y2 = min(h, y2 + buffer_size)
        
        # Extragem zona de cÄƒutare din masca pereÈ›ilor
        search_region = result[search_y1:search_y2, search_x1:search_x2]
        
        # CreÄƒm o mascÄƒ pentru scara (excludem scara din procesare)
        stairs_mask_region = np.zeros((search_y2 - search_y1, search_x2 - search_x1), dtype=np.uint8)
        local_x1 = x1 - search_x1
        local_y1 = y1 - search_y1
        local_x2 = x2 - search_x1
        local_y2 = y2 - search_y1
        cv2.rectangle(stairs_mask_region, (local_x1, local_y1), (local_x2, local_y2), 255, -1)
        
        # Excludem scara din zona de cÄƒutare
        search_region_no_stairs = cv2.bitwise_and(search_region, cv2.bitwise_not(stairs_mask_region))
        
        # DetectÄƒm pereÈ›ii existenÈ›i Ã®n jurul scÄƒrii
        existing_walls = search_region_no_stairs > 0
        
        # CreÄƒm o zonÄƒ buffer extinsÄƒ pentru a desena pereÈ›ii
        # Folosim conturul scÄƒrii ca bazÄƒ pentru reconstruirea pereÈ›ilor
        stairs_contour_mask = np.zeros((h, w), dtype=np.uint8)
        cv2.rectangle(stairs_contour_mask, (x1, y1), (x2, y2), 255, -1)
        
        # DilatÄƒm conturul scÄƒrii pentru a crea o zonÄƒ buffer
        # Grosimea peretelui va fi adaptivÄƒ
        wall_thickness = max(3, int(min(w, h) * 0.003))
        kernel_size = max(3, int(min(w, h) * 0.005))
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size, kernel_size))
        
        # DilatÄƒm scara pentru a obÈ›ine zona Ã®n care ar trebui sÄƒ fie pereÈ›ii
        stairs_dilated = cv2.dilate(stairs_contour_mask, kernel, iterations=1)
        
        # Extragem conturul zonei dilatate (perimetrul scÄƒrii + buffer)
        contours, _ = cv2.findContours(stairs_dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if contours:
            # GÄƒsim cel mai mare contur (scara principalÄƒ)
            largest_contour = max(contours, key=cv2.contourArea)
            
            # CreÄƒm o mascÄƒ pentru conturul perimetrului (unde ar trebui sÄƒ fie pereÈ›ii)
            contour_perimeter_mask = np.zeros((h, w), dtype=np.uint8)
            cv2.drawContours(contour_perimeter_mask, [largest_contour], -1, 255, wall_thickness)
            
            # IdentificÄƒm golurile: unde conturul existÄƒ dar pereÈ›ii nu existÄƒ
            gaps = cv2.bitwise_and(contour_perimeter_mask, cv2.bitwise_not(result))
            
            gaps_area = np.count_nonzero(gaps)
            
            if gaps_area > 0:
                # AdÄƒugÄƒm pereÈ›ii noi (doar golurile) la masca finalÄƒ
                result = cv2.bitwise_or(result, gaps)
                print(f"         âœ… Reconstruit {gaps_area} pixeli de pereÈ›i Ã®n jurul scÄƒrii #{stair_idx + 1}")
                stairs_processed += 1
                
                # VizualizÄƒm reconstruirea
                if stairs_output_dir:
                    vis_reconstruction = cv2.cvtColor(walls_mask, cv2.COLOR_GRAY2BGR)
                    
                    # DesenÄƒm scara (magenta)
                    cv2.rectangle(vis_reconstruction, (x1, y1), (x2, y2), (255, 0, 255), 2)
                    
                    # DesenÄƒm conturul perimetrului (albastru)
                    cv2.drawContours(vis_reconstruction, [largest_contour], -1, (255, 0, 0), 2)
                    
                    # DesenÄƒm pereÈ›ii reconstruiÈ›i (verde)
                    gaps_colored = np.zeros_like(vis_reconstruction)
                    gaps_colored[gaps > 0] = [0, 255, 0]
                    vis_reconstruction = cv2.addWeighted(vis_reconstruction, 0.7, gaps_colored, 0.3, 0)
                    
                    # AdÄƒugÄƒm text cu informaÈ›ii
                    status_text = f"Gaps filled: {gaps_area}px âœ…"
                    font_scale = 0.8
                    font_thickness = 2
                    (text_width, text_height), baseline = cv2.getTextSize(status_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)
                    cv2.rectangle(vis_reconstruction, 
                                 (x1, y2 + 5), 
                                 (x1 + text_width + 10, y2 + text_height + baseline + 10), 
                                 (255, 255, 255), -1)
                    cv2.putText(vis_reconstruction, status_text, (x1 + 5, y2 + text_height + 5), 
                               cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 255, 0), font_thickness)
                    
                    output_path = stairs_output_dir / f"reconstruction_{stair_idx + 1}.png"
                    cv2.imwrite(str(output_path), vis_reconstruction)
                    print(f"         ğŸ’¾ Salvat: {stairs_output_dir.name}/reconstruction_{stair_idx + 1}.png")
            else:
                print(f"         â„¹ï¸ Nu s-au gÄƒsit goluri Ã®n pereÈ›i Ã®n jurul scÄƒrii #{stair_idx + 1}")
                if stairs_output_dir:
                    vis_no_gaps = cv2.cvtColor(walls_mask, cv2.COLOR_GRAY2BGR)
                    cv2.rectangle(vis_no_gaps, (x1, y1), (x2, y2), (255, 0, 255), 2)
                    status_text = "No gaps found"
                    font_scale = 0.8
                    font_thickness = 2
                    (text_width, text_height), baseline = cv2.getTextSize(status_text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, font_thickness)
                    cv2.rectangle(vis_no_gaps, 
                                 (x1, y2 + 5), 
                                 (x1 + text_width + 10, y2 + text_height + baseline + 10), 
                                 (255, 255, 255), -1)
                    cv2.putText(vis_no_gaps, status_text, (x1 + 5, y2 + text_height + 5), 
                               cv2.FONT_HERSHEY_SIMPLEX, font_scale, (128, 128, 128), font_thickness)
                    output_path = stairs_output_dir / f"reconstruction_{stair_idx + 1}.png"
                    cv2.imwrite(str(output_path), vis_no_gaps)
                    print(f"         ğŸ’¾ Salvat: {stairs_output_dir.name}/reconstruction_{stair_idx + 1}.png")
        else:
            print(f"         âš ï¸ Nu s-au gÄƒsit contururi pentru scara #{stair_idx + 1}")
    
    if stairs_processed > 0:
        print(f"         âœ… Reconstruit pereÈ›i pentru {stairs_processed} scÄƒri")
    else:
        print(f"         â„¹ï¸ Nu s-au reconstruit pereÈ›i (nu s-au gÄƒsit goluri)")
    
    # SalvÄƒm rezultatul final
    if stairs_output_dir:
        vis_final = cv2.cvtColor(result, cv2.COLOR_GRAY2BGR)
        diff = cv2.subtract(result, walls_mask)
        diff_colored = np.zeros_like(vis_final)
        diff_colored[diff > 0] = [0, 255, 0]  # Verde pentru pereÈ›ii noi
        vis_final = cv2.addWeighted(vis_final, 0.7, diff_colored, 0.3, 0)
        cv2.imwrite(str(stairs_output_dir / "final_result.png"), vis_final)
        print(f"         ğŸ’¾ Salvat: {stairs_output_dir.name}/final_result.png (verde=pereÈ›i noi)")
    
    return result
